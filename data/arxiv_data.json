[
    {
        "title": "Lecture Notes: Optimization for Machine Learning",
        "abstract": "Lecture notes on optimization for machine learning, derived from a course at Princeton University and tutorials given in MLSS, Buenos Aires, as well as Simons Foundation, Berkeley.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1909.03550v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Elad Hazan"
        ],
        "pdf_url": "http://arxiv.org/pdf/1909.03550v1"
    },
    {
        "title": "Machine Learning for Clinical Predictive Analytics",
        "abstract": "In this chapter, we provide a brief overview of applying machine learning techniques for clinical prediction tasks. We begin with a quick introduction to the concepts of machine learning and outline some of the most common machine learning algorithms. Next, we demonstrate how to apply the algorithms with appropriate toolkits to conduct machine learning experiments for clinical prediction tasks. The objectives of this chapter are to (1) understand the basics of machine learning techniques and the reasons behind why they are useful for solving clinical prediction problems, (2) understand the intuition behind some machine learning models, including regression, decision trees, and support vector machines, and (3) understand how to apply these models to clinical prediction problems using publicly available datasets via case studies.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1909.09246v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Wei-Hung Weng"
        ],
        "pdf_url": "http://arxiv.org/pdf/1909.09246v1"
    },
    {
        "title": "Towards Modular Machine Learning Solution Development: Benefits and   Trade-offs",
        "abstract": "Machine learning technologies have demonstrated immense capabilities in various domains. They play a key role in the success of modern businesses. However, adoption of machine learning technologies has a lot of untouched potential. Cost of developing custom machine learning solutions that solve unique business problems is a major inhibitor to far-reaching adoption of machine learning technologies. We recognize that the monolithic nature prevalent in today's machine learning applications stands in the way of efficient and cost effective customized machine learning solution development. In this work we explore the benefits of modular machine learning solutions and discuss how modular machine learning solutions can overcome some of the major solution engineering limitations of monolithic machine learning solutions. We analyze the trade-offs between modular and monolithic machine learning solutions through three deep learning problems; one text based and the two image based. Our experimental results show that modular machine learning solutions have a promising potential to reap the solution engineering advantages of modularity while gaining performance and data advantages in a way the monolithic machine learning solutions do not permit.",
        "publication_year": "2023",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2301.09753v1",
        "keywords": "cs.LG, cs.SE",
        "subject_areas": "cs.LG, cs.SE",
        "authors": [
            "Samiyuru Menik",
            "Lakshmish Ramaswamy"
        ],
        "pdf_url": "http://arxiv.org/pdf/2301.09753v1"
    },
    {
        "title": "The Tribes of Machine Learning and the Realm of Computer Architecture",
        "abstract": "Machine learning techniques have influenced the field of computer architecture like many other fields. This paper studies how the fundamental machine learning techniques can be applied towards computer architecture problems. We also provide a detailed survey of computer architecture research that employs different machine learning methods. Finally, we present some future opportunities and the outstanding challenges that need to be overcome to exploit full potential of machine learning for computer architecture.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2012.04105v1",
        "keywords": "cs.LG, cs.AR",
        "subject_areas": "cs.LG, cs.AR",
        "authors": [
            "Ayaz Akram",
            "Jason Lowe-Power"
        ],
        "pdf_url": "http://arxiv.org/pdf/2012.04105v1"
    },
    {
        "title": "An Optimal Control View of Adversarial Machine Learning",
        "abstract": "I describe an optimal control view of adversarial machine learning, where the dynamical system is the machine learner, the input are adversarial actions, and the control costs are defined by the adversary's goals to do harm and be hard to detect. This view encompasses many types of adversarial machine learning, including test-item attacks, training-data poisoning, and adversarial reward shaping. The view encourages adversarial machine learning researcher to utilize advances in control theory and reinforcement learning.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1811.04422v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Xiaojin Zhu"
        ],
        "pdf_url": "http://arxiv.org/pdf/1811.04422v1"
    },
    {
        "title": "A Machine Learning Tutorial for Operational Meteorology, Part I:   Traditional Machine Learning",
        "abstract": "Recently, the use of machine learning in meteorology has increased greatly. While many machine learning methods are not new, university classes on machine learning are largely unavailable to meteorology students and are not required to become a meteorologist. The lack of formal instruction has contributed to perception that machine learning methods are 'black boxes' and thus end-users are hesitant to apply the machine learning methods in their every day workflow. To reduce the opaqueness of machine learning methods and lower hesitancy towards machine learning in meteorology, this paper provides a survey of some of the most common machine learning methods. A familiar meteorological example is used to contextualize the machine learning methods while also discussing machine learning topics using plain language. The following machine learning methods are demonstrated: linear regression; logistic regression; decision trees; random forest; gradient boosted decision trees; naive Bayes; and support vector machines. Beyond discussing the different methods, the paper also contains discussions on the general machine learning process as well as best practices to enable readers to apply machine learning to their own datasets. Furthermore, all code (in the form of Jupyter notebooks and Google Colaboratory notebooks) used to make the examples in the paper is provided in an effort to catalyse the use of machine learning in meteorology.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2204.07492v2",
        "keywords": "physics.ao-ph, cs.LG",
        "subject_areas": "physics.ao-ph, cs.LG",
        "authors": [
            "Randy J. Chase",
            "David R. Harrison",
            "Amanda Burke",
            "Gary M. Lackmann",
            "Amy McGovern"
        ],
        "pdf_url": "http://arxiv.org/pdf/2204.07492v2"
    },
    {
        "title": "MLBench: How Good Are Machine Learning Clouds for Binary Classification   Tasks on Structured Data?",
        "abstract": "We conduct an empirical study of machine learning functionalities provided by major cloud service providers, which we call machine learning clouds. Machine learning clouds hold the promise of hiding all the sophistication of running large-scale machine learning: Instead of specifying how to run a machine learning task, users only specify what machine learning task to run and the cloud figures out the rest. Raising the level of abstraction, however, rarely comes free - a performance penalty is possible. How good, then, are current machine learning clouds on real-world machine learning workloads?   We study this question with a focus on binary classication problems. We present mlbench, a novel benchmark constructed by harvesting datasets from Kaggle competitions. We then compare the performance of the top winning code available from Kaggle with that of running machine learning clouds from both Azure and Amazon on mlbench. Our comparative study reveals the strength and weakness of existing machine learning clouds and points out potential future directions for improvement.",
        "publication_year": "2017",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1707.09562v3",
        "keywords": "cs.DC, cs.LG, stat.ML",
        "subject_areas": "cs.DC, cs.LG, stat.ML",
        "authors": [
            "Yu Liu",
            "Hantian Zhang",
            "Luyuan Zeng",
            "Wentao Wu",
            "Ce Zhang"
        ],
        "pdf_url": "http://arxiv.org/pdf/1707.09562v3"
    },
    {
        "title": "Data Pricing in Machine Learning Pipelines",
        "abstract": "Machine learning is disruptive. At the same time, machine learning can only succeed by collaboration among many parties in multiple steps naturally as pipelines in an eco-system, such as collecting data for possible machine learning applications, collaboratively training models by multiple parties and delivering machine learning services to end users. Data is critical and penetrating in the whole machine learning pipelines. As machine learning pipelines involve many parties and, in order to be successful, have to form a constructive and dynamic eco-system, marketplaces and data pricing are fundamental in connecting and facilitating those many parties. In this article, we survey the principles and the latest research development of data pricing in machine learning pipelines. We start with a brief review of data marketplaces and pricing desiderata. Then, we focus on pricing in three important steps in machine learning pipelines. To understand pricing in the step of training data collection, we review pricing raw data sets and data labels. We also investigate pricing in the step of collaborative training of machine learning models, and overview pricing machine learning models for end users in the step of machine learning deployment. We also discuss a series of possible future directions.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2108.07915v1",
        "keywords": "cs.LG",
        "subject_areas": "cs.LG",
        "authors": [
            "Zicun Cong",
            "Xuan Luo",
            "Pei Jian",
            "Feida Zhu",
            "Yong Zhang"
        ],
        "pdf_url": "http://arxiv.org/pdf/2108.07915v1"
    },
    {
        "title": "Understanding Bias in Machine Learning",
        "abstract": "Bias is known to be an impediment to fair decisions in many domains such as human resources, the public sector, health care etc. Recently, hope has been expressed that the use of machine learning methods for taking such decisions would diminish or even resolve the problem. At the same time, machine learning experts warn that machine learning models can be biased as well. In this article, our goal is to explain the issue of bias in machine learning from a technical perspective and to illustrate the impact that biased data can have on a machine learning model. To reach such a goal, we develop interactive plots to visualizing the bias learned from synthetic data.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1909.01866v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Jindong Gu",
            "Daniela Oelke"
        ],
        "pdf_url": "http://arxiv.org/pdf/1909.01866v1"
    },
    {
        "title": "Introduction to Machine Learning: Class Notes 67577",
        "abstract": "Introduction to Machine learning covering Statistical Inference (Bayes, EM, ML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering), and PAC learning (the Formal model, VC dimension, Double Sampling theorem).",
        "publication_year": "2009",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/0904.3664v1",
        "keywords": "cs.LG",
        "subject_areas": "cs.LG",
        "authors": [
            "Amnon Shashua"
        ],
        "pdf_url": "http://arxiv.org/pdf/0904.3664v1"
    },
    {
        "title": "Proceedings of the 2016 ICML Workshop on #Data4Good: Machine Learning in   Social Good Applications",
        "abstract": "This is the Proceedings of the ICML Workshop on #Data4Good: Machine Learning in Social Good Applications, which was held on June 24, 2016 in New York.",
        "publication_year": "2016",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1607.02450v2",
        "keywords": "stat.ML, cs.CY, cs.LG",
        "subject_areas": "stat.ML, cs.CY, cs.LG",
        "authors": [
            "Kush R. Varshney"
        ],
        "pdf_url": "http://arxiv.org/pdf/1607.02450v2"
    },
    {
        "title": "Mathematical Perspective of Machine Learning",
        "abstract": "We take a closer look at some theoretical challenges of Machine Learning as a function approximation, gradient descent as the default optimization algorithm, limitations of fixed length and width networks and a different approach to RNNs from a mathematical perspective.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2007.01503v1",
        "keywords": "cs.LG, stat.ML, 68T07",
        "subject_areas": "cs.LG, stat.ML, 68T07",
        "authors": [
            "Yarema Boryshchak"
        ],
        "pdf_url": "http://arxiv.org/pdf/2007.01503v1"
    },
    {
        "title": "A Unified Analytical Framework for Trustable Machine Learning and   Automation Running with Blockchain",
        "abstract": "Traditional machine learning algorithms use data from databases that are mutable, and therefore the data cannot be fully trusted. Also, the machine learning process is difficult to automate. This paper proposes building a trustable machine learning system by using blockchain technology, which can store data in a permanent and immutable way. In addition, smart contracts are used to automate the machine learning process. This paper makes three contributions. First, it establishes a link between machine learning technology and blockchain technology. Previously, machine learning and blockchain have been considered two independent technologies without an obvious link. Second, it proposes a unified analytical framework for trustable machine learning by using blockchain technology. This unified framework solves both the trustability and automation issues in machine learning. Third, it enables a computer to translate core machine learning implementation from a single thread on a single machine to multiple threads on multiple machines running with blockchain by using a unified approach. The paper uses association rule mining as an example to demonstrate how trustable machine learning can be implemented with blockchain, and it shows how this approach can be used to analyze opioid prescriptions to help combat the opioid crisis.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1903.08801v1",
        "keywords": "cs.LG, cs.CR",
        "subject_areas": "cs.LG, cs.CR",
        "authors": [
            "Tao Wang"
        ],
        "pdf_url": "http://arxiv.org/pdf/1903.08801v1"
    },
    {
        "title": "Ten-year Survival Prediction for Breast Cancer Patients",
        "abstract": "This report assesses different machine learning approaches to 10-year survival prediction of breast cancer patients.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1911.00776v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Changmao Li",
            "Han He",
            "Yunze Hao",
            "Caleb Ziems"
        ],
        "pdf_url": "http://arxiv.org/pdf/1911.00776v1"
    },
    {
        "title": "A Survey of Optimization Methods from a Machine Learning Perspective",
        "abstract": "Machine learning develops rapidly, which has made many theoretical breakthroughs and is widely applied in various fields. Optimization, as an important part of machine learning, has attracted much attention of researchers. With the exponential growth of data amount and the increase of model complexity, optimization methods in machine learning face more and more challenges. A lot of work on solving optimization problems or improving optimization methods in machine learning has been proposed successively. The systematic retrospect and summary of the optimization methods from the perspective of machine learning are of great significance, which can offer guidance for both developments of optimization and machine learning research. In this paper, we first describe the optimization problems in machine learning. Then, we introduce the principles and progresses of commonly used optimization methods. Next, we summarize the applications and developments of optimization methods in some popular machine learning fields. Finally, we explore and give some challenges and open problems for the optimization in machine learning.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1906.06821v2",
        "keywords": "cs.LG, math.OC, stat.ML",
        "subject_areas": "cs.LG, math.OC, stat.ML",
        "authors": [
            "Shiliang Sun",
            "Zehui Cao",
            "Han Zhu",
            "Jing Zhao"
        ],
        "pdf_url": "http://arxiv.org/pdf/1906.06821v2"
    },
    {
        "title": "When Machine Learning Meets Privacy: A Survey and Outlook",
        "abstract": "The newly emerged machine learning (e.g. deep learning) methods have become a strong driving force to revolutionize a wide range of industries, such as smart healthcare, financial technology, and surveillance systems. Meanwhile, privacy has emerged as a big concern in this machine learning-based artificial intelligence era. It is important to note that the problem of privacy preservation in the context of machine learning is quite different from that in traditional data privacy protection, as machine learning can act as both friend and foe. Currently, the work on the preservation of privacy and machine learning (ML) is still in an infancy stage, as most existing solutions only focus on privacy problems during the machine learning process. Therefore, a comprehensive study on the privacy preservation problems and machine learning is required. This paper surveys the state of the art in privacy issues and solutions for machine learning. The survey covers three categories of interactions between privacy and machine learning: (i) private machine learning, (ii) machine learning aided privacy protection, and (iii) machine learning-based privacy attack and corresponding protection schemes. The current research progress in each category is reviewed and the key challenges are identified. Finally, based on our in-depth analysis of the area of privacy and machine learning, we point out future research directions in this field.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2011.11819v1",
        "keywords": "cs.LG, cs.AI, cs.CR",
        "subject_areas": "cs.LG, cs.AI, cs.CR",
        "authors": [
            "Bo Liu",
            "Ming Ding",
            "Sina Shaham",
            "Wenny Rahayu",
            "Farhad Farokhi",
            "Zihuai Lin"
        ],
        "pdf_url": "http://arxiv.org/pdf/2011.11819v1"
    },
    {
        "title": "Towards CRISP-ML(Q): A Machine Learning Process Model with Quality   Assurance Methodology",
        "abstract": "Machine learning is an established and frequently used technique in industry and academia but a standard process model to improve success and efficiency of machine learning applications is still missing. Project organizations and machine learning practitioners have a need for guidance throughout the life cycle of a machine learning application to meet business expectations. We therefore propose a process model for the development of machine learning applications, that covers six phases from defining the scope to maintaining the deployed machine learning application. The first phase combines business and data understanding as data availability oftentimes affects the feasibility of the project. The sixth phase covers state-of-the-art approaches for monitoring and maintenance of a machine learning applications, as the risk of model degradation in a changing environment is eminent. With each task of the process, we propose quality assurance methodology that is suitable to adress challenges in machine learning development that we identify in form of risks. The methodology is drawn from practical experience and scientific literature and has proven to be general and stable. The process model expands on CRISP-DM, a data mining process model that enjoys strong industry support but lacks to address machine learning specific tasks. Our work proposes an industry and application neutral process model tailored for machine learning applications with focus on technical tasks for quality assurance.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2003.05155v2",
        "keywords": "cs.LG, cs.SE, stat.ML",
        "subject_areas": "cs.LG, cs.SE, stat.ML",
        "authors": [
            "Stefan Studer",
            "Thanh Binh Bui",
            "Christian Drescher",
            "Alexander Hanuschkin",
            "Ludwig Winkler",
            "Steven Peters",
            "Klaus-Robert Mueller"
        ],
        "pdf_url": "http://arxiv.org/pdf/2003.05155v2"
    },
    {
        "title": "Proceedings of the 29th International Conference on Machine Learning   (ICML-12)",
        "abstract": "This is an index to the papers that appear in the Proceedings of the 29th International Conference on Machine Learning (ICML-12). The conference was held in Edinburgh, Scotland, June 27th - July 3rd, 2012.",
        "publication_year": "2012",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1207.4676v2",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "John Langford",
            "Joelle Pineau"
        ],
        "pdf_url": "http://arxiv.org/pdf/1207.4676v2"
    },
    {
        "title": "Position Paper: Towards Transparent Machine Learning",
        "abstract": "Transparent machine learning is introduced as an alternative form of machine learning, where both the model and the learning system are represented in source code form. The goal of this project is to enable direct human understanding of machine learning models, giving us the ability to learn, verify, and refine them as programs. If solved, this technology could represent a best-case scenario for the safety and security of AI systems going forward.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1911.06612v1",
        "keywords": "cs.LG",
        "subject_areas": "cs.LG",
        "authors": [
            "Dustin Juliano"
        ],
        "pdf_url": "http://arxiv.org/pdf/1911.06612v1"
    },
    {
        "title": "Components of Machine Learning: Binding Bits and FLOPS",
        "abstract": "Many machine learning problems and methods are combinations of three components: data, hypothesis space and loss function. Different machine learning methods are obtained as combinations of different choices for the representation of data, hypothesis space and loss function. After reviewing the mathematical structure of these three components, we discuss intrinsic trade-offs between statistical and computational properties of machine learning methods.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1910.12387v2",
        "keywords": "cs.LG",
        "subject_areas": "cs.LG",
        "authors": [
            "Alexander Jung"
        ],
        "pdf_url": "http://arxiv.org/pdf/1910.12387v2"
    },
    {
        "title": "Impact of Legal Requirements on Explainability in Machine Learning",
        "abstract": "The requirements on explainability imposed by European laws and their implications for machine learning (ML) models are not always clear. In that perspective, our research analyzes explanation obligations imposed for private and public decision-making, and how they can be implemented by machine learning techniques.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2007.05479v1",
        "keywords": "cs.AI, cs.CY, cs.LG",
        "subject_areas": "cs.AI, cs.CY, cs.LG",
        "authors": [
            "Adrien Bibal",
            "Michael Lognoul",
            "Alexandre de Streel",
            "Benoît Frénay"
        ],
        "pdf_url": "http://arxiv.org/pdf/2007.05479v1"
    },
    {
        "title": "Machine Learning Potential Repository",
        "abstract": "This paper introduces a machine learning potential repository that includes Pareto optimal machine learning potentials. It also shows the systematic development of accurate and fast machine learning potentials for a wide range of elemental systems. As a result, many Pareto optimal machine learning potentials are available in the repository from a website. Therefore, the repository will help many scientists to perform accurate and fast atomistic simulations.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2007.14206v1",
        "keywords": "physics.comp-ph, cond-mat.mtrl-sci, physics.chem-ph, physics.data-an",
        "subject_areas": "physics.comp-ph, cond-mat.mtrl-sci, physics.chem-ph, physics.data-an",
        "authors": [
            "Atsuto Seko"
        ],
        "pdf_url": "http://arxiv.org/pdf/2007.14206v1"
    },
    {
        "title": "Private Machine Learning via Randomised Response",
        "abstract": "We introduce a general learning framework for private machine learning based on randomised response. Our assumption is that all actors are potentially adversarial and as such we trust only to release a single noisy version of an individual's datapoint. We discuss a general approach that forms a consistent way to estimate the true underlying machine learning model and demonstrate this in the case of logistic regression.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2001.04942v2",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "David Barber"
        ],
        "pdf_url": "http://arxiv.org/pdf/2001.04942v2"
    },
    {
        "title": "Quantum memristors for neuromorphic quantum machine learning",
        "abstract": "Quantum machine learning may permit to realize more efficient machine learning calculations with near-term quantum devices. Among the diverse quantum machine learning paradigms which are currently being considered, quantum memristors are promising as a way of combining, in the same quantum hardware, a unitary evolution with the nonlinearity provided by the measurement and feedforward. Thus, an efficient way of deploying neuromorphic quantum computing for quantum machine learning may be enabled.",
        "publication_year": "2024",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2412.18979v1",
        "keywords": "quant-ph, cs.NE",
        "subject_areas": "quant-ph, cs.NE",
        "authors": [
            "Lucas Lamata"
        ],
        "pdf_url": "http://arxiv.org/pdf/2412.18979v1"
    },
    {
        "title": "AutoCompete: A Framework for Machine Learning Competition",
        "abstract": "In this paper, we propose AutoCompete, a highly automated machine learning framework for tackling machine learning competitions. This framework has been learned by us, validated and improved over a period of more than two years by participating in online machine learning competitions. It aims at minimizing human interference required to build a first useful predictive model and to assess the practical difficulty of a given machine learning challenge. The proposed system helps in identifying data types, choosing a machine learn- ing model, tuning hyper-parameters, avoiding over-fitting and optimization for a provided evaluation metric. We also observe that the proposed system produces better (or comparable) results with less runtime as compared to other approaches.",
        "publication_year": "2015",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1507.02188v1",
        "keywords": "stat.ML, cs.LG",
        "subject_areas": "stat.ML, cs.LG",
        "authors": [
            "Abhishek Thakur",
            "Artus Krohn-Grimberghe"
        ],
        "pdf_url": "http://arxiv.org/pdf/1507.02188v1"
    },
    {
        "title": "Bayesian Optimization for Machine Learning : A Practical Guidebook",
        "abstract": "The engineering of machine learning systems is still a nascent field; relying on a seemingly daunting collection of quickly evolving tools and best practices. It is our hope that this guidebook will serve as a useful resource for machine learning practitioners looking to take advantage of Bayesian optimization techniques. We outline four example machine learning problems that can be solved using open source machine learning libraries, and highlight the benefits of using Bayesian optimization in the context of these common machine learning applications.",
        "publication_year": "2016",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1612.04858v1",
        "keywords": "cs.LG",
        "subject_areas": "cs.LG",
        "authors": [
            "Ian Dewancker",
            "Michael McCourt",
            "Scott Clark"
        ],
        "pdf_url": "http://arxiv.org/pdf/1612.04858v1"
    },
    {
        "title": "Towards A Rigorous Science of Interpretable Machine Learning",
        "abstract": "As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.",
        "publication_year": "2017",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1702.08608v2",
        "keywords": "stat.ML, cs.AI, cs.LG",
        "subject_areas": "stat.ML, cs.AI, cs.LG",
        "authors": [
            "Finale Doshi-Velez",
            "Been Kim"
        ],
        "pdf_url": "http://arxiv.org/pdf/1702.08608v2"
    },
    {
        "title": "Solving machine learning optimization problems using quantum computers",
        "abstract": "Classical optimization algorithms in machine learning often take a long time to compute when applied to a multi-dimensional problem and require a huge amount of CPU and GPU resource. Quantum parallelism has a potential to speed up machine learning algorithms. We describe a generic mathematical model to leverage quantum parallelism to speed-up machine learning algorithms. We also apply quantum machine learning and quantum parallelism applied to a $3$-dimensional image that vary with time.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1911.08587v1",
        "keywords": "quant-ph, cs.LG, stat.ML",
        "subject_areas": "quant-ph, cs.LG, stat.ML",
        "authors": [
            "Venkat R. Dasari",
            "Mee Seong Im",
            "Lubjana Beshaj"
        ],
        "pdf_url": "http://arxiv.org/pdf/1911.08587v1"
    },
    {
        "title": "Infrastructure for Usable Machine Learning: The Stanford DAWN Project",
        "abstract": "Despite incredible recent advances in machine learning, building machine learning applications remains prohibitively time-consuming and expensive for all but the best-trained, best-funded engineering organizations. This expense comes not from a need for new and improved statistical models but instead from a lack of systems and tools for supporting end-to-end machine learning application development, from data preparation and labeling to productionization and monitoring. In this document, we outline opportunities for infrastructure supporting usable, end-to-end machine learning applications in the context of the nascent DAWN (Data Analytics for What's Next) project at Stanford.",
        "publication_year": "2017",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1705.07538v2",
        "keywords": "cs.LG, cs.DB, stat.ML",
        "subject_areas": "cs.LG, cs.DB, stat.ML",
        "authors": [
            "Peter Bailis",
            "Kunle Olukotun",
            "Christopher Re",
            "Matei Zaharia"
        ],
        "pdf_url": "http://arxiv.org/pdf/1705.07538v2"
    },
    {
        "title": "mlr3proba: An R Package for Machine Learning in Survival Analysis",
        "abstract": "As machine learning has become increasingly popular over the last few decades, so too has the number of machine learning interfaces for implementing these models. Whilst many R libraries exist for machine learning, very few offer extended support for survival analysis. This is problematic considering its importance in fields like medicine, bioinformatics, economics, engineering, and more. mlr3proba provides a comprehensive machine learning interface for survival analysis and connects with mlr3's general model tuning and benchmarking facilities to provide a systematic infrastructure for survival modeling and evaluation.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2008.08080v2",
        "keywords": "stat.CO, cs.LG, stat.ML",
        "subject_areas": "stat.CO, cs.LG, stat.ML",
        "authors": [
            "Raphael Sonabend",
            "Franz J. Király",
            "Andreas Bender",
            "Bernd Bischl",
            "Michel Lang"
        ],
        "pdf_url": "http://arxiv.org/pdf/2008.08080v2"
    },
    {
        "title": "Techniques for Interpretable Machine Learning",
        "abstract": "Interpretable machine learning tackles the important problem that humans cannot understand the behaviors of complex machine learning models and how these models arrive at a particular decision. Although many approaches have been proposed, a comprehensive understanding of the achievements and challenges is still lacking. We provide a survey covering existing techniques to increase the interpretability of machine learning models. We also discuss crucial issues that the community should consider in future work such as designing user-friendly explanations and developing comprehensive evaluation metrics to further push forward the area of interpretable machine learning.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1808.00033v3",
        "keywords": "cs.LG, cs.AI, stat.ML",
        "subject_areas": "cs.LG, cs.AI, stat.ML",
        "authors": [
            "Mengnan Du",
            "Ninghao Liu",
            "Xia Hu"
        ],
        "pdf_url": "http://arxiv.org/pdf/1808.00033v3"
    },
    {
        "title": "Techniques for Automated Machine Learning",
        "abstract": "Automated machine learning (AutoML) aims to find optimal machine learning solutions automatically given a machine learning problem. It could release the burden of data scientists from the multifarious manual tuning process and enable the access of domain experts to the off-the-shelf machine learning solutions without extensive experience. In this paper, we review the current developments of AutoML in terms of three categories, automated feature engineering (AutoFE), automated model and hyperparameter learning (AutoMHL), and automated deep learning (AutoDL). State-of-the-art techniques adopted in the three categories are presented, including Bayesian optimization, reinforcement learning, evolutionary algorithm, and gradient-based approaches. We summarize popular AutoML frameworks and conclude with current open challenges of AutoML.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1907.08908v1",
        "keywords": "cs.LG, cs.AI, stat.ML",
        "subject_areas": "cs.LG, cs.AI, stat.ML",
        "authors": [
            "Yi-Wei Chen",
            "Qingquan Song",
            "Xia Hu"
        ],
        "pdf_url": "http://arxiv.org/pdf/1907.08908v1"
    },
    {
        "title": "Lale: Consistent Automated Machine Learning",
        "abstract": "Automated machine learning makes it easier for data scientists to develop pipelines by searching over possible choices for hyperparameters, algorithms, and even pipeline topologies. Unfortunately, the syntax for automated machine learning tools is inconsistent with manual machine learning, with each other, and with error checks. Furthermore, few tools support advanced features such as topology search or higher-order operators. This paper introduces Lale, a library of high-level Python interfaces that simplifies and unifies automated machine learning in a consistent way.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2007.01977v1",
        "keywords": "cs.LG, cs.AI",
        "subject_areas": "cs.LG, cs.AI",
        "authors": [
            "Guillaume Baudart",
            "Martin Hirzel",
            "Kiran Kate",
            "Parikshit Ram",
            "Avraham Shinnar"
        ],
        "pdf_url": "http://arxiv.org/pdf/2007.01977v1"
    },
    {
        "title": "Differential Replication in Machine Learning",
        "abstract": "When deployed in the wild, machine learning models are usually confronted with data and requirements that constantly vary, either because of changes in the generating distribution or because external constraints change the environment where the model operates. To survive in such an ecosystem, machine learning models need to adapt to new conditions by evolving over time. The idea of model adaptability has been studied from different perspectives. In this paper, we propose a solution based on reusing the knowledge acquired by the already deployed machine learning models and leveraging it to train future generations. This is the idea behind differential replication of machine learning models.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2007.07981v1",
        "keywords": "cs.LG, stat.ML, cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML, cs.LG, stat.ML",
        "authors": [
            "Irene Unceta",
            "Jordi Nin",
            "Oriol Pujol"
        ],
        "pdf_url": "http://arxiv.org/pdf/2007.07981v1"
    },
    {
        "title": "Probabilistic Machine Learning for Healthcare",
        "abstract": "Machine learning can be used to make sense of healthcare data. Probabilistic machine learning models help provide a complete picture of observed data in healthcare. In this review, we examine how probabilistic machine learning can advance healthcare. We consider challenges in the predictive model building pipeline where probabilistic models can be beneficial including calibration and missing data. Beyond predictive models, we also investigate the utility of probabilistic machine learning models in phenotyping, in generative models for clinical use cases, and in reinforcement learning.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2009.11087v1",
        "keywords": "stat.ML, cs.CY, cs.LG",
        "subject_areas": "stat.ML, cs.CY, cs.LG",
        "authors": [
            "Irene Y. Chen",
            "Shalmali Joshi",
            "Marzyeh Ghassemi",
            "Rajesh Ranganath"
        ],
        "pdf_url": "http://arxiv.org/pdf/2009.11087v1"
    },
    {
        "title": "Teaching Uncertainty Quantification in Machine Learning through Use   Cases",
        "abstract": "Uncertainty in machine learning is not generally taught as general knowledge in Machine Learning course curricula. In this paper we propose a short curriculum for a course about uncertainty in machine learning, and complement the course with a selection of use cases, aimed to trigger discussion and let students play with the concepts of uncertainty in a programming setting. Our use cases cover the concept of output uncertainty, Bayesian neural networks and weight distributions, sources of uncertainty, and out of distribution detection. We expect that this curriculum and set of use cases motivates the community to adopt these important concepts into courses for safety in AI.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2108.08712v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Matias Valdenegro-Toro"
        ],
        "pdf_url": "http://arxiv.org/pdf/2108.08712v1"
    },
    {
        "title": "Introduction to Machine Learning for Physicians: A Survival Guide for   Data Deluge",
        "abstract": "Many modern research fields increasingly rely on collecting and analysing massive, often unstructured, and unwieldy datasets. Consequently, there is growing interest in machine learning and artificial intelligence applications that can harness this `data deluge'. This broad nontechnical overview provides a gentle introduction to machine learning with a specific focus on medical and biological applications. We explain the common types of machine learning algorithms and typical tasks that can be solved, illustrating the basics with concrete examples from healthcare. Lastly, we provide an outlook on open challenges, limitations, and potential impacts of machine-learning-powered medicine.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2212.12303v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Ričards Marcinkevičs",
            "Ece Ozkan",
            "Julia E. Vogt"
        ],
        "pdf_url": "http://arxiv.org/pdf/2212.12303v1"
    },
    {
        "title": "Evaluation Challenges for Geospatial ML",
        "abstract": "As geospatial machine learning models and maps derived from their predictions are increasingly used for downstream analyses in science and policy, it is imperative to evaluate their accuracy and applicability. Geospatial machine learning has key distinctions from other learning paradigms, and as such, the correct way to measure performance of spatial machine learning outputs has been a topic of debate. In this paper, I delineate unique challenges of model evaluation for geospatial machine learning with global or remotely sensed datasets, culminating in concrete takeaways to improve evaluations of geospatial model performance.",
        "publication_year": "2023",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2303.18087v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Esther Rolf"
        ],
        "pdf_url": "http://arxiv.org/pdf/2303.18087v1"
    },
    {
        "title": "Machine learning-assisted close-set X-ray diffraction phase   identification of transition metals",
        "abstract": "Machine learning has been applied to the problem of X-ray diffraction phase prediction with promising results. In this paper, we describe a method for using machine learning to predict crystal structure phases from X-ray diffraction data of transition metals and their oxides. We evaluate the performance of our method and compare the variety of its settings. Our results demonstrate that the proposed machine learning framework achieves competitive performance. This demonstrates the potential for machine learning to significantly impact the field of X-ray diffraction and crystal structure determination. Open-source implementation: https://github.com/maxnygma/NeuralXRD.",
        "publication_year": "2023",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2305.15410v1",
        "keywords": "cond-mat.mtrl-sci, cs.AI, cs.LG",
        "subject_areas": "cond-mat.mtrl-sci, cs.AI, cs.LG",
        "authors": [
            "Maksim Zhdanov",
            "Andrey Zhdanov"
        ],
        "pdf_url": "http://arxiv.org/pdf/2305.15410v1"
    },
    {
        "title": "Insights From Insurance for Fair Machine Learning",
        "abstract": "We argue that insurance can act as an analogon for the social situatedness of machine learning systems, hence allowing machine learning scholars to take insights from the rich and interdisciplinary insurance literature. Tracing the interaction of uncertainty, fairness and responsibility in insurance provides a fresh perspective on fairness in machine learning. We link insurance fairness conceptions to their machine learning relatives, and use this bridge to problematize fairness as calibration. In this process, we bring to the forefront two themes that have been largely overlooked in the machine learning literature: responsibility and aggregate-individual tensions.",
        "publication_year": "2023",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2306.14624v2",
        "keywords": "cs.LG, cs.CY",
        "subject_areas": "cs.LG, cs.CY",
        "authors": [
            "Christian Fröhlich",
            "Robert C. Williamson"
        ],
        "pdf_url": "http://arxiv.org/pdf/2306.14624v2"
    },
    {
        "title": "A comprehensive review of Quantum Machine Learning: from NISQ to Fault   Tolerance",
        "abstract": "Quantum machine learning, which involves running machine learning algorithms on quantum devices, has garnered significant attention in both academic and business circles. In this paper, we offer a comprehensive and unbiased review of the various concepts that have emerged in the field of quantum machine learning. This includes techniques used in Noisy Intermediate-Scale Quantum (NISQ) technologies and approaches for algorithms compatible with fault-tolerant quantum computing hardware. Our review covers fundamental concepts, algorithms, and the statistical learning theory pertinent to quantum machine learning.",
        "publication_year": "2024",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2401.11351v2",
        "keywords": "quant-ph, cs.AI, cs.LG, stat.ML",
        "subject_areas": "quant-ph, cs.AI, cs.LG, stat.ML",
        "authors": [
            "Yunfei Wang",
            "Junyu Liu"
        ],
        "pdf_url": "http://arxiv.org/pdf/2401.11351v2"
    },
    {
        "title": "Quantum Dynamics of Machine Learning",
        "abstract": "The quantum dynamic equation (QDE) of machine learning is obtained based on Schr\\\"odinger equation and potential energy equivalence relationship. Through Wick rotation, the relationship between quantum dynamics and thermodynamics is also established in this paper. This equation reformulates the iterative process of machine learning into a time-dependent partial differential equation with a clear mathematical structure, offering a theoretical framework for investigating machine learning iterations through quantum and mathematical theories. Within this framework, the fundamental iterative process, the diffusion model, and the Softmax and Sigmoid functions are examined, validating the proposed quantum dynamics equations. This approach not only presents a rigorous theoretical foundation for machine learning but also holds promise for supporting the implementation of machine learning algorithms on quantum computers.",
        "publication_year": "2024",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2407.19890v1",
        "keywords": "quant-ph, cs.LG",
        "subject_areas": "quant-ph, cs.LG",
        "authors": [
            "Peng Wang",
            "Maimaitiniyazi Maimaitiabudula"
        ],
        "pdf_url": "http://arxiv.org/pdf/2407.19890v1"
    },
    {
        "title": "On the Conditions for Domain Stability for Machine Learning: a   Mathematical Approach",
        "abstract": "This work proposes a mathematical approach that (re)defines a property of Machine Learning models named stability and determines sufficient conditions to validate it. Machine Learning models are represented as functions, and the characteristics in scope depend upon the domain of the function, what allows us to adopt topological and metric spaces theory as a basis. Finally, this work provides some equivalences useful to prove and test stability in Machine Learning models. The results suggest that whenever stability is aligned with the notion of function smoothness, then the stability of Machine Learning models primarily depends upon certain topological, measurable properties of the classification sets within the ML model domain.",
        "publication_year": "2024",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2412.00464v1",
        "keywords": "cs.LG, cs.AI, stat.ML, F.4.1; I.2.0",
        "subject_areas": "cs.LG, cs.AI, stat.ML, F.4.1; I.2.0",
        "authors": [
            "Gabriel Pedroza"
        ],
        "pdf_url": "http://arxiv.org/pdf/2412.00464v1"
    },
    {
        "title": "How Developers Iterate on Machine Learning Workflows -- A Survey of the   Applied Machine Learning Literature",
        "abstract": "Machine learning workflow development is anecdotally regarded to be an iterative process of trial-and-error with humans-in-the-loop. However, we are not aware of quantitative evidence corroborating this popular belief. A quantitative characterization of iteration can serve as a benchmark for machine learning workflow development in practice, and can aid the development of human-in-the-loop machine learning systems. To this end, we conduct a small-scale survey of the applied machine learning literature from five distinct application domains. We collect and distill statistics on the role of iteration within machine learning workflow development, and report preliminary trends and insights from our investigation, as a starting point towards this benchmark. Based on our findings, we finally describe desiderata for effective and versatile human-in-the-loop machine learning systems that can cater to users in diverse domains.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1803.10311v2",
        "keywords": "cs.LG, cs.DB, cs.HC, stat.ML",
        "subject_areas": "cs.LG, cs.DB, cs.HC, stat.ML",
        "authors": [
            "Doris Xin",
            "Litian Ma",
            "Shuchen Song",
            "Aditya Parameswaran"
        ],
        "pdf_url": "http://arxiv.org/pdf/1803.10311v2"
    },
    {
        "title": "Julia Language in Machine Learning: Algorithms, Applications, and Open   Issues",
        "abstract": "Machine learning is driving development across many fields in science and engineering. A simple and efficient programming language could accelerate applications of machine learning in various fields. Currently, the programming languages most commonly used to develop machine learning algorithms include Python, MATLAB, and C/C ++. However, none of these languages well balance both efficiency and simplicity. The Julia language is a fast, easy-to-use, and open-source programming language that was originally designed for high-performance computing, which can well balance the efficiency and simplicity. This paper summarizes the related research work and developments in the application of the Julia language in machine learning. It first surveys the popular machine learning algorithms that are developed in the Julia language. Then, it investigates applications of the machine learning algorithms implemented with the Julia language. Finally, it discusses the open issues and the potential future directions that arise in the use of the Julia language in machine learning.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2003.10146v2",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Kaifeng Gao",
            "Gang Mei",
            "Francesco Piccialli",
            "Salvatore Cuomo",
            "Jingzhi Tu",
            "Zenan Huo"
        ],
        "pdf_url": "http://arxiv.org/pdf/2003.10146v2"
    },
    {
        "title": "Can Machine Learning be Moral?",
        "abstract": "The ethics of Machine Learning has become an unavoidable topic in the AI Community. The deployment of machine learning systems in multiple social contexts has resulted in a closer ethical scrutiny of the design, development, and application of these systems. The AI/ML community has come to terms with the imperative to think about the ethical implications of machine learning, not only as a product but also as a practice (Birhane, 2021; Shen et al. 2021). The critical question that is troubling many debates is what can constitute an ethically accountable machine learning system. In this paper we explore possibilities for ethical evaluation of machine learning methodologies. We scrutinize techniques, methods and technical practices in machine learning from a relational ethics perspective, taking into consideration how machine learning systems are part of the world and how they relate to different forms of agency. Taking a page from Phil Agre (1997) we use the notion of a critical technical practice as a means of analysis of machine learning approaches. Our radical proposal is that supervised learning appears to be the only machine learning method that is ethically defensible.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2201.06921v1",
        "keywords": "cs.CY, cs.HC",
        "subject_areas": "cs.CY, cs.HC",
        "authors": [
            "Miguel Sicart",
            "Irina Shklovski",
            "Mirabelle Jones"
        ],
        "pdf_url": "http://arxiv.org/pdf/2201.06921v1"
    },
    {
        "title": "Machine Learning Interpretability: A Science rather than a tool",
        "abstract": "The term \"interpretability\" is oftenly used by machine learning researchers each with their own intuitive understanding of it. There is no universal well agreed upon definition of interpretability in machine learning. As any type of science discipline is mainly driven by the set of formulated questions rather than by different tools in that discipline, e.g. astrophysics is the discipline that learns the composition of stars, not as the discipline that use the spectroscopes. Similarly, we propose that machine learning interpretability should be a discipline that answers specific questions related to interpretability. These questions can be of statistical, causal and counterfactual nature. Therefore, there is a need to look into the interpretability problem of machine learning in the context of questions that need to be addressed rather than different tools. We discuss about a hypothetical interpretability framework driven by a question based scientific approach rather than some specific machine learning model. Using a question based notion of interpretability, we can step towards understanding the science of machine learning rather than its engineering. This notion will also help us understanding any specific problem more in depth rather than relying solely on machine learning methods.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1807.06722v2",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Abdul Karim",
            "Avinash Mishra",
            "MA Hakim Newton",
            "Abdul Sattar"
        ],
        "pdf_url": "http://arxiv.org/pdf/1807.06722v2"
    },
    {
        "title": "Practical Solutions for Machine Learning Safety in Autonomous Vehicles",
        "abstract": "Autonomous vehicles rely on machine learning to solve challenging tasks in perception and motion planning. However, automotive software safety standards have not fully evolved to address the challenges of machine learning safety such as interpretability, verification, and performance limitations. In this paper, we review and organize practical machine learning safety techniques that can complement engineering safety for machine learning based software in autonomous vehicles. Our organization maps safety strategies to state-of-the-art machine learning techniques in order to enhance dependability and safety of machine learning algorithms. We also discuss security limitations and user experience aspects of machine learning components in autonomous vehicles.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1912.09630v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Sina Mohseni",
            "Mandar Pitale",
            "Vasu Singh",
            "Zhangyang Wang"
        ],
        "pdf_url": "http://arxiv.org/pdf/1912.09630v1"
    },
    {
        "title": "Modeling Generalization in Machine Learning: A Methodological and   Computational Study",
        "abstract": "As machine learning becomes more and more available to the general public, theoretical questions are turning into pressing practical issues. Possibly, one of the most relevant concerns is the assessment of our confidence in trusting machine learning predictions. In many real-world cases, it is of utmost importance to estimate the capabilities of a machine learning algorithm to generalize, i.e., to provide accurate predictions on unseen data, depending on the characteristics of the target problem. In this work, we perform a meta-analysis of 109 publicly-available classification data sets, modeling machine learning generalization as a function of a variety of data set characteristics, ranging from number of samples to intrinsic dimensionality, from class-wise feature skewness to $F1$ evaluated on test samples falling outside the convex hull of the training set. Experimental results demonstrate the relevance of using the concept of the convex hull of the training data in assessing machine learning generalization, by emphasizing the difference between interpolated and extrapolated predictions. Besides several predictable correlations, we observe unexpectedly weak associations between the generalization ability of machine learning models and all metrics related to dimensionality, thus challenging the common assumption that the \\textit{curse of dimensionality} might impair generalization in machine learning.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2006.15680v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Pietro Barbiero",
            "Giovanni Squillero",
            "Alberto Tonda"
        ],
        "pdf_url": "http://arxiv.org/pdf/2006.15680v1"
    },
    {
        "title": "Automated Machine Learning on Graphs: A Survey",
        "abstract": "Machine learning on graphs has been extensively studied in both academic and industry. However, as the literature on graph learning booms with a vast number of emerging methods and techniques, it becomes increasingly difficult to manually design the optimal machine learning algorithm for different graph-related tasks. To solve this critical challenge, automated machine learning (AutoML) on graphs which combines the strength of graph machine learning and AutoML together, is gaining attention from the research community. Therefore, we comprehensively survey AutoML on graphs in this paper, primarily focusing on hyper-parameter optimization (HPO) and neural architecture search (NAS) for graph machine learning. We further overview libraries related to automated graph machine learning and in-depth discuss AutoGL, the first dedicated open-source library for AutoML on graphs. In the end, we share our insights on future research directions for automated graph machine learning. This paper is the first systematic and comprehensive review of automated machine learning on graphs to the best of our knowledge.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2103.00742v4",
        "keywords": "cs.LG",
        "subject_areas": "cs.LG",
        "authors": [
            "Ziwei Zhang",
            "Xin Wang",
            "Wenwu Zhu"
        ],
        "pdf_url": "http://arxiv.org/pdf/2103.00742v4"
    },
    {
        "title": "Mental Models of Adversarial Machine Learning",
        "abstract": "Although machine learning is widely used in practice, little is known about practitioners' understanding of potential security challenges. In this work, we close this substantial gap and contribute a qualitative study focusing on developers' mental models of the machine learning pipeline and potentially vulnerable components. Similar studies have helped in other security fields to discover root causes or improve risk communication. Our study reveals two \\facets of practitioners' mental models of machine learning security. Firstly, practitioners often confuse machine learning security with threats and defences that are not directly related to machine learning. Secondly, in contrast to most academic research, our participants perceive security of machine learning as not solely related to individual models, but rather in the context of entire workflows that consist of multiple components. Jointly with our additional findings, these two facets provide a foundation to substantiate mental models for machine learning security and have implications for the integration of adversarial machine learning into corporate workflows, \\new{decreasing practitioners' reported uncertainty}, and appropriate regulatory frameworks for machine learning security.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2105.03726v4",
        "keywords": "cs.CR, cs.AI",
        "subject_areas": "cs.CR, cs.AI",
        "authors": [
            "Lukas Bieringer",
            "Kathrin Grosse",
            "Michael Backes",
            "Battista Biggio",
            "Katharina Krombholz"
        ],
        "pdf_url": "http://arxiv.org/pdf/2105.03726v4"
    },
    {
        "title": "Scientific Machine Learning Benchmarks",
        "abstract": "The breakthrough in Deep Learning neural networks has transformed the use of AI and machine learning technologies for the analysis of very large experimental datasets. These datasets are typically generated by large-scale experimental facilities at national laboratories. In the context of science, scientific machine learning focuses on training machines to identify patterns, trends, and anomalies to extract meaningful scientific insights from such datasets. With a new generation of experimental facilities, the rate of data generation and the scale of data volumes will increasingly require the use of more automated data analysis. At present, identifying the most appropriate machine learning algorithm for the analysis of any given scientific dataset is still a challenge for scientists. This is due to many different machine learning frameworks, computer architectures, and machine learning models. Historically, for modelling and simulation on HPC systems such problems have been addressed through benchmarking computer applications, algorithms, and architectures. Extending such a benchmarking approach and identifying metrics for the application of machine learning methods to scientific datasets is a new challenge for both scientists and computer scientists. In this paper, we describe our approach to the development of scientific machine learning benchmarks and review other approaches to benchmarking scientific machine learning.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2110.12773v1",
        "keywords": "cs.LG, physics.comp-ph, I.2",
        "subject_areas": "cs.LG, physics.comp-ph, I.2",
        "authors": [
            "Jeyan Thiyagalingam",
            "Mallikarjun Shankar",
            "Geoffrey Fox",
            "Tony Hey"
        ],
        "pdf_url": "http://arxiv.org/pdf/2110.12773v1"
    },
    {
        "title": "Applying Machine Learning to Life Insurance: some knowledge sharing to   master it",
        "abstract": "Machine Learning permeates many industries, which brings new source of benefits for companies. However within the life insurance industry, Machine Learning is not widely used in practice as over the past years statistical models have shown their efficiency for risk assessment. Thus insurers may face difficulties to assess the value of the artificial intelligence. Focusing on the modification of the life insurance industry over time highlights the stake of using Machine Learning for insurers and benefits that it can bring by unleashing data value. This paper reviews traditional actuarial methodologies for survival modeling and extends them with Machine Learning techniques. It points out differences with regular machine learning models and emphasizes importance of specific implementations to face censored data with machine learning models family. In complement to this article, a Python library has been developed. Different open-source Machine Learning algorithms have been adjusted to adapt the specificities of life insurance data, namely censoring and truncation. Such models can be easily applied from this SCOR library to accurately model life insurance risks.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2209.02057v3",
        "keywords": "stat.ML, cs.CY, cs.LG, stat.AP",
        "subject_areas": "stat.ML, cs.CY, cs.LG, stat.AP",
        "authors": [
            "Antoine Chancel",
            "Laura Bradier",
            "Antoine Ly",
            "Razvan Ionescu",
            "Laurene Martin",
            "Marguerite Sauce"
        ],
        "pdf_url": "http://arxiv.org/pdf/2209.02057v3"
    },
    {
        "title": "Machine learning and domain decomposition methods -- a survey",
        "abstract": "Hybrid algorithms, which combine black-box machine learning methods with experience from traditional numerical methods and domain expertise from diverse application areas, are progressively gaining importance in scientific machine learning and various industrial domains, especially in computational science and engineering. In the present survey, several promising avenues of research will be examined which focus on the combination of machine learning (ML) and domain decomposition methods (DDMs). The aim of this survey is to provide an overview of existing work within this field and to structure it into domain decomposition for machine learning and machine learning-enhanced domain decomposition, including: domain decomposition for classical machine learning, domain decomposition to accelerate the training of physics-aware neural networks, machine learning to enhance the convergence properties or computational efficiency of DDMs, and machine learning as a discretization method in a DDM for the solution of PDEs. In each of these fields, we summarize existing work and key advances within a common framework and, finally, disuss ongoing challenges and opportunities for future research.",
        "publication_year": "2023",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2312.14050v1",
        "keywords": "math.NA, cs.LG, cs.NA, 65F10, 65N22, 65N55, 68T05, 68T07",
        "subject_areas": "math.NA, cs.LG, cs.NA, 65F10, 65N22, 65N55, 68T05, 68T07",
        "authors": [
            "Axel Klawonn",
            "Martin Lanser",
            "Janine Weber"
        ],
        "pdf_url": "http://arxiv.org/pdf/2312.14050v1"
    },
    {
        "title": "Beyond Model Interpretability: Socio-Structural Explanations in Machine   Learning",
        "abstract": "What is it to interpret the outputs of an opaque machine learning model. One approach is to develop interpretable machine learning techniques. These techniques aim to show how machine learning models function by providing either model centric local or global explanations, which can be based on mechanistic interpretations revealing the inner working mechanisms of models or nonmechanistic approximations showing input feature output data relationships. In this paper, we draw on social philosophy to argue that interpreting machine learning outputs in certain normatively salient domains could require appealing to a third type of explanation that we call sociostructural explanation. The relevance of this explanation type is motivated by the fact that machine learning models are not isolated entities but are embedded within and shaped by social structures. Sociostructural explanations aim to illustrate how social structures contribute to and partially explain the outputs of machine learning models. We demonstrate the importance of sociostructural explanations by examining a racially biased healthcare allocation algorithm. Our proposal highlights the need for transparency beyond model interpretability, understanding the outputs of machine learning systems could require a broader analysis that extends beyond the understanding of the machine learning model itself.",
        "publication_year": "2024",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2409.03632v1",
        "keywords": "cs.LG",
        "subject_areas": "cs.LG",
        "authors": [
            "Andrew Smart",
            "Atoosa Kasirzadeh"
        ],
        "pdf_url": "http://arxiv.org/pdf/2409.03632v1"
    },
    {
        "title": "Aspects of Artificial Intelligence: Transforming Machine Learning   Systems Naturally",
        "abstract": "In this paper, we study the machine learning elements which we are interested in together as a machine learning system, consisting of a collection of machine learning elements and a collection of relations between the elements. The relations we concern are algebraic operations, binary relations, and binary relations with composition that can be reasoned categorically. A machine learning system transformation between two systems is a map between the systems, which preserves the relations we concern. The system transformations given by quotient or clustering, representable functor, and Yoneda embedding are highlighted and discussed by machine learning examples. An adjunction between machine learning systems, a special machine learning system transformation loop, provides the optimal way of solving problems. Machine learning system transformations are linked and compared by their maps at 2-cell, natural transformations. New insights and structures can be obtained from universal properties and algebraic structures given by monads, which are generated from adjunctions.",
        "publication_year": "2025",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2502.01708v1",
        "keywords": "cs.LG, cs.AI, cs.DB, cs.DM",
        "subject_areas": "cs.LG, cs.AI, cs.DB, cs.DM",
        "authors": [
            "Xiuzhan Guo"
        ],
        "pdf_url": "http://arxiv.org/pdf/2502.01708v1"
    },
    {
        "title": "Domain Knowledge in Artificial Intelligence: Using Conceptual Modeling   to Increase Machine Learning Accuracy and Explainability",
        "abstract": "Machine learning enables the extraction of useful information from large, diverse datasets. However, despite many successful applications, machine learning continues to suffer from performance and transparency issues. These challenges can be partially attributed to the limited use of domain knowledge by machine learning models. This research proposes using the domain knowledge represented in conceptual models to improve the preparation of the data used to train machine learning models. We develop and demonstrate a method, called the Conceptual Modeling for Machine Learning (CMML), which is comprised of guidelines for data preparation in machine learning and based on conceptual modeling constructs and principles. To assess the impact of CMML on machine learning outcomes, we first applied it to two real-world problems to evaluate its impact on model performance. We then solicited an assessment by data scientists on the applicability of the method. These results demonstrate the value of CMML for improving machine learning outcomes.",
        "publication_year": "2025",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2507.02922v1",
        "keywords": "cs.LG, cs.HC",
        "subject_areas": "cs.LG, cs.HC",
        "authors": [
            "V. C. Storey",
            "J. Parsons",
            "A. Castellanos",
            "M. Tremblay",
            "R. Lukyanenko",
            "W. Maass",
            "A. Castillo"
        ],
        "pdf_url": "http://arxiv.org/pdf/2507.02922v1"
    },
    {
        "title": "A systematic review of fuzzing based on machine learning techniques",
        "abstract": "Security vulnerabilities play a vital role in network security system. Fuzzing technology is widely used as a vulnerability discovery technology to reduce damage in advance. However, traditional fuzzing techniques have many challenges, such as how to mutate input seed files, how to increase code coverage, and how to effectively bypass verification. Machine learning technology has been introduced as a new method into fuzzing test to alleviate these challenges. This paper reviews the research progress of using machine learning technology for fuzzing test in recent years, analyzes how machine learning improve the fuzz process and results, and sheds light on future work in fuzzing. Firstly, this paper discusses the reasons why machine learning techniques can be used for fuzzing scenarios and identifies six different stages in which machine learning have been used. Then this paper systematically study the machine learning based fuzzing models from selection of machine learning algorithm, pre-processing methods, datasets, evaluation metrics, and hyperparameters setting. Next, this paper assesses the performance of the machine learning models based on the frequently used evaluation metrics. The results of the evaluation prove that machine learning technology has an acceptable capability of categorize predictive for fuzzing. Finally, the comparison on capability of discovering vulnerabilities between traditional fuzzing tools and machine learning based fuzzing tools is analyzed. The results depict that the introduction of machine learning technology can improve the performance of fuzzing. However, there are still some limitations, such as unbalanced training samples and difficult to extract the characteristics related to vulnerabilities.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1908.01262v1",
        "keywords": "cs.CR, cs.LG",
        "subject_areas": "cs.CR, cs.LG",
        "authors": [
            "Yan Wang",
            "Peng Jia",
            "Luping Liu",
            "Jiayong Liu"
        ],
        "pdf_url": "http://arxiv.org/pdf/1908.01262v1"
    },
    {
        "title": "A Comparison of First-order Algorithms for Machine Learning",
        "abstract": "Using an optimization algorithm to solve a machine learning problem is one of mainstreams in the field of science. In this work, we demonstrate a comprehensive comparison of some state-of-the-art first-order optimization algorithms for convex optimization problems in machine learning. We concentrate on several smooth and non-smooth machine learning problems with a loss function plus a regularizer. The overall experimental results show the superiority of primal-dual algorithms in solving a machine learning problem from the perspectives of the ease to construct, running time and accuracy.",
        "publication_year": "2014",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1404.6674v1",
        "keywords": "cs.LG",
        "subject_areas": "cs.LG",
        "authors": [
            "Yu Wei",
            "Pock Thomas"
        ],
        "pdf_url": "http://arxiv.org/pdf/1404.6674v1"
    },
    {
        "title": "Meaningful Models: Utilizing Conceptual Structure to Improve Machine   Learning Interpretability",
        "abstract": "The last decade has seen huge progress in the development of advanced machine learning models; however, those models are powerless unless human users can interpret them. Here we show how the mind's construction of concepts and meaning can be used to create more interpretable machine learning models. By proposing a novel method of classifying concepts, in terms of 'form' and 'function', we elucidate the nature of meaning and offer proposals to improve model understandability. As machine learning begins to permeate daily life, interpretable models may serve as a bridge between domain-expert authors and non-expert users.",
        "publication_year": "2016",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1607.00279v1",
        "keywords": "stat.ML, cs.AI",
        "subject_areas": "stat.ML, cs.AI",
        "authors": [
            "Nick Condry"
        ],
        "pdf_url": "http://arxiv.org/pdf/1607.00279v1"
    },
    {
        "title": "An Aggregate and Iterative Disaggregate Algorithm with Proven Optimality   in Machine Learning",
        "abstract": "We propose a clustering-based iterative algorithm to solve certain optimization problems in machine learning, where we start the algorithm by aggregating the original data, solving the problem on aggregated data, and then in subsequent steps gradually disaggregate the aggregated data. We apply the algorithm to common machine learning problems such as the least absolute deviation regression problem, support vector machines, and semi-supervised support vector machines. We derive model-specific data aggregation and disaggregation procedures. We also show optimality, convergence, and the optimality gap of the approximated solution in each iteration. A computational study is provided.",
        "publication_year": "2016",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1607.01400v1",
        "keywords": "stat.ML, cs.LG",
        "subject_areas": "stat.ML, cs.LG",
        "authors": [
            "Young Woong Park",
            "Diego Klabjan"
        ],
        "pdf_url": "http://arxiv.org/pdf/1607.01400v1"
    },
    {
        "title": "TF.Learn: TensorFlow's High-level Module for Distributed Machine   Learning",
        "abstract": "TF.Learn is a high-level Python module for distributed machine learning inside TensorFlow. It provides an easy-to-use Scikit-learn style interface to simplify the process of creating, configuring, training, evaluating, and experimenting a machine learning model. TF.Learn integrates a wide range of state-of-art machine learning algorithms built on top of TensorFlow's low level APIs for small to large-scale supervised and unsupervised problems. This module focuses on bringing machine learning to non-specialists using a general-purpose high-level language as well as researchers who want to implement, benchmark, and compare their new methods in a structured environment. Emphasis is put on ease of use, performance, documentation, and API consistency.",
        "publication_year": "2016",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1612.04251v1",
        "keywords": "cs.DC, cs.LG",
        "subject_areas": "cs.DC, cs.LG",
        "authors": [
            "Yuan Tang"
        ],
        "pdf_url": "http://arxiv.org/pdf/1612.04251v1"
    },
    {
        "title": "Optimal Algorithms for Ski Rental with Soft Machine-Learned Predictions",
        "abstract": "We consider a variant of the classic Ski Rental online algorithm with applications to machine learning. In our variant, we allow the skier access to a black-box machine-learning algorithm that provides an estimate of the probability that there will be at most a threshold number of ski-days. We derive a class of optimal randomized algorithms to determine the strategy that minimizes the worst-case expected competitive ratio for the skier given a prediction from the machine learning algorithm,and analyze the performance and robustness of these algorithms.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1903.00092v2",
        "keywords": "cs.LG, cs.DS, stat.ML",
        "subject_areas": "cs.LG, cs.DS, stat.ML",
        "authors": [
            "Rohan Kodialam"
        ],
        "pdf_url": "http://arxiv.org/pdf/1903.00092v2"
    },
    {
        "title": "Towards Quantification of Bias in Machine Learning for Healthcare: A   Case Study of Renal Failure Prediction",
        "abstract": "As machine learning (ML) models, trained on real-world datasets, become common practice, it is critical to measure and quantify their potential biases. In this paper, we focus on renal failure and compare a commonly used traditional risk score, Tangri, with a more powerful machine learning model, which has access to a larger variable set and trained on 1.6 million patients' EHR data. We will compare and discuss the generalization and applicability of these two models, in an attempt to quantify biases of status quo clinical practice, compared to ML-driven models.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1911.07679v1",
        "keywords": "cs.LG, stat.AP, stat.ML",
        "subject_areas": "cs.LG, stat.AP, stat.ML",
        "authors": [
            "Josie Williams",
            "Narges Razavian"
        ],
        "pdf_url": "http://arxiv.org/pdf/1911.07679v1"
    },
    {
        "title": "On the computation of counterfactual explanations -- A survey",
        "abstract": "Due to the increasing use of machine learning in practice it becomes more and more important to be able to explain the prediction and behavior of machine learning models. An instance of explanations are counterfactual explanations which provide an intuitive and useful explanations of machine learning models. In this survey we review model-specific methods for efficiently computing counterfactual explanations of many different machine learning models and propose methods for models that have not been considered in literature so far.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1911.07749v1",
        "keywords": "cs.LG, cs.AI, stat.ML",
        "subject_areas": "cs.LG, cs.AI, stat.ML",
        "authors": [
            "André Artelt",
            "Barbara Hammer"
        ],
        "pdf_url": "http://arxiv.org/pdf/1911.07749v1"
    },
    {
        "title": "Computer Systems Have 99 Problems, Let's Not Make Machine Learning   Another One",
        "abstract": "Machine learning techniques are finding many applications in computer systems, including many tasks that require decision making: network optimization, quality of service assurance, and security. We believe machine learning systems are here to stay, and to materialize on their potential we advocate a fresh look at various key issues that need further attention, including security as a requirement and system complexity, and how machine learning systems affect them. We also discuss reproducibility as a key requirement for sustainable machine learning systems, and leads to pursuing it.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1911.12593v1",
        "keywords": "cs.CY, cs.CR, cs.LG",
        "subject_areas": "cs.CY, cs.CR, cs.LG",
        "authors": [
            "David Mohaisen",
            "Songqing Chen"
        ],
        "pdf_url": "http://arxiv.org/pdf/1911.12593v1"
    },
    {
        "title": "Application of Machine Learning Techniques in Aquaculture",
        "abstract": "In this paper we present applications of different machine learning algorithms in aquaculture. Machine learning algorithms learn models from historical data. In aquaculture historical data are obtained from farm practices, yields, and environmental data sources. Associations between these different variables can be obtained by applying machine learning algorithms to historical data. In this paper we present applications of different machine learning algorithms in aquaculture applications.",
        "publication_year": "2014",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1405.1304v1",
        "keywords": "cs.CE, cs.LG",
        "subject_areas": "cs.CE, cs.LG",
        "authors": [
            "Akhlaqur Rahman",
            "Sumaira Tasnim"
        ],
        "pdf_url": "http://arxiv.org/pdf/1405.1304v1"
    },
    {
        "title": "Machine Learning in Official Statistics",
        "abstract": "In the first half of 2018, the Federal Statistical Office of Germany (Destatis) carried out a \"Proof of Concept Machine Learning\" as part of its Digital Agenda. A major component of this was surveys on the use of machine learning methods in official statistics, which were conducted at selected national and international statistical institutions and among the divisions of Destatis. It was of particular interest to find out in which statistical areas and for which tasks machine learning is used and which methods are applied. This paper is intended to make the results of the surveys publicly accessible.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1812.10422v1",
        "keywords": "cs.CY, cs.LG, stat.ML",
        "subject_areas": "cs.CY, cs.LG, stat.ML",
        "authors": [
            "Martin Beck",
            "Florian Dumpert",
            "Joerg Feuerhake"
        ],
        "pdf_url": "http://arxiv.org/pdf/1812.10422v1"
    },
    {
        "title": "Efficient Private Machine Learning by Differentiable Random   Transformations",
        "abstract": "With the increasing demands for privacy protection, many privacy-preserving machine learning systems were proposed in recent years. However, most of them cannot be put into production due to their slow training and inference speed caused by the heavy cost of homomorphic encryption and secure multiparty computation(MPC) methods. To circumvent this, I proposed a privacy definition which is suitable for large amount of data in machine learning tasks. Based on that, I showed that random transformations like linear transformation and random permutation can well protect privacy. Merging random transformations and arithmetic sharing together, I designed a framework for private machine learning with high efficiency and low computation cost.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2008.07758v1",
        "keywords": "cs.CR, cs.LG, stat.ML",
        "subject_areas": "cs.CR, cs.LG, stat.ML",
        "authors": [
            "Fei Zheng"
        ],
        "pdf_url": "http://arxiv.org/pdf/2008.07758v1"
    },
    {
        "title": "Energy-Harvesting Distributed Machine Learning",
        "abstract": "This paper provides a first study of utilizing energy harvesting for sustainable machine learning in distributed networks. We consider a distributed learning setup in which a machine learning model is trained over a large number of devices that can harvest energy from the ambient environment, and develop a practical learning framework with theoretical convergence guarantees. We demonstrate through numerical experiments that the proposed framework can significantly outperform energy-agnostic benchmarks. Our framework is scalable, requires only local estimation of the energy statistics, and can be applied to a wide range of distributed training settings, including machine learning in wireless networks, edge computing, and mobile internet of things.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2102.05639v1",
        "keywords": "cs.LG, cs.IT, math.IT, stat.ML",
        "subject_areas": "cs.LG, cs.IT, math.IT, stat.ML",
        "authors": [
            "Basak Guler",
            "Aylin Yener"
        ],
        "pdf_url": "http://arxiv.org/pdf/2102.05639v1"
    },
    {
        "title": "Seven Myths in Machine Learning Research",
        "abstract": "We present seven myths commonly believed to be true in machine learning research, circa Feb 2019. This is an archival copy of the blog post at https://crazyoscarchang.github.io/2019/02/16/seven-myths-in-machine-learning-research/   Myth 1: TensorFlow is a Tensor manipulation library   Myth 2: Image datasets are representative of real images found in the wild   Myth 3: Machine Learning researchers do not use the test set for validation   Myth 4: Every datapoint is used in training a neural network   Myth 5: We need (batch) normalization to train very deep residual networks   Myth 6: Attention $>$ Convolution   Myth 7: Saliency maps are robust ways to interpret neural networks",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1902.06789v2",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Oscar Chang",
            "Hod Lipson"
        ],
        "pdf_url": "http://arxiv.org/pdf/1902.06789v2"
    },
    {
        "title": "Using Deep Learning and Machine Learning to Detect Epileptic Seizure   with Electroencephalography (EEG) Data",
        "abstract": "The prediction of epileptic seizure has always been extremely challenging in medical domain. However, as the development of computer technology, the application of machine learning introduced new ideas for seizure forecasting. Applying machine learning model onto the predication of epileptic seizure could help us obtain a better result and there have been plenty of scientists who have been doing such works so that there are sufficient medical data provided for researchers to do training of machine learning models.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1910.02544v1",
        "keywords": "cs.LG, eess.SP, stat.ML",
        "subject_areas": "cs.LG, eess.SP, stat.ML",
        "authors": [
            "Haotian Liu",
            "Lin Xi",
            "Ying Zhao",
            "Zhixiang Li"
        ],
        "pdf_url": "http://arxiv.org/pdf/1910.02544v1"
    },
    {
        "title": "Addressing Privacy Threats from Machine Learning",
        "abstract": "Every year at NeurIPS, machine learning researchers gather and discuss exciting applications of machine learning in areas such as public health, disaster response, climate change, education, and more. However, many of these same researchers are expressing growing concern about applications of machine learning for surveillance (Nanayakkara et al., 2021). This paper presents a brief overview of strategies for resisting these surveillance technologies and calls for greater collaboration between machine learning and human-computer interaction researchers to address the threats that these technologies pose.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2111.04439v1",
        "keywords": "cs.CY, cs.CR, cs.LG",
        "subject_areas": "cs.CY, cs.CR, cs.LG",
        "authors": [
            "Mary Anne Smart"
        ],
        "pdf_url": "http://arxiv.org/pdf/2111.04439v1"
    },
    {
        "title": "Machine Learning in Network Security Using KNIME Analytics",
        "abstract": "Machine learning has more and more effect on our every day's life. This field keeps growing and expanding into new areas. Machine learning is based on the implementation of artificial intelligence that gives systems the capability to automatically learn and enhance from experiments without being explicitly programmed. Machine Learning algorithms apply mathematical equations to analyze datasets and predict values based on the dataset. In the field of cybersecurity, machine learning algorithms can be utilized to train and analyze the Intrusion Detection Systems (IDSs) on security-related datasets. In this paper, we tested different machine learning algorithms to analyze NSL-KDD dataset using KNIME analytics.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2001.11489v1",
        "keywords": "cs.CR",
        "subject_areas": "cs.CR",
        "authors": [
            "Munther Abualkibash"
        ],
        "pdf_url": "http://arxiv.org/pdf/2001.11489v1"
    },
    {
        "title": "When Machine Learning Meets Multiscale Modeling in Chemical Reactions",
        "abstract": "Due to the intrinsic complexity and nonlinearity of chemical reactions, direct applications of traditional machine learning algorithms may face with many difficulties. In this study, through two concrete examples with biological background, we illustrate how the key ideas of multiscale modeling can help to reduce the computational cost of machine learning a lot, as well as how machine learning algorithms perform model reduction automatically in a time-scale separated system. Our study highlights the necessity and effectiveness of an integration of machine learning algorithms and multiscale modeling during the study of chemical reactions.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2006.00700v1",
        "keywords": "q-bio.MN, cs.LG",
        "subject_areas": "q-bio.MN, cs.LG",
        "authors": [
            "Wuyue Yang",
            "Liangrong Peng",
            "Yi Zhu",
            "Liu Hong"
        ],
        "pdf_url": "http://arxiv.org/pdf/2006.00700v1"
    },
    {
        "title": "Distributed Double Machine Learning with a Serverless Architecture",
        "abstract": "This paper explores serverless cloud computing for double machine learning. Being based on repeated cross-fitting, double machine learning is particularly well suited to exploit the high level of parallelism achievable with serverless computing. It allows to get fast on-demand estimations without additional cloud maintenance effort. We provide a prototype Python implementation \\texttt{DoubleML-Serverless} for the estimation of double machine learning models with the serverless computing platform AWS Lambda and demonstrate its utility with a case study analyzing estimation times and costs.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2101.04025v2",
        "keywords": "cs.DC, cs.LG, stat.ML",
        "subject_areas": "cs.DC, cs.LG, stat.ML",
        "authors": [
            "Malte S. Kurz"
        ],
        "pdf_url": "http://arxiv.org/pdf/2101.04025v2"
    },
    {
        "title": "SELM: Software Engineering of Machine Learning Models",
        "abstract": "One of the pillars of any machine learning model is its concepts. Using software engineering, we can engineer these concepts and then develop and expand them. In this article, we present a SELM framework for Software Engineering of machine Learning Models. We then evaluate this framework through a case study. Using the SELM framework, we can improve a machine learning process efficiency and provide more accuracy in learning with less processing hardware resources and a smaller training dataset. This issue highlights the importance of an interdisciplinary approach to machine learning. Therefore, in this article, we have provided interdisciplinary teams' proposals for machine learning.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2103.11249v1",
        "keywords": "cs.SE, cs.AI",
        "subject_areas": "cs.SE, cs.AI",
        "authors": [
            "Nafiseh Jafari",
            "Mohammad Reza Besharati",
            "Mohammad Izadi",
            "Maryam Hourali"
        ],
        "pdf_url": "http://arxiv.org/pdf/2103.11249v1"
    },
    {
        "title": "Human-in-the-loop Machine Learning: A Macro-Micro Perspective",
        "abstract": "Though technical advance of artificial intelligence and machine learning has enabled many promising intelligent systems, many computing tasks are still not able to be fully accomplished by machine intelligence. Motivated by the complementary nature of human and machine intelligence, an emerging trend is to involve humans in the loop of machine learning and decision-making. In this paper, we provide a macro-micro review of human-in-the-loop machine learning. We first describe major machine learning challenges which can be addressed by human intervention in the loop. Then we examine closely the latest research and findings of introducing humans into each step of the lifecycle of machine learning. Finally, we analyze current research gaps and point out future research directions.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2202.10564v1",
        "keywords": "cs.HC",
        "subject_areas": "cs.HC",
        "authors": [
            "Jiangtao Wang",
            "Bin Guo",
            "Liming Chen"
        ],
        "pdf_url": "http://arxiv.org/pdf/2202.10564v1"
    },
    {
        "title": "Categories of Differentiable Polynomial Circuits for Machine Learning",
        "abstract": "Reverse derivative categories (RDCs) have recently been shown to be a suitable semantic framework for studying machine learning algorithms. Whereas emphasis has been put on training methodologies, less attention has been devoted to particular \\emph{model classes}: the concrete categories whose morphisms represent machine learning models. In this paper we study presentations by generators and equations of classes of RDCs. In particular, we propose \\emph{polynomial circuits} as a suitable machine learning model. We give an axiomatisation for these circuits and prove a functional completeness result. Finally, we discuss the use of polynomial circuits over specific semirings to perform machine learning with discrete values.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2203.06430v2",
        "keywords": "cs.LG, math.CT",
        "subject_areas": "cs.LG, math.CT",
        "authors": [
            "Paul Wilson",
            "Fabio Zanasi"
        ],
        "pdf_url": "http://arxiv.org/pdf/2203.06430v2"
    },
    {
        "title": "When Physics Meets Machine Learning: A Survey of Physics-Informed   Machine Learning",
        "abstract": "Physics-informed machine learning (PIML), referring to the combination of prior knowledge of physics, which is the high level abstraction of natural phenomenons and human behaviours in the long history, with data-driven machine learning models, has emerged as an effective way to mitigate the shortage of training data, to increase models' generalizability and to ensure the physical plausibility of results. In this paper, we survey an abundant number of recent works in PIML and summarize them from three aspects: (1) motivations of PIML, (2) physics knowledge in PIML, (3) methods of physics knowledge integration in PIML. We also discuss current challenges and corresponding research opportunities in PIML.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2203.16797v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Chuizheng Meng",
            "Sungyong Seo",
            "Defu Cao",
            "Sam Griesemer",
            "Yan Liu"
        ],
        "pdf_url": "http://arxiv.org/pdf/2203.16797v1"
    },
    {
        "title": "Parallelization of Machine Learning Algorithms Respectively on Single   Machine and Spark",
        "abstract": "With the rapid development of big data technologies, how to dig out useful information from massive data becomes an essential problem. However, using machine learning algorithms to analyze large data may be time-consuming and inefficient on the traditional single machine. To solve these problems, this paper has made some research on the parallelization of several classic machine learning algorithms respectively on the single machine and the big data platform Spark. We compare the runtime and efficiency of traditional machine learning algorithms with parallelized machine learning algorithms respectively on the single machine and Spark platform. The research results have shown significant improvement in runtime and efficiency of parallelized machine learning algorithms.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2206.07090v2",
        "keywords": "cs.DC",
        "subject_areas": "cs.DC",
        "authors": [
            "Jiajun Shen"
        ],
        "pdf_url": "http://arxiv.org/pdf/2206.07090v2"
    },
    {
        "title": "Challenges and Opportunities in Quantum Machine Learning",
        "abstract": "At the intersection of machine learning and quantum computing, Quantum Machine Learning (QML) has the potential of accelerating data analysis, especially for quantum data, with applications for quantum materials, biochemistry, and high-energy physics. Nevertheless, challenges remain regarding the trainability of QML models. Here we review current methods and applications for QML. We highlight differences between quantum and classical machine learning, with a focus on quantum neural networks and quantum deep learning. Finally, we discuss opportunities for quantum advantage with QML.",
        "publication_year": "2023",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2303.09491v1",
        "keywords": "quant-ph, cs.LG, stat.ML",
        "subject_areas": "quant-ph, cs.LG, stat.ML",
        "authors": [
            "M. Cerezo",
            "Guillaume Verdon",
            "Hsin-Yuan Huang",
            "Lukasz Cincio",
            "Patrick J. Coles"
        ],
        "pdf_url": "http://arxiv.org/pdf/2303.09491v1"
    },
    {
        "title": "Nine tips for ecologists using machine learning",
        "abstract": "Due to their high predictive performance and flexibility, machine learning models are an appropriate and efficient tool for ecologists. However, implementing a machine learning model is not yet a trivial task and may seem intimidating to ecologists with no previous experience in this area. Here we provide a series of tips to help ecologists in implementing machine learning models. We focus on classification problems as many ecological studies aim to assign data into predefined classes such as ecological states or biological entities. Each of the nine tips identifies a common error, trap or challenge in developing machine learning models and provides recommendations to facilitate their use in ecological studies.",
        "publication_year": "2023",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2305.10472v2",
        "keywords": "q-bio.PE, cs.LG",
        "subject_areas": "q-bio.PE, cs.LG",
        "authors": [
            "Marine Desprez",
            "Vincent Miele",
            "Olivier Gimenez"
        ],
        "pdf_url": "http://arxiv.org/pdf/2305.10472v2"
    },
    {
        "title": "A Comparison of Machine Learning Methods for Data with High-Cardinality   Categorical Variables",
        "abstract": "High-cardinality categorical variables are variables for which the number of different levels is large relative to the sample size of a data set, or in other words, there are few data points per level. Machine learning methods can have difficulties with high-cardinality variables. In this article, we empirically compare several versions of two of the most successful machine learning methods, tree-boosting and deep neural networks, and linear mixed effects models using multiple tabular data sets with high-cardinality categorical variables. We find that, first, machine learning models with random effects have higher prediction accuracy than their classical counterparts without random effects, and, second, tree-boosting with random effects outperforms deep neural networks with random effects.",
        "publication_year": "2023",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2307.02071v1",
        "keywords": "cs.LG, cs.AI, stat.ML",
        "subject_areas": "cs.LG, cs.AI, stat.ML",
        "authors": [
            "Fabio Sigrist"
        ],
        "pdf_url": "http://arxiv.org/pdf/2307.02071v1"
    },
    {
        "title": "Machine learning for accuracy in density functional approximations",
        "abstract": "Machine learning techniques have found their way into computational chemistry as indispensable tools to accelerate atomistic simulations and materials design. In addition, machine learning approaches hold the potential to boost the predictive power of computationally efficient electronic structure methods, such as density functional theory, to chemical accuracy and to correct for fundamental errors in density functional approaches. Here, recent progress in applying machine learning to improve the accuracy of density functional and related approximations is reviewed. Promises and challenges in devising machine learning models transferable between different chemistries and materials classes are discussed with the help of examples applying promising models to systems far outside their training sets.",
        "publication_year": "2023",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2311.00196v1",
        "keywords": "physics.chem-ph, cs.LG",
        "subject_areas": "physics.chem-ph, cs.LG",
        "authors": [
            "Johannes Voss"
        ],
        "pdf_url": "http://arxiv.org/pdf/2311.00196v1"
    },
    {
        "title": "Improving Radiography Machine Learning Workflows via Metadata Management   for Training Data Selection",
        "abstract": "Most machine learning models require many iterations of hyper-parameter tuning, feature engineering, and debugging to produce effective results. As machine learning models become more complicated, this pipeline becomes more difficult to manage effectively. In the physical sciences, there is an ever-increasing pool of metadata that is generated by the scientific research cycle. Tracking this metadata can reduce redundant work, improve reproducibility, and aid in the feature and training dataset engineering process. In this case study, we present a tool for machine learning metadata management in dynamic radiography. We evaluate the efficacy of this tool against the initial research workflow and discuss extensions to general machine learning pipelines in the physical sciences.",
        "publication_year": "2024",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2408.12655v1",
        "keywords": "cs.LG, cs.HC",
        "subject_areas": "cs.LG, cs.HC",
        "authors": [
            "Mirabel Reid",
            "Christine Sweeney",
            "Oleg Korobkin"
        ],
        "pdf_url": "http://arxiv.org/pdf/2408.12655v1"
    },
    {
        "title": "A method to benchmark high-dimensional process drift detection",
        "abstract": "Process curves are multivariate finite time series data coming from manufacturing processes. This paper studies machine learning that detect drifts in process curve datasets. A theoretic framework to synthetically generate process curves in a controlled way is introduced in order to benchmark machine learning algorithms for process drift detection. An evaluation score, called the temporal area under the curve, is introduced, which allows to quantify how well machine learning models unveil curves belonging to drift segments. Finally, a benchmark study comparing popular machine learning approaches on synthetic data generated with the introduced framework is presented that shows that existing algorithms often struggle with datasets containing multiple drift segments.",
        "publication_year": "2024",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2409.03669v2",
        "keywords": "stat.ML, cs.AI, cs.LG",
        "subject_areas": "stat.ML, cs.AI, cs.LG",
        "authors": [
            "Edgar Wolf",
            "Tobias Windisch"
        ],
        "pdf_url": "http://arxiv.org/pdf/2409.03669v2"
    },
    {
        "title": "Inverse Problems and Data Assimilation: A Machine Learning Approach",
        "abstract": "The aim of these notes is to demonstrate the potential for ideas in machine learning to impact on the fields of inverse problems and data assimilation. The perspective is one that is primarily aimed at researchers from inverse problems and/or data assimilation who wish to see a mathematical presentation of machine learning as it pertains to their fields. As a by-product, we include a succinct mathematical treatment of various topics in machine learning.",
        "publication_year": "2024",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2410.10523v1",
        "keywords": "stat.ML, cs.LG, math.OC",
        "subject_areas": "stat.ML, cs.LG, math.OC",
        "authors": [
            "Eviatar Bach",
            "Ricardo Baptista",
            "Daniel Sanz-Alonso",
            "Andrew Stuart"
        ],
        "pdf_url": "http://arxiv.org/pdf/2410.10523v1"
    },
    {
        "title": "Proceedings of NIPS 2016 Workshop on Interpretable Machine Learning for   Complex Systems",
        "abstract": "This is the Proceedings of NIPS 2016 Workshop on Interpretable Machine Learning for Complex Systems, held in Barcelona, Spain on December 9, 2016",
        "publication_year": "2016",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1611.09139v1",
        "keywords": "stat.ML",
        "subject_areas": "stat.ML",
        "authors": [
            "Andrew Gordon Wilson",
            "Been Kim",
            "William Herlands"
        ],
        "pdf_url": "http://arxiv.org/pdf/1611.09139v1"
    },
    {
        "title": "Classifying medical notes into standard disease codes using Machine   Learning",
        "abstract": "We investigate the automatic classification of patient discharge notes into standard disease labels. We find that Convolutional Neural Networks with Attention outperform previous algorithms used in this task, and suggest further areas for improvement.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1802.00382v1",
        "keywords": "cs.LG, cs.CL, stat.AP, stat.ML",
        "subject_areas": "cs.LG, cs.CL, stat.AP, stat.ML",
        "authors": [
            "Amitabha Karmakar"
        ],
        "pdf_url": "http://arxiv.org/pdf/1802.00382v1"
    },
    {
        "title": "Minimax deviation strategies for machine learning and recognition with   short learning samples",
        "abstract": "The article is devoted to the problem of small learning samples in machine learning. The flaws of maximum likelihood learning and minimax learning are looked into and the concept of minimax deviation learning is introduced that is free of those flaws.",
        "publication_year": "2017",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1707.04849v1",
        "keywords": "cs.LG",
        "subject_areas": "cs.LG",
        "authors": [
            "Michail Schlesinger",
            "Evgeniy Vodolazskiy"
        ],
        "pdf_url": "http://arxiv.org/pdf/1707.04849v1"
    },
    {
        "title": "Engineering problems in machine learning systems",
        "abstract": "Fatal accidents are a major issue hindering the wide acceptance of safety-critical systems that employ machine learning and deep learning models, such as automated driving vehicles. In order to use machine learning in a safety-critical system, it is necessary to demonstrate the safety and security of the system through engineering processes. However, thus far, no such widely accepted engineering concepts or frameworks have been established for these systems. The key to using a machine learning model in a deductively engineered system is decomposing the data-driven training of machine learning models into requirement, design, and verification, particularly for machine learning models used in safety-critical systems. Simultaneously, open problems and relevant technical fields are not organized in a manner that enables researchers to select a theme and work on it. In this study, we identify, classify, and explore the open problems in engineering (safety-critical) machine learning systems --- that is, in terms of requirement, design, and verification of machine learning models and systems --- as well as discuss related works and research directions, using automated driving vehicles as an example. Our results show that machine learning models are characterized by a lack of requirements specification, lack of design specification, lack of interpretability, and lack of robustness. We also perform a gap analysis on a conventional system quality standard SQuARE with the characteristics of machine learning models to study quality models for machine learning systems. We find that a lack of requirements specification and lack of robustness have the greatest impact on conventional quality models.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1904.00001v2",
        "keywords": "cs.SE, cs.LG",
        "subject_areas": "cs.SE, cs.LG",
        "authors": [
            "Hiroshi Kuwajima",
            "Hirotoshi Yasuoka",
            "Toshihiro Nakae"
        ],
        "pdf_url": "http://arxiv.org/pdf/1904.00001v2"
    },
    {
        "title": "Automated Graph Machine Learning: Approaches, Libraries, Benchmarks and   Directions",
        "abstract": "Graph machine learning has been extensively studied in both academic and industry. However, as the literature on graph learning booms with a vast number of emerging methods and techniques, it becomes increasingly difficult to manually design the optimal machine learning algorithm for different graph-related tasks. To tackle the challenge, automated graph machine learning, which aims at discovering the best hyper-parameter and neural architecture configuration for different graph tasks/data without manual design, is gaining an increasing number of attentions from the research community. In this paper, we extensively discuss automated graph machine learning approaches, covering hyper-parameter optimization (HPO) and neural architecture search (NAS) for graph machine learning. We briefly overview existing libraries designed for either graph machine learning or automated machine learning respectively, and further in depth introduce AutoGL, our dedicated and the world's first open-source library for automated graph machine learning. Also, we describe a tailored benchmark that supports unified, reproducible, and efficient evaluations. Last but not least, we share our insights on future research directions for automated graph machine learning. This paper is the first systematic and comprehensive discussion of approaches, libraries as well as directions for automated graph machine learning.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2201.01288v2",
        "keywords": "cs.LG, cs.AI",
        "subject_areas": "cs.LG, cs.AI",
        "authors": [
            "Xin Wang",
            "Ziwei Zhang",
            "Haoyang Li",
            "Wenwu Zhu"
        ],
        "pdf_url": "http://arxiv.org/pdf/2201.01288v2"
    },
    {
        "title": "Detection of brain tumors using machine learning algorithms",
        "abstract": "An algorithm capable of processing NMR images was developed for analysis using machine learning techniques to detect the presence of brain tumors.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2201.04703v1",
        "keywords": "eess.IV, cs.LG",
        "subject_areas": "eess.IV, cs.LG",
        "authors": [
            "Horacio Corral",
            "Javier Melchor",
            "Balam Sotelo",
            "Jorge Vera"
        ],
        "pdf_url": "http://arxiv.org/pdf/2201.04703v1"
    },
    {
        "title": "Introduction to intelligent computing unit 1",
        "abstract": "This brief note highlights some basic concepts required toward understanding the evolution of machine learning and deep learning models. The note starts with an overview of artificial intelligence and its relationship to biological neuron that ultimately led to the evolution of todays intelligent models.",
        "publication_year": "2017",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1711.06552v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Isa Inuwa-Dutse"
        ],
        "pdf_url": "http://arxiv.org/pdf/1711.06552v1"
    },
    {
        "title": "Proceedings of NIPS 2017 Workshop on Machine Learning for the Developing   World",
        "abstract": "This is the Proceedings of NIPS 2017 Workshop on Machine Learning for the Developing World, held in Long Beach, California, USA on December 8, 2017",
        "publication_year": "2017",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1711.09522v2",
        "keywords": "stat.ML",
        "subject_areas": "stat.ML",
        "authors": [
            "Maria De-Arteaga",
            "William Herlands"
        ],
        "pdf_url": "http://arxiv.org/pdf/1711.09522v2"
    },
    {
        "title": "Linear, Machine Learning and Probabilistic Approaches for Time Series   Analysis",
        "abstract": "In this paper we study different approaches for time series modeling. The forecasting approaches using linear models, ARIMA alpgorithm, XGBoost machine learning algorithm are described. Results of different model combinations are shown. For probabilistic modeling the approaches using copulas and Bayesian inference are considered.",
        "publication_year": "2017",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1703.01977v1",
        "keywords": "stat.AP, cs.LG, stat.ME",
        "subject_areas": "stat.AP, cs.LG, stat.ME",
        "authors": [
            "B. M. Pavlyshenko"
        ],
        "pdf_url": "http://arxiv.org/pdf/1703.01977v1"
    },
    {
        "title": "Elements of effective machine learning datasets in astronomy",
        "abstract": "In this work, we identify elements of effective machine learning datasets in astronomy and present suggestions for their design and creation. Machine learning has become an increasingly important tool for analyzing and understanding the large-scale flood of data in astronomy. To take advantage of these tools, datasets are required for training and testing. However, building machine learning datasets for astronomy can be challenging. Astronomical data is collected from instruments built to explore science questions in a traditional fashion rather than to conduct machine learning. Thus, it is often the case that raw data, or even downstream processed data is not in a form amenable to machine learning. We explore the construction of machine learning datasets and we ask: what elements define effective machine learning datasets? We define effective machine learning datasets in astronomy to be formed with well-defined data points, structure, and metadata. We discuss why these elements are important for astronomical applications and ways to put them in practice. We posit that these qualities not only make the data suitable for machine learning, they also help to foster usable, reusable, and replicable science practices.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2211.14401v2",
        "keywords": "astro-ph.IM, cs.LG",
        "subject_areas": "astro-ph.IM, cs.LG",
        "authors": [
            "Bernie Boscoe",
            "Tuan Do",
            "Evan Jones",
            "Yunqi Li",
            "Kevin Alfaro",
            "Christy Ma"
        ],
        "pdf_url": "http://arxiv.org/pdf/2211.14401v2"
    },
    {
        "title": "Bridging belief function theory to modern machine learning",
        "abstract": "Machine learning is a quickly evolving field which now looks really different from what it was 15 years ago, when classification and clustering were major issues. This document proposes several trends to explore the new questions of modern machine learning, with the strong afterthought that the belief function framework has a major role to play.",
        "publication_year": "2015",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1504.03874v1",
        "keywords": "cs.AI, cs.LG",
        "subject_areas": "cs.AI, cs.LG",
        "authors": [
            "Thomas Burger"
        ],
        "pdf_url": "http://arxiv.org/pdf/1504.03874v1"
    },
    {
        "title": "Electre Tri-Machine Learning Approach to the Record Linkage Problem",
        "abstract": "In this short paper, the Electre Tri-Machine Learning Method, generally used to solve ordinal classification problems, is proposed for solving the Record Linkage problem. Preliminary experimental results show that, using the Electre Tri method, high accuracy can be achieved and more than 99% of the matches and nonmatches were correctly identified by the procedure.",
        "publication_year": "2015",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1505.06614v1",
        "keywords": "stat.ML, cs.LG",
        "subject_areas": "stat.ML, cs.LG",
        "authors": [
            "Renato De Leone",
            "Valentina Minnetti"
        ],
        "pdf_url": "http://arxiv.org/pdf/1505.06614v1"
    },
    {
        "title": "Model-Agnostic Interpretability of Machine Learning",
        "abstract": "Understanding why machine learning models behave the way they do empowers both system designers and end-users in many ways: in model selection, feature engineering, in order to trust and act upon the predictions, and in more intuitive user interfaces. Thus, interpretability has become a vital concern in machine learning, and work in the area of interpretable models has found renewed interest. In some applications, such models are as accurate as non-interpretable ones, and thus are preferred for their transparency. Even when they are not accurate, they may still be preferred when interpretability is of paramount importance. However, restricting machine learning to interpretable models is often a severe limitation. In this paper we argue for explaining machine learning predictions using model-agnostic approaches. By treating the machine learning models as black-box functions, these approaches provide crucial flexibility in the choice of models, explanations, and representations, improving debugging, comparison, and interfaces for a variety of users and models. We also outline the main challenges for such methods, and review a recently-introduced model-agnostic explanation approach (LIME) that addresses these challenges.",
        "publication_year": "2016",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1606.05386v1",
        "keywords": "stat.ML, cs.LG",
        "subject_areas": "stat.ML, cs.LG",
        "authors": [
            "Marco Tulio Ribeiro",
            "Sameer Singh",
            "Carlos Guestrin"
        ],
        "pdf_url": "http://arxiv.org/pdf/1606.05386v1"
    },
    {
        "title": "Proceedings of the 2016 ICML Workshop on Human Interpretability in   Machine Learning (WHI 2016)",
        "abstract": "This is the Proceedings of the 2016 ICML Workshop on Human Interpretability in Machine Learning (WHI 2016), which was held in New York, NY, June 23, 2016.   Invited speakers were Susan Athey, Rich Caruana, Jacob Feldman, Percy Liang, and Hanna Wallach.",
        "publication_year": "2016",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1607.02531v2",
        "keywords": "stat.ML, cs.LG",
        "subject_areas": "stat.ML, cs.LG",
        "authors": [
            "Been Kim",
            "Dmitry M. Malioutov",
            "Kush R. Varshney"
        ],
        "pdf_url": "http://arxiv.org/pdf/1607.02531v2"
    },
    {
        "title": "An Introduction to MM Algorithms for Machine Learning and Statistical",
        "abstract": "MM (majorization--minimization) algorithms are an increasingly popular tool for solving optimization problems in machine learning and statistical estimation. This article introduces the MM algorithm framework in general and via three popular example applications: Gaussian mixture regressions, multinomial logistic regressions, and support vector machines. Specific algorithms for the three examples are derived and numerical demonstrations are presented. Theoretical and practical aspects of MM algorithm design are discussed.",
        "publication_year": "2016",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1611.03969v1",
        "keywords": "stat.CO, cs.LG, stat.ML",
        "subject_areas": "stat.CO, cs.LG, stat.ML",
        "authors": [
            "Hien D. Nguyen"
        ],
        "pdf_url": "http://arxiv.org/pdf/1611.03969v1"
    },
    {
        "title": "Proceedings of the 2017 ICML Workshop on Human Interpretability in   Machine Learning (WHI 2017)",
        "abstract": "This is the Proceedings of the 2017 ICML Workshop on Human Interpretability in Machine Learning (WHI 2017), which was held in Sydney, Australia, August 10, 2017. Invited speakers were Tony Jebara, Pang Wei Koh, and David Sontag.",
        "publication_year": "2017",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1708.02666v1",
        "keywords": "stat.ML, cs.LG",
        "subject_areas": "stat.ML, cs.LG",
        "authors": [
            "Been Kim",
            "Dmitry M. Malioutov",
            "Kush R. Varshney",
            "Adrian Weller"
        ],
        "pdf_url": "http://arxiv.org/pdf/1708.02666v1"
    },
    {
        "title": "Privacy Preserving Machine Learning: Threats and Solutions",
        "abstract": "For privacy concerns to be addressed adequately in current machine learning systems, the knowledge gap between the machine learning and privacy communities must be bridged. This article aims to provide an introduction to the intersection of both fields with special emphasis on the techniques used to protect the data.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1804.11238v1",
        "keywords": "cs.CR, cs.LG",
        "subject_areas": "cs.CR, cs.LG",
        "authors": [
            "Mohammad Al-Rubaie",
            "J. Morris Chang"
        ],
        "pdf_url": "http://arxiv.org/pdf/1804.11238v1"
    },
    {
        "title": "Radiological images and machine learning: trends, perspectives, and   prospects",
        "abstract": "The application of machine learning to radiological images is an increasingly active research area that is expected to grow in the next five to ten years. Recent advances in machine learning have the potential to recognize and classify complex patterns from different radiological imaging modalities such as x-rays, computed tomography, magnetic resonance imaging and positron emission tomography imaging. In many applications, machine learning based systems have shown comparable performance to human decision-making. The applications of machine learning are the key ingredients of future clinical decision making and monitoring systems. This review covers the fundamental concepts behind various machine learning techniques and their applications in several radiological imaging areas, such as medical image segmentation, brain function studies and neurological disease diagnosis, as well as computer-aided systems, image registration, and content-based image retrieval systems. Synchronistically, we will briefly discuss current challenges and future directions regarding the application of machine learning in radiological imaging. By giving insight on how take advantage of machine learning powered applications, we expect that clinicians can prevent and diagnose diseases more accurately and efficiently.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1903.11726v1",
        "keywords": "eess.IV, cs.LG",
        "subject_areas": "eess.IV, cs.LG",
        "authors": [
            "Zhenwei Zhang",
            "Ervin Sejdic"
        ],
        "pdf_url": "http://arxiv.org/pdf/1903.11726v1"
    },
    {
        "title": "Collaborative Machine Learning Markets with Data-Replication-Robust   Payments",
        "abstract": "We study the problem of collaborative machine learning markets where multiple parties can achieve improved performance on their machine learning tasks by combining their training data. We discuss desired properties for these machine learning markets in terms of fair revenue distribution and potential threats, including data replication. We then instantiate a collaborative market for cases where parties share a common machine learning task and where parties' tasks are different. Our marketplace incentivizes parties to submit high quality training and true validation data. To this end, we introduce a novel payment division function that is robust-to-replication and customized output models that perform well only on requested machine learning tasks. In experiments, we validate the assumptions underlying our theoretical analysis and show that these are approximately satisfied for commonly used machine learning models.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1911.09052v1",
        "keywords": "cs.GT, cs.LG, stat.ML",
        "subject_areas": "cs.GT, cs.LG, stat.ML",
        "authors": [
            "Olga Ohrimenko",
            "Shruti Tople",
            "Sebastian Tschiatschek"
        ],
        "pdf_url": "http://arxiv.org/pdf/1911.09052v1"
    },
    {
        "title": "DriveML: An R Package for Driverless Machine Learning",
        "abstract": "In recent years, the concept of automated machine learning has become very popular. Automated Machine Learning (AutoML) mainly refers to the automated methods for model selection and hyper-parameter optimization of various algorithms such as random forests, gradient boosting, neural networks, etc. In this paper, we introduce a new package i.e. DriveML for automated machine learning. DriveML helps in implementing some of the pillars of an automated machine learning pipeline such as automated data preparation, feature engineering, model building and model explanation by running the function instead of writing lengthy R codes. The DriveML package is available in CRAN. We compare the DriveML package with other relevant packages in CRAN/Github and find that DriveML performs the best across different parameters. We also provide an illustration by applying the DriveML package with default configuration on a real world dataset. Overall, the main benefits of DriveML are in development time savings, reduce developer's errors, optimal tuning of machine learning models and reproducibility.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2005.00478v3",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Sayan Putatunda",
            "Dayananda Ubrangala",
            "Kiran Rama",
            "Ravi Kondapalli"
        ],
        "pdf_url": "http://arxiv.org/pdf/2005.00478v3"
    },
    {
        "title": "An $O(N)$ Sorting Algorithm: Machine Learning Sort",
        "abstract": "We propose an $O(N\\cdot M)$ sorting algorithm by Machine Learning method, which shows a huge potential sorting big data. This sorting algorithm can be applied to parallel sorting and is suitable for GPU or TPU acceleration. Furthermore, we discuss the application of this algorithm to sparse hash table.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1805.04272v2",
        "keywords": "cs.LG, cs.DS, stat.ML",
        "subject_areas": "cs.LG, cs.DS, stat.ML",
        "authors": [
            "Hanqing Zhao",
            "Yuehan Luo"
        ],
        "pdf_url": "http://arxiv.org/pdf/1805.04272v2"
    },
    {
        "title": "Risk Assessment for Machine Learning Models",
        "abstract": "In this paper we propose a framework for assessing the risk associated with deploying a machine learning model in a specified environment. For that we carry over the risk definition from decision theory to machine learning. We develop and implement a method that allows to define deployment scenarios, test the machine learning model under the conditions specified in each scenario, and estimate the damage associated with the output of the machine learning model under test. Using the likelihood of each scenario together with the estimated damage we define \\emph{key risk indicators} of a machine learning model.   The definition of scenarios and weighting by their likelihood allows for standardized risk assessment in machine learning throughout multiple domains of application. In particular, in our framework, the robustness of a machine learning model to random input corruptions, distributional shifts caused by a changing environment, and adversarial perturbations can be assessed.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2011.04328v1",
        "keywords": "cs.LG, cs.AI",
        "subject_areas": "cs.LG, cs.AI",
        "authors": [
            "Paul Schwerdtner",
            "Florens Greßner",
            "Nikhil Kapoor",
            "Felix Assion",
            "René Sass",
            "Wiebke Günther",
            "Fabian Hüger",
            "Peter Schlicht"
        ],
        "pdf_url": "http://arxiv.org/pdf/2011.04328v1"
    },
    {
        "title": "Distributed Multitask Learning",
        "abstract": "We consider the problem of distributed multi-task learning, where each machine learns a separate, but related, task. Specifically, each machine learns a linear predictor in high-dimensional space,where all tasks share the same small support. We present a communication-efficient estimator based on the debiased lasso and show that it is comparable with the optimal centralized method.",
        "publication_year": "2015",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1510.00633v1",
        "keywords": "stat.ML, cs.LG",
        "subject_areas": "stat.ML, cs.LG",
        "authors": [
            "Jialei Wang",
            "Mladen Kolar",
            "Nathan Srebro"
        ],
        "pdf_url": "http://arxiv.org/pdf/1510.00633v1"
    },
    {
        "title": "A Survey on Resilient Machine Learning",
        "abstract": "Machine learning based system are increasingly being used for sensitive tasks such as security surveillance, guiding autonomous vehicle, taking investment decisions, detecting and blocking network intrusion and malware etc. However, recent research has shown that machine learning models are venerable to attacks by adversaries at all phases of machine learning (eg, training data collection, training, operation). All model classes of machine learning systems can be misled by providing carefully crafted inputs making them wrongly classify inputs. Maliciously created input samples can affect the learning process of a ML system by either slowing down the learning process, or affecting the performance of the learned mode, or causing the system make error(s) only in attacker's planned scenario. Because of these developments, understanding security of machine learning algorithms and systems is emerging as an important research area among computer security and machine learning researchers and practitioners. We present a survey of this emerging area in machine learning.",
        "publication_year": "2017",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1707.03184v1",
        "keywords": "cs.AI, cs.CR, cs.LG",
        "subject_areas": "cs.AI, cs.CR, cs.LG",
        "authors": [
            "Atul Kumar",
            "Sameep Mehta"
        ],
        "pdf_url": "http://arxiv.org/pdf/1707.03184v1"
    },
    {
        "title": "Proceedings of NeurIPS 2018 Workshop on Machine Learning for the   Developing World: Achieving Sustainable Impact",
        "abstract": "This is the Proceedings of NeurIPS 2018 Workshop on Machine Learning for the Developing World: Achieving Sustainable Impact, held in Montreal, Canada on December 8, 2018",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1812.10398v2",
        "keywords": "cs.CY, cs.AI, cs.LG, stat.ML",
        "subject_areas": "cs.CY, cs.AI, cs.LG, stat.ML",
        "authors": [
            "Maria De-Arteaga",
            "Amanda Coston",
            "William Herlands"
        ],
        "pdf_url": "http://arxiv.org/pdf/1812.10398v2"
    },
    {
        "title": "A Game of Dice: Machine Learning and the Question Concerning Art",
        "abstract": "We review some practical and philosophical questions raised by the use of machine learning in creative practice. Beyond the obvious problems regarding plagiarism and authorship, we argue that the novelty in AI Art relies mostly on a narrow machine learning contribution : manifold approximation. Nevertheless, this contribution creates a radical shift in the way we have to consider this movement. Is this omnipotent tool a blessing or a curse for the artists?",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1904.01957v1",
        "keywords": "cs.AI, cs.LG",
        "subject_areas": "cs.AI, cs.LG",
        "authors": [
            "Paul Todorov"
        ],
        "pdf_url": "http://arxiv.org/pdf/1904.01957v1"
    },
    {
        "title": "Systematic Training and Testing for Machine Learning Using Combinatorial   Interaction Testing",
        "abstract": "This paper demonstrates the systematic use of combinatorial coverage for selecting and characterizing test and training sets for machine learning models. The presented work adapts combinatorial interaction testing, which has been successfully leveraged in identifying faults in software testing, to characterize data used in machine learning. The MNIST hand-written digits data is used to demonstrate that combinatorial coverage can be used to select test sets that stress machine learning model performance, to select training sets that lead to robust model performance, and to select data for fine-tuning models to new domains. Thus, the results posit combinatorial coverage as a holistic approach to training and testing for machine learning. In contrast to prior work which has focused on the use of coverage in regard to the internal of neural networks, this paper considers coverage over simple features derived from inputs and outputs. Thus, this paper addresses the case where the supplier of test and training sets for machine learning models does not have intellectual property rights to the models themselves. Finally, the paper addresses prior criticism of combinatorial coverage and provides a rebuttal which advocates the use of coverage metrics in machine learning applications.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2201.12428v1",
        "keywords": "cs.LG, cs.SE, stat.ML",
        "subject_areas": "cs.LG, cs.SE, stat.ML",
        "authors": [
            "Tyler Cody",
            "Erin Lanus",
            "Daniel D. Doyle",
            "Laura Freeman"
        ],
        "pdf_url": "http://arxiv.org/pdf/2201.12428v1"
    },
    {
        "title": "Proceedings of the 2018 ICML Workshop on Human Interpretability in   Machine Learning (WHI 2018)",
        "abstract": "This is the Proceedings of the 2018 ICML Workshop on Human Interpretability in Machine Learning (WHI 2018), which was held in Stockholm, Sweden, July 14, 2018. Invited speakers were Barbara Engelhardt, Cynthia Rudin, Fernanda Vi\\'egas, and Martin Wattenberg.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1807.01308v1",
        "keywords": "stat.ML, cs.LG",
        "subject_areas": "stat.ML, cs.LG",
        "authors": [
            "Been Kim",
            "Kush R. Varshney",
            "Adrian Weller"
        ],
        "pdf_url": "http://arxiv.org/pdf/1807.01308v1"
    },
    {
        "title": "TherML: Thermodynamics of Machine Learning",
        "abstract": "In this work we offer a framework for reasoning about a wide class of existing objectives in machine learning. We develop a formal correspondence between this work and thermodynamics and discuss its implications.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1807.04162v3",
        "keywords": "cs.LG, cond-mat.stat-mech, stat.ML",
        "subject_areas": "cs.LG, cond-mat.stat-mech, stat.ML",
        "authors": [
            "Alexander A. Alemi",
            "Ian Fischer"
        ],
        "pdf_url": "http://arxiv.org/pdf/1807.04162v3"
    },
    {
        "title": "ML-Schema: Exposing the Semantics of Machine Learning with Schemas and   Ontologies",
        "abstract": "The ML-Schema, proposed by the W3C Machine Learning Schema Community Group, is a top-level ontology that provides a set of classes, properties, and restrictions for representing and interchanging information on machine learning algorithms, datasets, and experiments. It can be easily extended and specialized and it is also mapped to other more domain-specific ontologies developed in the area of machine learning and data mining. In this paper we overview existing state-of-the-art machine learning interchange formats and present the first release of ML-Schema, a canonical format resulted of more than seven years of experience among different research institutions. We argue that exposing semantics of machine learning algorithms, models, and experiments through a canonical format may pave the way to better interpretability and to realistically achieve the full interoperability of experiments regardless of platform or adopted workflow solution.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1807.05351v1",
        "keywords": "cs.LG, cs.DB, cs.IR, stat.ML",
        "subject_areas": "cs.LG, cs.DB, cs.IR, stat.ML",
        "authors": [
            "Gustavo Correa Publio",
            "Diego Esteves",
            "Agnieszka Ławrynowicz",
            "Panče Panov",
            "Larisa Soldatova",
            "Tommaso Soru",
            "Joaquin Vanschoren",
            "Hamid Zafar"
        ],
        "pdf_url": "http://arxiv.org/pdf/1807.05351v1"
    },
    {
        "title": "Category Theory in Machine Learning",
        "abstract": "Over the past two decades machine learning has permeated almost every realm of technology. At the same time, many researchers have begun using category theory as a unifying language, facilitating communication between different scientific disciplines. It is therefore unsurprising that there is a burgeoning interest in applying category theory to machine learning. We aim to document the motivations, goals and common themes across these applications. We touch on gradient-based learning, probability, and equivariant learning.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2106.07032v1",
        "keywords": "cs.LG",
        "subject_areas": "cs.LG",
        "authors": [
            "Dan Shiebler",
            "Bruno Gavranović",
            "Paul Wilson"
        ],
        "pdf_url": "http://arxiv.org/pdf/2106.07032v1"
    },
    {
        "title": "On conditional parity as a notion of non-discrimination in machine   learning",
        "abstract": "We identify conditional parity as a general notion of non-discrimination in machine learning. In fact, several recently proposed notions of non-discrimination, including a few counterfactual notions, are instances of conditional parity. We show that conditional parity is amenable to statistical analysis by studying randomization as a general mechanism for achieving conditional parity and a kernel-based test of conditional parity.",
        "publication_year": "2017",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1706.08519v1",
        "keywords": "stat.ML, cs.CY, cs.LG",
        "subject_areas": "stat.ML, cs.CY, cs.LG",
        "authors": [
            "Ya'acov Ritov",
            "Yuekai Sun",
            "Ruofei Zhao"
        ],
        "pdf_url": "http://arxiv.org/pdf/1706.08519v1"
    },
    {
        "title": "Some Requests for Machine Learning Research from the East African Tech   Scene",
        "abstract": "Based on 46 in-depth interviews with scientists, engineers, and CEOs, this document presents a list of concrete machine research problems, progress on which would directly benefit tech ventures in East Africa.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1810.11383v2",
        "keywords": "cs.LG, cs.CY, stat.ML",
        "subject_areas": "cs.LG, cs.CY, stat.ML",
        "authors": [
            "Milan Cvitkovic"
        ],
        "pdf_url": "http://arxiv.org/pdf/1810.11383v2"
    },
    {
        "title": "Characterizing machine learning process: A maturity framework",
        "abstract": "Academic literature on machine learning modeling fails to address how to make machine learning models work for enterprises. For example, existing machine learning processes cannot address how to define business use cases for an AI application, how to convert business requirements from offering managers into data requirements for data scientists, and how to continuously improve AI applications in term of accuracy and fairness, and how to customize general purpose machine learning models with industry, domain, and use case specific data to make them more accurate for specific situations etc. Making AI work for enterprises requires special considerations, tools, methods and processes. In this paper we present a maturity framework for machine learning model lifecycle management for enterprises. Our framework is a re-interpretation of the software Capability Maturity Model (CMM) for machine learning model development process. We present a set of best practices from our personal experience of building large scale real-world machine learning models to help organizations achieve higher levels of maturity independent of their starting point.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1811.04871v1",
        "keywords": "cs.LG, cs.SE",
        "subject_areas": "cs.LG, cs.SE",
        "authors": [
            "Rama Akkiraju",
            "Vibha Sinha",
            "Anbang Xu",
            "Jalal Mahmud",
            "Pritam Gundecha",
            "Zhe Liu",
            "Xiaotong Liu",
            "John Schumacher"
        ],
        "pdf_url": "http://arxiv.org/pdf/1811.04871v1"
    },
    {
        "title": "Towards Identifying and Managing Sources of Uncertainty in AI and   Machine Learning Models - An Overview",
        "abstract": "Quantifying and managing uncertainties that occur when data-driven models such as those provided by AI and machine learning methods are applied is crucial. This whitepaper provides a brief motivation and first overview of the state of the art in identifying and quantifying sources of uncertainty for data-driven components as well as means for analyzing their impact.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1811.11669v1",
        "keywords": "cs.LG, stat.ML, 68T01",
        "subject_areas": "cs.LG, stat.ML, 68T01",
        "authors": [
            "Michael Kläs"
        ],
        "pdf_url": "http://arxiv.org/pdf/1811.11669v1"
    },
    {
        "title": "Financial Time Series Data Processing for Machine Learning",
        "abstract": "This article studies the financial time series data processing for machine learning. It introduces the most frequent scaling methods, then compares the resulting stationarity and preservation of useful information for trend forecasting. It proposes an empirical test based on the capability to learn simple data relationship with simple models. It also speaks about the data split method specific to time series, avoiding unwanted overfitting and proposes various labelling for classification and regression.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1907.03010v1",
        "keywords": "q-fin.ST, cs.LG, stat.ML",
        "subject_areas": "q-fin.ST, cs.LG, stat.ML",
        "authors": [
            "Fabrice Daniel"
        ],
        "pdf_url": "http://arxiv.org/pdf/1907.03010v1"
    },
    {
        "title": "Machine Learning and Computational Mathematics",
        "abstract": "Neural network-based machine learning is capable of approximating functions in very high dimension with unprecedented efficiency and accuracy. This has opened up many exciting new possibilities, not just in traditional areas of artificial intelligence, but also in scientific computing and computational science. At the same time, machine learning has also acquired the reputation of being a set of \"black box\" type of tricks, without fundamental principles. This has been a real obstacle for making further progress in machine learning. In this article, we try to address the following two very important questions: (1) How machine learning has already impacted and will further impact computational mathematics, scientific computing and computational science? (2) How computational mathematics, particularly numerical analysis, {can} impact machine learning? We describe some of the most important progress that has been made on these issues. Our hope is to put things into a perspective that will help to integrate machine learning with computational mathematics.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2009.14596v1",
        "keywords": "math.NA, cs.LG, cs.NA, stat.ML, 68T07, 46E15, 26B35, 26B40",
        "subject_areas": "math.NA, cs.LG, cs.NA, stat.ML, 68T07, 46E15, 26B35, 26B40",
        "authors": [
            "Weinan E"
        ],
        "pdf_url": "http://arxiv.org/pdf/2009.14596v1"
    },
    {
        "title": "Machine Learning for Detecting Malware in PE Files",
        "abstract": "The increasing number of sophisticated malware poses a major cybersecurity threat. Portable executable (PE) files are a common vector for such malware. In this work we review and evaluate machine learning-based PE malware detection techniques. Using a large benchmark dataset, we evaluate features of PE files using the most common machine learning techniques to detect malware.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2212.13988v1",
        "keywords": "cs.CR, cs.LG",
        "subject_areas": "cs.CR, cs.LG",
        "authors": [
            "Collin Connors",
            "Dilip Sarkar"
        ],
        "pdf_url": "http://arxiv.org/pdf/2212.13988v1"
    },
    {
        "title": "The Top 10 Topics in Machine Learning Revisited: A Quantitative   Meta-Study",
        "abstract": "Which topics of machine learning are most commonly addressed in research? This question was initially answered in 2007 by doing a qualitative survey among distinguished researchers. In our study, we revisit this question from a quantitative perspective. Concretely, we collect 54K abstracts of papers published between 2007 and 2016 in leading machine learning journals and conferences. We then use machine learning in order to determine the top 10 topics in machine learning. We not only include models, but provide a holistic view across optimization, data, features, etc. This quantitative approach allows reducing the bias of surveys. It reveals new and up-to-date insights into what the 10 most prolific topics in machine learning research are. This allows researchers to identify popular topics as well as new and rising topics for their research.",
        "publication_year": "2017",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1703.10121v1",
        "keywords": "cs.LG, cs.AI, stat.ML",
        "subject_areas": "cs.LG, cs.AI, stat.ML",
        "authors": [
            "Patrick Glauner",
            "Manxing Du",
            "Victor Paraschiv",
            "Andrey Boytsov",
            "Isabel Lopez Andrade",
            "Jorge Meira",
            "Petko Valtchev",
            "Radu State"
        ],
        "pdf_url": "http://arxiv.org/pdf/1703.10121v1"
    },
    {
        "title": "Analysis of Software Engineering for Agile Machine Learning Projects",
        "abstract": "The number of machine learning, artificial intelligence or data science related software engineering projects using Agile methodology is increasing. However, there are very few studies on how such projects work in practice. In this paper, we analyze project issues tracking data taken from Scrum (a popular tool for Agile) for several machine learning projects. We compare this data with corresponding data from non-machine learning projects, in an attempt to analyze how machine learning projects are executed differently from normal software engineering projects. On analysis, we find that machine learning project issues use different kinds of words to describe issues, have higher number of exploratory or research oriented tasks as compared to implementation tasks, and have a higher number of issues in the product backlog after each sprint, denoting that it is more difficult to estimate the duration of machine learning project related tasks in advance. After analyzing this data, we propose a few ways in which Agile machine learning projects can be better logged and executed, given their differences with normal software engineering projects.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1912.07323v1",
        "keywords": "cs.SE, cs.LG, D.2",
        "subject_areas": "cs.SE, cs.LG, D.2",
        "authors": [
            "Kushal Singla",
            "Joy Bose",
            "Chetan Naik"
        ],
        "pdf_url": "http://arxiv.org/pdf/1912.07323v1"
    },
    {
        "title": "A combinatorial conjecture from PAC-Bayesian machine learning",
        "abstract": "We present a proof of a combinatorial conjecture from the second author's Ph.D. thesis. The proof relies on binomial and multinomial sums identities. We also discuss the relevance of the conjecture in the context of PAC-Bayesian machine learning.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2006.01387v2",
        "keywords": "stat.ML, cs.LG, math.CO",
        "subject_areas": "stat.ML, cs.LG, math.CO",
        "authors": [
            "M. Younsi",
            "A. Lacasse"
        ],
        "pdf_url": "http://arxiv.org/pdf/2006.01387v2"
    },
    {
        "title": "Integrating Machine Learning with Physics-Based Modeling",
        "abstract": "Machine learning is poised as a very powerful tool that can drastically improve our ability to carry out scientific research. However, many issues need to be addressed before this becomes a reality. This article focuses on one particular issue of broad interest: How can we integrate machine learning with physics-based modeling to develop new interpretable and truly reliable physical models? After introducing the general guidelines, we discuss the two most important issues for developing machine learning-based physical models: Imposing physical constraints and obtaining optimal datasets. We also provide a simple and intuitive explanation for the fundamental reasons behind the success of modern machine learning, as well as an introduction to the concurrent machine learning framework needed for integrating machine learning with physics-based modeling. Molecular dynamics and moment closure of kinetic equations are used as examples to illustrate the main issues discussed. We end with a general discussion on where this integration will lead us to, and where the new frontier will be after machine learning is successfully integrated into scientific modeling.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2006.02619v1",
        "keywords": "physics.comp-ph, cs.LG, cs.NA, math.NA",
        "subject_areas": "physics.comp-ph, cs.LG, cs.NA, math.NA",
        "authors": [
            "Weinan E",
            "Jiequn Han",
            "Linfeng Zhang"
        ],
        "pdf_url": "http://arxiv.org/pdf/2006.02619v1"
    },
    {
        "title": "Power Consumption Variation over Activation Functions",
        "abstract": "The power that machine learning models consume when making predictions can be affected by a model's architecture. This paper presents various estimates of power consumption for a range of different activation functions, a core factor in neural network model architecture design. Substantial differences in hardware performance exist between activation functions. This difference informs how power consumption in machine learning models can be reduced.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2006.07237v1",
        "keywords": "cs.LG, cs.NE, stat.ML",
        "subject_areas": "cs.LG, cs.NE, stat.ML",
        "authors": [
            "Leon Derczynski"
        ],
        "pdf_url": "http://arxiv.org/pdf/2006.07237v1"
    },
    {
        "title": "Classification with Quantum Machine Learning: A Survey",
        "abstract": "Due to the superiority and noteworthy progress of Quantum Computing (QC) in a lot of applications such as cryptography, chemistry, Big data, machine learning, optimization, Internet of Things (IoT), Blockchain, communication, and many more. Fully towards to combine classical machine learning (ML) with Quantum Information Processing (QIP) to build a new field in the quantum world is called Quantum Machine Learning (QML) to solve and improve problems that displayed in classical machine learning (e.g. time and energy consumption, kernel estimation). The aim of this paper presents and summarizes a comprehensive survey of the state-of-the-art advances in Quantum Machine Learning (QML). Especially, recent QML classification works. Also, we cover about 30 publications that are published lately in Quantum Machine Learning (QML). we propose a classification scheme in the quantum world and discuss encoding methods for mapping classical data to quantum data. Then, we provide quantum subroutines and some methods of Quantum Computing (QC) in improving performance and speed up of classical Machine Learning (ML). And also some of QML applications in various fields, challenges, and future vision will be presented.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2006.12270v1",
        "keywords": "quant-ph, cs.LG",
        "subject_areas": "quant-ph, cs.LG",
        "authors": [
            "Zainab Abohashima",
            "Mohamed Elhosen",
            "Essam H. Houssein",
            "Waleed M. Mohamed"
        ],
        "pdf_url": "http://arxiv.org/pdf/2006.12270v1"
    },
    {
        "title": "Adversarial Machine Learning Attacks on Condition-Based Maintenance   Capabilities",
        "abstract": "Condition-based maintenance (CBM) strategies exploit machine learning models to assess the health status of systems based on the collected data from the physical environment, while machine learning models are vulnerable to adversarial attacks. A malicious adversary can manipulate the collected data to deceive the machine learning model and affect the CBM system's performance. Adversarial machine learning techniques introduced in the computer vision domain can be used to make stealthy attacks on CBM systems by adding perturbation to data to confuse trained models. The stealthy nature causes difficulty and delay in detection of the attacks. In this paper, adversarial machine learning in the domain of CBM is introduced. A case study shows how adversarial machine learning can be used to attack CBM capabilities. Adversarial samples are crafted using the Fast Gradient Sign method, and the performance of a CBM system under attack is investigated. The obtained results reveal that CBM systems are vulnerable to adversarial machine learning attacks and defense strategies need to be considered.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2101.12097v1",
        "keywords": "cs.LG, cs.AI, cs.CR",
        "subject_areas": "cs.LG, cs.AI, cs.CR",
        "authors": [
            "Hamidreza Habibollahi Najaf Abadi"
        ],
        "pdf_url": "http://arxiv.org/pdf/2101.12097v1"
    },
    {
        "title": "Confronting Machine Learning With Financial Research",
        "abstract": "This study aims to examine the challenges and applications of machine learning for financial research. Machine learning algorithms have been developed for certain data environments which substantially differ from the one we encounter in finance. Not only do difficulties arise due to some of the idiosyncrasies of financial markets, there is a fundamental tension between the underlying paradigm of machine learning and the research philosophy in financial economics. Given the peculiar features of financial markets and the empirical framework within social science, various adjustments have to be made to the conventional machine learning methodology. We discuss some of the main challenges of machine learning in finance and examine how these could be accounted for. Despite some of the challenges, we argue that machine learning could be unified with financial research to become a robust complement to the econometrician's toolbox. Moreover, we discuss the various applications of machine learning in the research process such as estimation, empirical discovery, testing, causal inference and prediction.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2103.00366v2",
        "keywords": "q-fin.ST, cs.LG, econ.EM",
        "subject_areas": "q-fin.ST, cs.LG, econ.EM",
        "authors": [
            "Kristof Lommers",
            "Ouns El Harzli",
            "Jack Kim"
        ],
        "pdf_url": "http://arxiv.org/pdf/2103.00366v2"
    },
    {
        "title": "Machine Learning using Stata/Python",
        "abstract": "We present two related Stata modules, r_ml_stata and c_ml_stata, for fitting popular Machine Learning (ML) methods both in regression and classification settings. Using the recent Stata/Python integration platform (sfi) of Stata 16, these commands provide hyper-parameters' optimal tuning via K-fold cross-validation using greed search. More specifically, they make use of the Python Scikit-learn API to carry out both cross-validation and outcome/label prediction.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2103.03122v1",
        "keywords": "stat.CO, cs.LG, cs.MS",
        "subject_areas": "stat.CO, cs.LG, cs.MS",
        "authors": [
            "Giovanni Cerulli"
        ],
        "pdf_url": "http://arxiv.org/pdf/2103.03122v1"
    },
    {
        "title": "Machine Learning with a Reject Option: A survey",
        "abstract": "Machine learning models always make a prediction, even when it is likely to be inaccurate. This behavior should be avoided in many decision support applications, where mistakes can have severe consequences. Albeit already studied in 1970, machine learning with rejection recently gained interest. This machine learning subfield enables machine learning models to abstain from making a prediction when likely to make a mistake.   This survey aims to provide an overview on machine learning with rejection. We introduce the conditions leading to two types of rejection, ambiguity and novelty rejection, which we carefully formalize. Moreover, we review and categorize strategies to evaluate a model's predictive and rejective quality. Additionally, we define the existing architectures for models with rejection and describe the standard techniques for learning such models. Finally, we provide examples of relevant application domains and show how machine learning with rejection relates to other machine learning research areas.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2107.11277v3",
        "keywords": "cs.LG, cs.AI, 68T02, I.2.6",
        "subject_areas": "cs.LG, cs.AI, 68T02, I.2.6",
        "authors": [
            "Kilian Hendrickx",
            "Lorenzo Perini",
            "Dries Van der Plas",
            "Wannes Meert",
            "Jesse Davis"
        ],
        "pdf_url": "http://arxiv.org/pdf/2107.11277v3"
    },
    {
        "title": "Software Testing for Machine Learning",
        "abstract": "Machine learning has become prevalent across a wide variety of applications. Unfortunately, machine learning has also shown to be susceptible to deception, leading to errors, and even fatal failures. This circumstance calls into question the widespread use of machine learning, especially in safety-critical applications, unless we are able to assure its correctness and trustworthiness properties. Software verification and testing are established technique for assuring such properties, for example by detecting errors. However, software testing challenges for machine learning are vast and profuse - yet critical to address. This summary talk discusses the current state-of-the-art of software testing for machine learning. More specifically, it discusses six key challenge areas for software testing of machine learning systems, examines current approaches to these challenges and highlights their limitations. The paper provides a research agenda with elaborated directions for making progress toward advancing the state-of-the-art on testing of machine learning.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2205.00210v1",
        "keywords": "cs.SE, cs.AI, cs.LG",
        "subject_areas": "cs.SE, cs.AI, cs.LG",
        "authors": [
            "Dusica Marijan",
            "Arnaud Gotlieb"
        ],
        "pdf_url": "http://arxiv.org/pdf/2205.00210v1"
    },
    {
        "title": "PSI Draft Specification",
        "abstract": "This document presents the draft specification for delivering machine learning services over HTTP, developed as part of the Protocols and Structures for Inference project, which concluded in 2013. It presents the motivation for providing machine learning as a service, followed by a description of the essential and optional components of such a service.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2205.09488v1",
        "keywords": "cs.SE, cs.LG, cs.NI",
        "subject_areas": "cs.SE, cs.LG, cs.NI",
        "authors": [
            "Mark Reid",
            "James Montgomery",
            "Barry Drake",
            "Avraham Ruderman"
        ],
        "pdf_url": "http://arxiv.org/pdf/2205.09488v1"
    },
    {
        "title": "PSL is Dead. Long Live PSL",
        "abstract": "Property Specification Language (PSL) is a form of temporal logic that has been mainly used in discrete domains (e.g. formal hardware verification). In this paper, we show that by merging machine learning techniques with PSL monitors, we can extend PSL to work on continuous domains. We apply this technique in machine learning-based anomaly detection to analyze scenarios of real-time streaming events from continuous variables in order to detect abnormal behaviors of a system. By using machine learning with formal models, we leverage the strengths of both machine learning methods and formal semantics of time. On one hand, machine learning techniques can produce distributions on continuous variables, where abnormalities can be captured as deviations from the distributions. On the other hand, formal methods can characterize discrete temporal behaviors and relations that cannot be easily learned by machine learning techniques. Interestingly, the anomalies detected by machine learning and the underlying time representation used are discrete events. We implemented a temporal monitoring package (TEF) that operates in conjunction with normal data science packages for anomaly detection machine learning systems, and we show that TEF can be used to perform accurate interpretation of temporal correlation between events.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2205.14136v1",
        "keywords": "cs.LG, cs.FL",
        "subject_areas": "cs.LG, cs.FL",
        "authors": [
            "Kevin Smith",
            "Hai Lin",
            "Praveen Tiwari",
            "Marjorie Sayer",
            "Claudionor Coelho"
        ],
        "pdf_url": "http://arxiv.org/pdf/2205.14136v1"
    },
    {
        "title": "Pen and Paper Exercises in Machine Learning",
        "abstract": "This is a collection of (mostly) pen-and-paper exercises in machine learning. The exercises are on the following topics: linear algebra, optimisation, directed graphical models, undirected graphical models, expressive power of graphical models, factor graphs and message passing, inference for hidden Markov models, model-based learning (including ICA and unnormalised models), sampling and Monte-Carlo integration, and variational inference.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2206.13446v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Michael U. Gutmann"
        ],
        "pdf_url": "http://arxiv.org/pdf/2206.13446v1"
    },
    {
        "title": "Practical Attacks on Machine Learning: A Case Study on Adversarial   Windows Malware",
        "abstract": "While machine learning is vulnerable to adversarial examples, it still lacks systematic procedures and tools for evaluating its security in different application contexts. In this article, we discuss how to develop automated and scalable security evaluations of machine learning using practical attacks, reporting a use case on Windows malware detection.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2207.05548v1",
        "keywords": "cs.CR, cs.LG",
        "subject_areas": "cs.CR, cs.LG",
        "authors": [
            "Luca Demetrio",
            "Battista Biggio",
            "Fabio Roli"
        ],
        "pdf_url": "http://arxiv.org/pdf/2207.05548v1"
    },
    {
        "title": "Fairness and Randomness in Machine Learning: Statistical Independence   and Relativization",
        "abstract": "Fair Machine Learning endeavors to prevent unfairness arising in the context of machine learning applications embedded in society. Despite the variety of definitions of fairness and proposed \"fair algorithms\", there remain unresolved conceptual problems regarding fairness. In this paper, we dissect the role of statistical independence in fairness and randomness notions regularly used in machine learning. Thereby, we are led to a suprising hypothesis: randomness and fairness can be considered equivalent concepts in machine learning.   In particular, we obtain a relativized notion of randomness expressed as statistical independence by appealing to Von Mises' century-old foundations for probability. This notion turns out to be \"orthogonal\" in an abstract sense to the commonly used i.i.d.-randomness. Using standard fairness notions in machine learning, which are defined via statistical independence, we then link the ex ante randomness assumptions about the data to the ex post requirements for fair predictions. This connection proves fruitful: we use it to argue that randomness and fairness are essentially relative and that both concepts should reflect their nature as modeling assumptions in machine learning.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2207.13596v2",
        "keywords": "cs.LG, cs.CY",
        "subject_areas": "cs.LG, cs.CY",
        "authors": [
            "Rabanus Derr",
            "Robert C. Williamson"
        ],
        "pdf_url": "http://arxiv.org/pdf/2207.13596v2"
    },
    {
        "title": "Survey of Machine Learning Techniques To Predict Heartbeat Arrhythmias",
        "abstract": "Many works in biomedical computer science research use machine learning techniques to give accurate results. However, these techniques may not be feasible for real-time analysis of data pulled from live hospital feeds. In this project, different machine learning techniques are compared from various sources to find one that provides not only high accuracy but also low latency and memory overhead to be used in real-world health care systems.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2208.10463v1",
        "keywords": "cs.LG, eess.SP",
        "subject_areas": "cs.LG, eess.SP",
        "authors": [
            "Samuel Armstrong"
        ],
        "pdf_url": "http://arxiv.org/pdf/2208.10463v1"
    },
    {
        "title": "Data Privacy and Trustworthy Machine Learning",
        "abstract": "The privacy risks of machine learning models is a major concern when training them on sensitive and personal data. We discuss the tradeoffs between data privacy and the remaining goals of trustworthy machine learning (notably, fairness, robustness, and explainability).",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2209.06529v1",
        "keywords": "cs.LG, cs.CR",
        "subject_areas": "cs.LG, cs.CR",
        "authors": [
            "Martin Strobel",
            "Reza Shokri"
        ],
        "pdf_url": "http://arxiv.org/pdf/2209.06529v1"
    },
    {
        "title": "An investigation of licensing of datasets for machine learning based on   the GQM model",
        "abstract": "Dataset licensing is currently an issue in the development of machine learning systems. And in the development of machine learning systems, the most widely used are publicly available datasets. However, since the images in the publicly available dataset are mainly obtained from the Internet, some images are not commercially available. Furthermore, developers of machine learning systems do not often care about the license of the dataset when training machine learning models with it. In summary, the licensing of datasets for machine learning systems is in a state of incompleteness in all aspects at this stage.   Our investigation of two collection datasets revealed that most of the current datasets lacked licenses, and the lack of licenses made it impossible to determine the commercial availability of the datasets. Therefore, we decided to take a more scientific and systematic approach to investigate the licensing of datasets and the licensing of machine learning systems that use the dataset to make it easier and more compliant for future developers of machine learning systems.",
        "publication_year": "2023",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2303.13735v1",
        "keywords": "cs.SE, cs.CY, cs.LG",
        "subject_areas": "cs.SE, cs.CY, cs.LG",
        "authors": [
            "Junyu Chen",
            "Norihiro Yoshida",
            "Hiroaki Takada"
        ],
        "pdf_url": "http://arxiv.org/pdf/2303.13735v1"
    },
    {
        "title": "Matched Machine Learning: A Generalized Framework for Treatment Effect   Inference With Learned Metrics",
        "abstract": "We introduce Matched Machine Learning, a framework that combines the flexibility of machine learning black boxes with the interpretability of matching, a longstanding tool in observational causal inference. Interpretability is paramount in many high-stakes application of causal inference. Current tools for nonparametric estimation of both average and individualized treatment effects are black-boxes that do not allow for human auditing of estimates. Our framework uses machine learning to learn an optimal metric for matching units and estimating outcomes, thus achieving the performance of machine learning black-boxes, while being interpretable. Our general framework encompasses several published works as special cases. We provide asymptotic inference theory for our proposed framework, enabling users to construct approximate confidence intervals around estimates of both individualized and average treatment effects. We show empirically that instances of Matched Machine Learning perform on par with black-box machine learning methods and better than existing matching methods for similar problems. Finally, in our application we show how Matched Machine Learning can be used to perform causal inference even when covariate data are highly complex: we study an image dataset, and produce high quality matches and estimates of treatment effects.",
        "publication_year": "2023",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2304.01316v1",
        "keywords": "stat.ME, stat.ML",
        "subject_areas": "stat.ME, stat.ML",
        "authors": [
            "Marco Morucci",
            "Cynthia Rudin",
            "Alexander Volfovsky"
        ],
        "pdf_url": "http://arxiv.org/pdf/2304.01316v1"
    },
    {
        "title": "Applied Causal Inference Powered by ML and AI",
        "abstract": "An introduction to the emerging fusion of machine learning and causal inference. The book presents ideas from classical structural equation models (SEMs) and their modern AI equivalent, directed acyclical graphs (DAGs) and structural causal models (SCMs), and covers Double/Debiased Machine Learning methods to do inference in such models using modern predictive tools.",
        "publication_year": "2024",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2403.02467v1",
        "keywords": "econ.EM, cs.LG, stat.ME, stat.ML",
        "subject_areas": "econ.EM, cs.LG, stat.ME, stat.ML",
        "authors": [
            "Victor Chernozhukov",
            "Christian Hansen",
            "Nathan Kallus",
            "Martin Spindler",
            "Vasilis Syrgkanis"
        ],
        "pdf_url": "http://arxiv.org/pdf/2403.02467v1"
    },
    {
        "title": "A Declarative Query Language for Scientific Machine Learning",
        "abstract": "The popularity of data science as a discipline and its importance in the emerging economy and industrial progress dictate that machine learning be democratized for the masses. This also means that the current practice of workforce training using machine learning tools, which requires low-level statistical and algorithmic details, is a barrier that needs to be addressed. Similar to data management languages such as SQL, machine learning needs to be practiced at a conceptual level to help make it a staple tool for general users. In particular, the technical sophistication demanded by existing machine learning frameworks is prohibitive for many scientists who are not computationally savvy or well versed in machine learning techniques. The learning curve to use the needed machine learning tools is also too high for them to take advantage of these powerful platforms to rapidly advance science. In this paper, we introduce a new declarative machine learning query language, called {\\em MQL}, for naive users. We discuss its merit and possible ways of implementing it over a traditional relational database system. We discuss two materials science experiments implemented using MQL on a materials science workflow system called MatFlow.",
        "publication_year": "2024",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2405.16159v1",
        "keywords": "cs.LG, cs.DB",
        "subject_areas": "cs.LG, cs.DB",
        "authors": [
            "Hasan M Jamil"
        ],
        "pdf_url": "http://arxiv.org/pdf/2405.16159v1"
    },
    {
        "title": "Creative Loss: Ambiguity, Uncertainty and Indeterminacy",
        "abstract": "This article evaluates how creative uses of machine learning can address three adjacent terms: ambiguity, uncertainty and indeterminacy. Through the progression of these concepts it reflects on increasing ambitions for machine learning as a creative partner, illustrated with research from Unit 21 at the Bartlett School of Architecture, UCL. Through indeterminacy are potential future approaches to machine learning and design.",
        "publication_year": "2024",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2501.10369v1",
        "keywords": "cs.CY, cs.AI, cs.HC, cs.LG",
        "subject_areas": "cs.CY, cs.AI, cs.HC, cs.LG",
        "authors": [
            "Tom Holberton"
        ],
        "pdf_url": "http://arxiv.org/pdf/2501.10369v1"
    },
    {
        "title": "Machine learning and high dimensional vector search",
        "abstract": "Machine learning and vector search are two research topics that developed in parallel in nearby communities. However, unlike many other fields related to big data, machine learning has not significantly impacted vector search. In this opinion paper we attempt to explain this oddity. Along the way, we wander over the numerous bridges between the two fields.",
        "publication_year": "2025",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2502.16931v1",
        "keywords": "cs.LG",
        "subject_areas": "cs.LG",
        "authors": [
            "Matthijs Douze"
        ],
        "pdf_url": "http://arxiv.org/pdf/2502.16931v1"
    },
    {
        "title": "The Threat of Adversarial Attacks on Machine Learning in Network   Security -- A Survey",
        "abstract": "Machine learning models have made many decision support systems to be faster, more accurate, and more efficient. However, applications of machine learning in network security face a more disproportionate threat of active adversarial attacks compared to other domains. This is because machine learning applications in network security such as malware detection, intrusion detection, and spam filtering are by themselves adversarial in nature. In what could be considered an arm's race between attackers and defenders, adversaries constantly probe machine learning systems with inputs that are explicitly designed to bypass the system and induce a wrong prediction. In this survey, we first provide a taxonomy of machine learning techniques, tasks, and depth. We then introduce a classification of machine learning in network security applications. Next, we examine various adversarial attacks against machine learning in network security and introduce two classification approaches for adversarial attacks in network security. First, we classify adversarial attacks in network security based on a taxonomy of network security applications. Secondly, we categorize adversarial attacks in network security into a problem space vs feature space dimensional classification model. We then analyze the various defenses against adversarial attacks on machine learning-based network security applications. We conclude by introducing an adversarial risk grid map and evaluating several existing adversarial attacks against machine learning in network security using the risk grid map. We also identify where each attack classification resides within the adversarial risk grid map.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1911.02621v3",
        "keywords": "cs.CR, cs.LG, cs.NI",
        "subject_areas": "cs.CR, cs.LG, cs.NI",
        "authors": [
            "Olakunle Ibitoye",
            "Rana Abou-Khamis",
            "Mohamed el Shehaby",
            "Ashraf Matrawy",
            "M. Omair Shafiq"
        ],
        "pdf_url": "http://arxiv.org/pdf/1911.02621v3"
    },
    {
        "title": "Machine Learning for Software Engineering: A Systematic Mapping",
        "abstract": "Context: The software development industry is rapidly adopting machine learning for transitioning modern day software systems towards highly intelligent and self-learning systems. However, the full potential of machine learning for improving the software engineering life cycle itself is yet to be discovered, i.e., up to what extent machine learning can help reducing the effort/complexity of software engineering and improving the quality of resulting software systems. To date, no comprehensive study exists that explores the current state-of-the-art on the adoption of machine learning across software engineering life cycle stages. Objective: This article addresses the aforementioned problem and aims to present a state-of-the-art on the growing number of uses of machine learning in software engineering. Method: We conduct a systematic mapping study on applications of machine learning to software engineering following the standard guidelines and principles of empirical software engineering. Results: This study introduces a machine learning for software engineering (MLSE) taxonomy classifying the state-of-the-art machine learning techniques according to their applicability to various software engineering life cycle stages. Overall, 227 articles were rigorously selected and analyzed as a result of this study. Conclusion: From the selected articles, we explore a variety of aspects that should be helpful to academics and practitioners alike in understanding the potential of adopting machine learning techniques during software engineering projects.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2005.13299v1",
        "keywords": "cs.SE, cs.LG",
        "subject_areas": "cs.SE, cs.LG",
        "authors": [
            "Saad Shafiq",
            "Atif Mashkoor",
            "Christoph Mayr-Dorn",
            "Alexander Egyed"
        ],
        "pdf_url": "http://arxiv.org/pdf/2005.13299v1"
    },
    {
        "title": "A Review of Formal Methods applied to Machine Learning",
        "abstract": "We review state-of-the-art formal methods applied to the emerging field of the verification of machine learning systems. Formal methods can provide rigorous correctness guarantees on hardware and software systems. Thanks to the availability of mature tools, their use is well established in the industry, and in particular to check safety-critical applications as they undergo a stringent certification process. As machine learning is becoming more popular, machine-learned components are now considered for inclusion in critical systems. This raises the question of their safety and their verification. Yet, established formal methods are limited to classic, i.e. non machine-learned software. Applying formal methods to verify systems that include machine learning has only been considered recently and poses novel challenges in soundness, precision, and scalability.   We first recall established formal methods and their current use in an exemplar safety-critical field, avionic software, with a focus on abstract interpretation based techniques as they provide a high level of scalability. This provides a golden standard and sets high expectations for machine learning verification. We then provide a comprehensive and detailed review of the formal methods developed so far for machine learning, highlighting their strengths and limitations. The large majority of them verify trained neural networks and employ either SMT, optimization, or abstract interpretation techniques. We also discuss methods for support vector machines and decision tree ensembles, as well as methods targeting training and data preparation, which are critical but often neglected aspects of machine learning. Finally, we offer perspectives for future research directions towards the formal verification of machine learning systems.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2104.02466v2",
        "keywords": "cs.PL, cs.LG, cs.LO",
        "subject_areas": "cs.PL, cs.LG, cs.LO",
        "authors": [
            "Caterina Urban",
            "Antoine Miné"
        ],
        "pdf_url": "http://arxiv.org/pdf/2104.02466v2"
    },
    {
        "title": "Diversity in Machine Learning",
        "abstract": "Machine learning methods have achieved good performance and been widely applied in various real-world applications. They can learn the model adaptively and be better fit for special requirements of different tasks. Generally, a good machine learning system is composed of plentiful training data, a good model training process, and an accurate inference. Many factors can affect the performance of the machine learning process, among which the diversity of the machine learning process is an important one. The diversity can help each procedure to guarantee a total good machine learning: diversity of the training data ensures that the training data can provide more discriminative information for the model, diversity of the learned model (diversity in parameters of each model or diversity among different base models) makes each parameter/model capture unique or complement information and the diversity in inference can provide multiple choices each of which corresponds to a specific plausible local optimal result. Even though the diversity plays an important role in machine learning process, there is no systematical analysis of the diversification in machine learning system. In this paper, we systematically summarize the methods to make data diversification, model diversification, and inference diversification in the machine learning process, respectively. In addition, the typical applications where the diversity technology improved the machine learning performance have been surveyed, including the remote sensing imaging tasks, machine translation, camera relocalization, image segmentation, object detection, topic modeling, and others. Finally, we discuss some challenges of the diversity technology in machine learning and point out some directions in future work.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1807.01477v2",
        "keywords": "cs.CV",
        "subject_areas": "cs.CV",
        "authors": [
            "Zhiqiang Gong",
            "Ping Zhong",
            "Weidong Hu"
        ],
        "pdf_url": "http://arxiv.org/pdf/1807.01477v2"
    },
    {
        "title": "Machine Learning for the Geosciences: Challenges and Opportunities",
        "abstract": "Geosciences is a field of great societal relevance that requires solutions to several urgent problems facing our humanity and the planet. As geosciences enters the era of big data, machine learning (ML) -- that has been widely successful in commercial domains -- offers immense potential to contribute to problems in geosciences. However, problems in geosciences have several unique challenges that are seldom found in traditional applications, requiring novel problem formulations and methodologies in machine learning. This article introduces researchers in the machine learning (ML) community to these challenges offered by geoscience problems and the opportunities that exist for advancing both machine learning and geosciences. We first highlight typical sources of geoscience data and describe their properties that make it challenging to use traditional machine learning techniques. We then describe some of the common categories of geoscience problems where machine learning can play a role, and discuss some of the existing efforts and promising directions for methodological development in machine learning. We conclude by discussing some of the emerging research themes in machine learning that are applicable across all problems in the geosciences, and the importance of a deep collaboration between machine learning and geosciences for synergistic advancements in both disciplines.",
        "publication_year": "2017",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1711.04708v1",
        "keywords": "cs.LG, cs.AI, cs.CV, physics.geo-ph",
        "subject_areas": "cs.LG, cs.AI, cs.CV, physics.geo-ph",
        "authors": [
            "Anuj Karpatne",
            "Imme Ebert-Uphoff",
            "Sai Ravela",
            "Hassan Ali Babaie",
            "Vipin Kumar"
        ],
        "pdf_url": "http://arxiv.org/pdf/1711.04708v1"
    },
    {
        "title": "Modeling Stated Preference for Mobility-on-Demand Transit: A Comparison   of Machine Learning and Logit Models",
        "abstract": "Logit models are usually applied when studying individual travel behavior, i.e., to predict travel mode choice and to gain behavioral insights on traveler preferences. Recently, some studies have applied machine learning to model travel mode choice and reported higher out-of-sample predictive accuracy than traditional logit models (e.g., multinomial logit). However, little research focuses on comparing the interpretability of machine learning with logit models. In other words, how to draw behavioral insights from the high-performance \"black-box\" machine-learning models remains largely unsolved in the field of travel behavior modeling.   This paper aims at providing a comprehensive comparison between the two approaches by examining the key similarities and differences in model development, evaluation, and behavioral interpretation between logit and machine-learning models for travel mode choice modeling. To complement the theoretical discussions, the paper also empirically evaluates the two approaches on the stated-preference survey data for a new type of transit system integrating high-frequency fixed-route services and ridesourcing. The results show that machine learning can produce significantly higher predictive accuracy than logit models. Moreover, machine learning and logit models largely agree on many aspects of behavioral interpretations. In addition, machine learning can automatically capture the nonlinear relationship between the input features and choice outcomes. The paper concludes that there is great potential in merging ideas from machine learning and conventional statistical methods to develop refined models for travel behavior research and suggests some new research directions.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1811.01315v2",
        "keywords": "cs.LG, cs.AI, stat.AP, stat.ML",
        "subject_areas": "cs.LG, cs.AI, stat.AP, stat.ML",
        "authors": [
            "Xilei Zhao",
            "Xiang Yan",
            "Alan Yu",
            "Pascal Van Hentenryck"
        ],
        "pdf_url": "http://arxiv.org/pdf/1811.01315v2"
    },
    {
        "title": "On Hyperparameter Optimization of Machine Learning Algorithms: Theory   and Practice",
        "abstract": "Machine learning algorithms have been used widely in various applications and areas. To fit a machine learning model into different problems, its hyper-parameters must be tuned. Selecting the best hyper-parameter configuration for machine learning models has a direct impact on the model's performance. It often requires deep knowledge of machine learning algorithms and appropriate hyper-parameter optimization techniques. Although several automatic optimization techniques exist, they have different strengths and drawbacks when applied to different types of problems. In this paper, optimizing the hyper-parameters of common machine learning models is studied. We introduce several state-of-the-art optimization techniques and discuss how to apply them to machine learning algorithms. Many available libraries and frameworks developed for hyper-parameter optimization problems are provided, and some open challenges of hyper-parameter optimization research are also discussed in this paper. Moreover, experiments are conducted on benchmark datasets to compare the performance of different optimization methods and provide practical examples of hyper-parameter optimization. This survey paper will help industrial users, data analysts, and researchers to better develop machine learning models by identifying the proper hyper-parameter configurations effectively.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2007.15745v3",
        "keywords": "cs.LG, stat.ML, 68T01, 90C31, I.2.0; I.2.2; C.2.0",
        "subject_areas": "cs.LG, stat.ML, 68T01, 90C31, I.2.0; I.2.2; C.2.0",
        "authors": [
            "Li Yang",
            "Abdallah Shami"
        ],
        "pdf_url": "http://arxiv.org/pdf/2007.15745v3"
    },
    {
        "title": "Choice modelling in the age of machine learning -- discussion paper",
        "abstract": "Since its inception, the choice modelling field has been dominated by theory-driven modelling approaches. Machine learning offers an alternative data-driven approach for modelling choice behaviour and is increasingly drawing interest in our field. Cross-pollination of machine learning models, techniques and practices could help overcome problems and limitations encountered in the current theory-driven modelling paradigm, such as subjective labour-intensive search processes for model selection, and the inability to work with text and image data. However, despite the potential benefits of using the advances of machine learning to improve choice modelling practices, the choice modelling field has been hesitant to embrace machine learning. This discussion paper aims to consolidate knowledge on the use of machine learning models, techniques and practices for choice modelling, and discuss their potential. Thereby, we hope not only to make the case that further integration of machine learning in choice modelling is beneficial, but also to further facilitate it. To this end, we clarify the similarities and differences between the two modelling paradigms; we review the use of machine learning for choice modelling; and we explore areas of opportunities for embracing machine learning models and techniques to improve our practices. To conclude this discussion paper, we put forward a set of research questions which must be addressed to better understand if and how machine learning can benefit choice modelling.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2101.11948v2",
        "keywords": "econ.EM, cs.LG",
        "subject_areas": "econ.EM, cs.LG",
        "authors": [
            "S. Van Cranenburgh",
            "S. Wang",
            "A. Vij",
            "F. Pereira",
            "J. Walker"
        ],
        "pdf_url": "http://arxiv.org/pdf/2101.11948v2"
    },
    {
        "title": "Decision Models for Selecting Federated Learning Architecture Patterns",
        "abstract": "Federated machine learning is growing fast in academia and industries as a solution to solve data hungriness and privacy issues in machine learning. Being a widely distributed system, federated machine learning requires various system design thinking. To better design a federated machine learning system, researchers have introduced multiple patterns and tactics that cover various system design aspects. However, the multitude of patterns leaves the designers confused about when and which pattern to adopt. In this paper, we present a set of decision models for the selection of patterns for federated machine learning architecture design based on a systematic literature review on federated machine learning, to assist designers and architects who have limited knowledge of federated machine learning. Each decision model maps functional and non-functional requirements of federated machine learning systems to a set of patterns. We also clarify the drawbacks of the patterns. We evaluated the decision models by mapping the decision patterns to concrete federated machine learning architectures by big tech firms to assess the models' correctness and usefulness. The evaluation results indicate that the proposed decision models are able to bring structure to the federated machine learning architecture design process and help explicitly articulate the design rationale.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2204.13291v3",
        "keywords": "cs.LG, cs.SE",
        "subject_areas": "cs.LG, cs.SE",
        "authors": [
            "Sin Kit Lo",
            "Qinghua Lu",
            "Hye-Young Paik",
            "Liming Zhu"
        ],
        "pdf_url": "http://arxiv.org/pdf/2204.13291v3"
    },
    {
        "title": "BPMN4sML: A BPMN Extension for Serverless Machine Learning. Technology   Independent and Interoperable Modeling of Machine Learning Workflows and   their Serverless Deployment Orchestration",
        "abstract": "Machine learning (ML) continues to permeate all layers of academia, industry and society. Despite its successes, mental frameworks to capture and represent machine learning workflows in a consistent and coherent manner are lacking. For instance, the de facto process modeling standard, Business Process Model and Notation (BPMN), managed by the Object Management Group, is widely accepted and applied. However, it is short of specific support to represent machine learning workflows. Further, the number of heterogeneous tools for deployment of machine learning solutions can easily overwhelm practitioners. Research is needed to align the process from modeling to deploying ML workflows.   We analyze requirements for standard based conceptual modeling for machine learning workflows and their serverless deployment. Confronting the shortcomings with respect to consistent and coherent modeling of ML workflows in a technology independent and interoperable manner, we extend BPMN's Meta-Object Facility (MOF) metamodel and the corresponding notation and introduce BPMN4sML (BPMN for serverless machine learning). Our extension BPMN4sML follows the same outline referenced by the Object Management Group (OMG) for BPMN. We further address the heterogeneity in deployment by proposing a conceptual mapping to convert BPMN4sML models to corresponding deployment models using TOSCA.   BPMN4sML allows technology-independent and interoperable modeling of machine learning workflows of various granularity and complexity across the entire machine learning lifecycle. It aids in arriving at a shared and standardized language to communicate ML solutions. Moreover, it takes the first steps toward enabling conversion of ML workflow model diagrams to corresponding deployment models for serverless deployment via TOSCA.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2208.02030v1",
        "keywords": "cs.SE, cs.LG",
        "subject_areas": "cs.SE, cs.LG",
        "authors": [
            "Laurens Martin Tetzlaff"
        ],
        "pdf_url": "http://arxiv.org/pdf/2208.02030v1"
    },
    {
        "title": "BigDB: Automatic Machine Learning Optimizer",
        "abstract": "In this short vision paper, we introduce a machine learning optimizer for data management and describe its architecture and main functionality.",
        "publication_year": "2013",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1301.1575v1",
        "keywords": "cs.DB",
        "subject_areas": "cs.DB",
        "authors": [
            "Anna Pyayt",
            "Michael Gubanov"
        ],
        "pdf_url": "http://arxiv.org/pdf/1301.1575v1"
    },
    {
        "title": "Piecewise Linear Multilayer Perceptrons and Dropout",
        "abstract": "We propose a new type of hidden layer for a multilayer perceptron, and demonstrate that it obtains the best reported performance for an MLP on the MNIST dataset.",
        "publication_year": "2013",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1301.5088v1",
        "keywords": "stat.ML, cs.LG",
        "subject_areas": "stat.ML, cs.LG",
        "authors": [
            "Ian J. Goodfellow"
        ],
        "pdf_url": "http://arxiv.org/pdf/1301.5088v1"
    },
    {
        "title": "A Kernel for Hierarchical Parameter Spaces",
        "abstract": "We define a family of kernels for mixed continuous/discrete hierarchical parameter spaces and show that they are positive definite.",
        "publication_year": "2013",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1310.5738v1",
        "keywords": "stat.ML, cs.LG",
        "subject_areas": "stat.ML, cs.LG",
        "authors": [
            "Frank Hutter",
            "Michael A. Osborne"
        ],
        "pdf_url": "http://arxiv.org/pdf/1310.5738v1"
    },
    {
        "title": "Indexing Cost Sensitive Prediction",
        "abstract": "Predictive models are often used for real-time decision making. However, typical machine learning techniques ignore feature evaluation cost, and focus solely on the accuracy of the machine learning models obtained utilizing all the features available. We develop algorithms and indexes to support cost-sensitive prediction, i.e., making decisions using machine learning models taking feature evaluation cost into account. Given an item and a online computation cost (i.e., time) budget, we present two approaches to return an appropriately chosen machine learning model that will run within the specified time on the given item. The first approach returns the optimal machine learning model, i.e., one with the highest accuracy, that runs within the specified time, but requires significant up-front precomputation time. The second approach returns a possibly sub- optimal machine learning model, but requires little up-front precomputation time. We study these two algorithms in detail and characterize the scenarios (using real and synthetic data) in which each performs well. Unlike prior work that focuses on a narrow domain or a specific algorithm, our techniques are very general: they apply to any cost-sensitive prediction scenario on any machine learning algorithm.",
        "publication_year": "2014",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1408.4072v1",
        "keywords": "cs.LG, cs.DB, cs.DS",
        "subject_areas": "cs.LG, cs.DB, cs.DS",
        "authors": [
            "Leilani Battle",
            "Edward Benson",
            "Aditya Parameswaran",
            "Eugene Wu"
        ],
        "pdf_url": "http://arxiv.org/pdf/1408.4072v1"
    },
    {
        "title": "Identifying and Harnessing the Building Blocks of Machine Learning   Pipelines for Sensible Initialization of a Data Science Automation Tool",
        "abstract": "As data science continues to grow in popularity, there will be an increasing need to make data science tools more scalable, flexible, and accessible. In particular, automated machine learning (AutoML) systems seek to automate the process of designing and optimizing machine learning pipelines. In this chapter, we present a genetic programming-based AutoML system called TPOT that optimizes a series of feature preprocessors and machine learning models with the goal of maximizing classification accuracy on a supervised classification problem. Further, we analyze a large database of pipelines that were previously used to solve various supervised classification problems and identify 100 short series of machine learning operations that appear the most frequently, which we call the building blocks of machine learning pipelines. We harness these building blocks to initialize TPOT with promising solutions, and find that this sensible initialization method significantly improves TPOT's performance on one benchmark at no cost of significantly degrading performance on the others. Thus, sensible initialization with machine learning pipeline building blocks shows promise for GP-based AutoML systems, and should be further refined in future work.",
        "publication_year": "2016",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1607.08878v1",
        "keywords": "cs.NE, cs.AI, cs.LG",
        "subject_areas": "cs.NE, cs.AI, cs.LG",
        "authors": [
            "Randal S. Olson",
            "Jason H. Moore"
        ],
        "pdf_url": "http://arxiv.org/pdf/1607.08878v1"
    },
    {
        "title": "A Note on Kaldi's PLDA Implementation",
        "abstract": "Some explanations to Kaldi's PLDA implementation to make formula derivation easier to catch.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1804.00403v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Ke Ding"
        ],
        "pdf_url": "http://arxiv.org/pdf/1804.00403v1"
    },
    {
        "title": "A review of possible effects of cognitive biases on the interpretation   of rule-based machine learning models",
        "abstract": "While the interpretability of machine learning models is often equated with their mere syntactic comprehensibility, we think that interpretability goes beyond that, and that human interpretability should also be investigated from the point of view of cognitive science. The goal of this paper is to discuss to what extent cognitive biases may affect human understanding of interpretable machine learning models, in particular of logical rules discovered from data. Twenty cognitive biases are covered, as are possible debiasing techniques that can be adopted by designers of machine learning algorithms and software. Our review transfers results obtained in cognitive psychology to the domain of machine learning, aiming to bridge the current gap between these two areas. It needs to be followed by empirical studies specifically focused on the machine learning domain.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1804.02969v7",
        "keywords": "stat.ML, cs.AI, cs.LG",
        "subject_areas": "stat.ML, cs.AI, cs.LG",
        "authors": [
            "Tomáš Kliegr",
            "Štěpán Bahník",
            "Johannes Fürnkranz"
        ],
        "pdf_url": "http://arxiv.org/pdf/1804.02969v7"
    },
    {
        "title": "Machine Learning: A Dark Side of Cancer Computing",
        "abstract": "Cancer analysis and prediction is the utmost important research field for well-being of humankind. The Cancer data are analyzed and predicted using machine learning algorithms. Most of the researcher claims the accuracy of the predicted results within 99%. However, we show that machine learning algorithms can easily predict with an accuracy of 100% on Wisconsin Diagnostic Breast Cancer dataset. We show that the method of gaining accuracy is an unethical approach that we can easily mislead the algorithms. In this paper, we exploit the weakness of Machine Learning algorithms. We perform extensive experiments for the correctness of our results to exploit the weakness of machine learning algorithms. The methods are rigorously evaluated to validate our claim. In addition, this paper focuses on correctness of accuracy. This paper report three key outcomes of the experiments, namely, correctness of accuracies, significance of minimum accuracy, and correctness of machine learning algorithms.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1903.07167v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Ripon Patgiri",
            "Sabuzima Nayak",
            "Tanya Akutota",
            "Bishal Paul"
        ],
        "pdf_url": "http://arxiv.org/pdf/1903.07167v1"
    },
    {
        "title": "Performance Analysis on Machine Learning-Based Channel Estimation",
        "abstract": "Recently, machine learning-based channel estimation has attracted much attention. The performance of machine learning-based estimation has been validated by simulation experiments. However, little attention has been paid to the theoretical performance analysis. In this paper, we investigate the mean square error (MSE) performance of machine learning-based estimation. Hypothesis testing is employed to analyze its MSE upper bound. Furthermore, we build a statistical model for hypothesis testing, which holds when the linear learning module with a low input dimension is used in machine learning-based channel estimation, and derive a clear analytical relation between the size of the training data and performance. Then, we simulate the machine learning-based channel estimation in orthogonal frequency division multiplexing (OFDM) systems to verify our analysis results. Finally, the design considerations for the situation where only limited training data is available are discussed. In this situation, our analysis results can be applied to assess the performance and support the design of machine learning-based channel estimation.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1911.03886v2",
        "keywords": "eess.SP, cs.LG",
        "subject_areas": "eess.SP, cs.LG",
        "authors": [
            "Kai Mei",
            "Jun Liu",
            "Xiaochen Zhang",
            "Nandana Rajatheva",
            "Jibo Wei"
        ],
        "pdf_url": "http://arxiv.org/pdf/1911.03886v2"
    },
    {
        "title": "Forbidden knowledge in machine learning -- Reflections on the limits of   research and publication",
        "abstract": "Certain research strands can yield \"forbidden knowledge\". This term refers to knowledge that is considered too sensitive, dangerous or taboo to be produced or shared. Discourses about such publication restrictions are already entrenched in scientific fields like IT security, synthetic biology or nuclear physics research. This paper makes the case for transferring this discourse to machine learning research. Some machine learning applications can very easily be misused and unfold harmful consequences, for instance with regard to generative video or text synthesis, personality analysis, behavior manipulation, software vulnerability detection and the like. Up to now, the machine learning research community embraces the idea of open access. However, this is opposed to precautionary efforts to prevent the malicious use of machine learning applications. Information about or from such applications may, if improperly disclosed, cause harm to people, organizations or whole societies. Hence, the goal of this work is to outline norms that can help to decide whether and when the dissemination of such information should be prevented. It proposes review parameters for the machine learning community to establish an ethical framework on how to deal with forbidden knowledge and dual-use applications.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1911.08603v1",
        "keywords": "cs.LG, cs.AI, cs.CY, stat.ML",
        "subject_areas": "cs.LG, cs.AI, cs.CY, stat.ML",
        "authors": [
            "Thilo Hagendorff"
        ],
        "pdf_url": "http://arxiv.org/pdf/1911.08603v1"
    },
    {
        "title": "Warning Signs in Communicating the Machine Learning Detection Results of   Misinformation with Individuals",
        "abstract": "With the prevalence of misinformation online, researchers have focused on developing various machine learning algorithms to detect fake news. However, users' perception of machine learning outcomes and related behaviors have been widely ignored. Hence, this paper proposed to bridge this gap by studying how to pass the detection results of machine learning to the users, and aid their decisions in handling misinformation. An online experiment was conducted, to evaluate the effect of the proposed machine learning warning sign against a control condition. We examined participants' detection and sharing of news. The data showed that warning sign's effects on participants' trust toward the fake news were not significant. However, we found that people's uncertainty about the authenticity of the news dropped with the presence of the machine learning warning sign. We also found that social media experience had effects on users' trust toward the fake news, and age and social media experience had effects on users' sharing decision. Therefore, the results indicate that there are many factors worth studying that affect people's trust in the news. Moreover, the warning sign in communicating machine learning detection results is different from ordinary warnings and needs more detailed research and design. These findings hold important implications for the design of machine learning warnings.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1911.11920v1",
        "keywords": "cs.HC, H.5.2",
        "subject_areas": "cs.HC, H.5.2",
        "authors": [
            "Limeng Cui"
        ],
        "pdf_url": "http://arxiv.org/pdf/1911.11920v1"
    },
    {
        "title": "Arabic Offensive Language Detection Using Machine Learning and Ensemble   Machine Learning Approaches",
        "abstract": "This study aims at investigating the effect of applying single learner machine learning approach and ensemble machine learning approach for offensive language detection on Arabic language. Classifying Arabic social media text is a very challenging task due to the ambiguity and informality of the written format of the text. Arabic language has multiple dialects with diverse vocabularies and structures, which increase the complexity of obtaining high classification performance. Our study shows significant impact for applying ensemble machine learning approach over the single learner machine learning approach. Among the trained ensemble machine learning classifiers, bagging performs the best in offensive language detection with F1 score of 88%, which exceeds the score obtained by the best single learner classifier by 6%. Our findings highlight the great opportunities of investing more efforts in promoting the ensemble machine learning approach solutions for offensive language detection models.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2005.08946v1",
        "keywords": "cs.CL, 68W99",
        "subject_areas": "cs.CL, 68W99",
        "authors": [
            "Fatemah Husain"
        ],
        "pdf_url": "http://arxiv.org/pdf/2005.08946v1"
    },
    {
        "title": "Machine Learning for Public Administration Research, with Application to   Organizational Reputation",
        "abstract": "Machine learning methods have gained a great deal of popularity in recent years among public administration scholars and practitioners. These techniques open the door to the analysis of text, image and other types of data that allow us to test foundational theories of public administration and to develop new theories. Despite the excitement surrounding machine learning methods, clarity regarding their proper use and potential pitfalls is lacking. This paper attempts to fill this gap in the literature through providing a machine learning \"guide to practice\" for public administration scholars and practitioners. Here, we take a foundational view of machine learning and describe how these methods can enrich public administration research and practice through their ability develop new measures, tap into new sources of data and conduct statistical inference and causal inference in a principled manner. We then turn our attention to the pitfalls of using these methods such as unvalidated measures and lack of interpretability. Finally, we demonstrate how machine learning techniques can help us learn about organizational reputation in federal agencies through an illustrated example using tweets from 13 executive federal agencies.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1805.05409v2",
        "keywords": "cs.CY, cs.LG, stat.ML",
        "subject_areas": "cs.CY, cs.LG, stat.ML",
        "authors": [
            "L. Jason Anastasopoulos",
            "Andrew B. Whitford"
        ],
        "pdf_url": "http://arxiv.org/pdf/1805.05409v2"
    },
    {
        "title": "Open Problems in Engineering and Quality Assurance of Safety Critical   Machine Learning Systems",
        "abstract": "Fatal accidents are a major issue hindering the wide acceptance of safety-critical systems using machine-learning and deep-learning models, such as automated-driving vehicles. Quality assurance frameworks are required for such machine learning systems, but there are no widely accepted and established quality-assurance concepts and techniques. At the same time, open problems and the relevant technical fields are not organized. To establish standard quality assurance frameworks, it is necessary to visualize and organize these open problems in an interdisciplinary way, so that the experts from many different technical fields may discuss these problems in depth and develop solutions. In the present study, we identify, classify, and explore the open problems in quality assurance of safety-critical machine-learning systems, and their relevant corresponding industry and technological trends, using automated-driving vehicles as an example. Our results show that addressing these open problems requires incorporating knowledge from several different technological and industrial fields, including the automobile industry, statistics, software engineering, and machine learning.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1812.03057v1",
        "keywords": "cs.CY, cs.LG, stat.ML",
        "subject_areas": "cs.CY, cs.LG, stat.ML",
        "authors": [
            "Hiroshi Kuwajima",
            "Hirotoshi Yasuoka",
            "Toshihiro Nakae"
        ],
        "pdf_url": "http://arxiv.org/pdf/1812.03057v1"
    },
    {
        "title": "Robust Coreset Construction for Distributed Machine Learning",
        "abstract": "Coreset, which is a summary of the original dataset in the form of a small weighted set in the same sample space, provides a promising approach to enable machine learning over distributed data. Although viewed as a proxy of the original dataset, each coreset is only designed to approximate the cost function of a specific machine learning problem, and thus different coresets are often required to solve different machine learning problems, increasing the communication overhead. We resolve this dilemma by developing robust coreset construction algorithms that can support a variety of machine learning problems. Motivated by empirical evidence that suitably-weighted k-clustering centers provide a robust coreset, we harden the observation by establishing theoretical conditions under which the coreset provides a guaranteed approximation for a broad range of machine learning problems, and developing both centralized and distributed algorithms to generate coresets satisfying the conditions. The robustness of the proposed algorithms is verified through extensive experiments on diverse datasets with respect to both supervised and unsupervised learning problems.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1904.05961v3",
        "keywords": "cs.LG, cs.DS, stat.ML",
        "subject_areas": "cs.LG, cs.DS, stat.ML",
        "authors": [
            "Hanlin Lu",
            "Ming-Ju Li",
            "Ting He",
            "Shiqiang Wang",
            "Vijaykrishnan Narayanan",
            "Kevin S Chan"
        ],
        "pdf_url": "http://arxiv.org/pdf/1904.05961v3"
    },
    {
        "title": "Benchmark and Survey of Automated Machine Learning Frameworks",
        "abstract": "Machine learning (ML) has become a vital part in many aspects of our daily life. However, building well performing machine learning applications requires highly specialized data scientists and domain experts. Automated machine learning (AutoML) aims to reduce the demand for data scientists by enabling domain experts to build machine learning applications automatically without extensive knowledge of statistics and machine learning. This paper is a combination of a survey on current AutoML methods and a benchmark of popular AutoML frameworks on real data sets. Driven by the selected frameworks for evaluation, we summarize and review important AutoML techniques and methods concerning every step in building an ML pipeline. The selected AutoML frameworks are evaluated on 137 data sets from established AutoML benchmark suits.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1904.12054v5",
        "keywords": "cs.LG, cs.AI, stat.ML",
        "subject_areas": "cs.LG, cs.AI, stat.ML",
        "authors": [
            "Marc-André Zöller",
            "Marco F. Huber"
        ],
        "pdf_url": "http://arxiv.org/pdf/1904.12054v5"
    },
    {
        "title": "Towards automated kernel selection in machine learning systems: A SYCL   case study",
        "abstract": "Automated tuning of compute kernels is a popular area of research, mainly focused on finding optimal kernel parameters for a problem with fixed input sizes. This approach is good for deploying machine learning models, where the network topology is constant, but machine learning research often involves changing network topologies and hyperparameters. Traditional kernel auto-tuning has limited impact in this case; a more general selection of kernels is required for libraries to accelerate machine learning research.   In this paper we present initial results using machine learning to select kernels in a case study deploying high performance SYCL kernels in libraries that target a range of heterogeneous devices from desktop GPUs to embedded accelerators. The techniques investigated apply more generally and could similarly be integrated with other heterogeneous programming systems. By combining auto-tuning and machine learning these kernel selection processes can be deployed with little developer effort to achieve high performance on new hardware.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2003.06795v1",
        "keywords": "cs.LG, cs.PF, stat.ML",
        "subject_areas": "cs.LG, cs.PF, stat.ML",
        "authors": [
            "John Lawson"
        ],
        "pdf_url": "http://arxiv.org/pdf/2003.06795v1"
    },
    {
        "title": "Bayesian Optimization is Superior to Random Search for Machine Learning   Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020",
        "abstract": "This paper presents the results and insights from the black-box optimization (BBO) challenge at NeurIPS 2020 which ran from July-October, 2020. The challenge emphasized the importance of evaluating derivative-free optimizers for tuning the hyperparameters of machine learning models. This was the first black-box optimization challenge with a machine learning emphasis. It was based on tuning (validation set) performance of standard machine learning models on real datasets. This competition has widespread impact as black-box optimization (e.g., Bayesian optimization) is relevant for hyperparameter tuning in almost every machine learning project as well as many applications outside of machine learning. The final leaderboard was determined using the optimization performance on held-out (hidden) objective functions, where the optimizers ran without human intervention. Baselines were set using the default settings of several open-source black-box optimization packages as well as random search.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2104.10201v2",
        "keywords": "cs.LG, cs.AI, stat.ML",
        "subject_areas": "cs.LG, cs.AI, stat.ML",
        "authors": [
            "Ryan Turner",
            "David Eriksson",
            "Michael McCourt",
            "Juha Kiili",
            "Eero Laaksonen",
            "Zhen Xu",
            "Isabelle Guyon"
        ],
        "pdf_url": "http://arxiv.org/pdf/2104.10201v2"
    },
    {
        "title": "The Fairness Field Guide: Perspectives from Social and Formal Sciences",
        "abstract": "Over the past several years, a slew of different methods to measure the fairness of a machine learning model have been proposed. However, despite the growing number of publications and implementations, there is still a critical lack of literature that explains the interplay of fair machine learning with the social sciences of philosophy, sociology, and law. We hope to remedy this issue by accumulating and expounding upon the thoughts and discussions of fair machine learning produced by both social and formal (specifically machine learning and statistics) sciences in this field guide. Specifically, in addition to giving the mathematical and algorithmic backgrounds of several popular statistical and causal-based fair machine learning methods, we explain the underlying philosophical and legal thoughts that support them. Further, we explore several criticisms of the current approaches to fair machine learning from sociological and philosophical viewpoints. It is our hope that this field guide will help fair machine learning practitioners better understand how their algorithms align with important humanistic values (such as fairness) and how we can, as a field, design methods and metrics to better serve oppressed and marginalized populaces.",
        "publication_year": "2022",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2201.05216v2",
        "keywords": "cs.AI, cs.CY, cs.LG, A.1, I.2.0, J.4",
        "subject_areas": "cs.AI, cs.CY, cs.LG, A.1, I.2.0, J.4",
        "authors": [
            "Alycia N. Carey",
            "Xintao Wu"
        ],
        "pdf_url": "http://arxiv.org/pdf/2201.05216v2"
    },
    {
        "title": "Exponential Convergence of the Deep Neural Network Approximation for   Analytic Functions",
        "abstract": "We prove that for analytic functions in low dimension, the convergence rate of the deep neural network approximation is exponential.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1807.00297v1",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Weinan E",
            "Qingcan Wang"
        ],
        "pdf_url": "http://arxiv.org/pdf/1807.00297v1"
    },
    {
        "title": "RuleMatrix: Visualizing and Understanding Classifiers with Rules",
        "abstract": "With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand, diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models. By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior. We design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. We evaluate the effectiveness of RuleMatrix via two use cases and a usability study.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1807.06228v1",
        "keywords": "cs.LG, cs.AI, cs.HC, stat.ML",
        "subject_areas": "cs.LG, cs.AI, cs.HC, stat.ML",
        "authors": [
            "Yao Ming",
            "Huamin Qu",
            "Enrico Bertini"
        ],
        "pdf_url": "http://arxiv.org/pdf/1807.06228v1"
    },
    {
        "title": "Application of Machine Learning in Rock Facies Classification with   Physics-Motivated Feature Augmentation",
        "abstract": "With recent progress in algorithms and the availability of massive amounts of computation power, application of machine learning techniques is becoming a hot topic in the oil and gas industry. One of the most promising aspects to apply machine learning to the upstream field is the rock facies classification in reservoir characterization, which is crucial in determining the net pay thickness of reservoirs, thus a definitive factor in drilling decision making process. For complex machine learning tasks like facies classification, feature engineering is often critical. This paper shows the inclusion of physics-motivated feature interaction in feature augmentation can further improve the capability of machine learning in rock facies classification. We demonstrate this approach with the SEG 2016 machine learning contest dataset and the top winning algorithms. The improvement is roboust and can be $\\sim5\\%$ better than current existing best F-1 score, where F-1 is an evaluation metric used to quantify average prediction accuracy.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1808.09856v1",
        "keywords": "stat.ML, cs.LG, physics.geo-ph",
        "subject_areas": "stat.ML, cs.LG, physics.geo-ph",
        "authors": [
            "Jie Chen",
            "Yu Zeng"
        ],
        "pdf_url": "http://arxiv.org/pdf/1808.09856v1"
    },
    {
        "title": "Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?",
        "abstract": "No.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1902.02322v1",
        "keywords": "cs.LG, cs.AI, cs.CR, stat.ML",
        "subject_areas": "cs.LG, cs.AI, cs.CR, stat.ML",
        "authors": [
            "Nicholas Carlini"
        ],
        "pdf_url": "http://arxiv.org/pdf/1902.02322v1"
    },
    {
        "title": "A Review of Machine Learning Classification Using Quantum Annealing for   Real-world Applications",
        "abstract": "Optimizing the training of a machine learning pipeline helps in reducing training costs and improving model performance. One such optimizing strategy is quantum annealing, which is an emerging computing paradigm that has shown potential in optimizing the training of a machine learning model. The implementation of a physical quantum annealer has been realized by D-Wave systems and is available to the research community for experiments. Recent experimental results on a variety of machine learning applications using quantum annealing have shown interesting results where the performance of classical machine learning techniques is limited by limited training data and high dimensional features. This article explores the application of D-Wave's quantum annealer for optimizing machine learning pipelines for real-world classification problems. We review the application domains on which a physical quantum annealer has been used to train machine learning classifiers. We discuss and analyze the experiments performed on the D-Wave quantum annealer for applications such as image recognition, remote sensing imagery, computational biology, and particle physics. We discuss the possible advantages and the problems for which quantum annealing is likely to be advantageous over classical computation.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2106.02964v1",
        "keywords": "quant-ph, cs.LG",
        "subject_areas": "quant-ph, cs.LG",
        "authors": [
            "Rajdeep Kumar Nath",
            "Himanshu Thapliyal",
            "Travis S. Humble"
        ],
        "pdf_url": "http://arxiv.org/pdf/2106.02964v1"
    },
    {
        "title": "Learning proofs for the classification of nilpotent semigroups",
        "abstract": "Machine learning is applied to find proofs, with smaller or smallest numbers of nodes, for the classification of 4-nilpotent semigroups.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2106.03015v1",
        "keywords": "cs.LG, math.LO, math.RA, 68T15 (Primary) 20M10, 03F07, 03B35 (Secondary)",
        "subject_areas": "cs.LG, math.LO, math.RA, 68T15 (Primary) 20M10, 03F07, 03B35 (Secondary)",
        "authors": [
            "Carlos Simpson"
        ],
        "pdf_url": "http://arxiv.org/pdf/2106.03015v1"
    },
    {
        "title": "PyKale: Knowledge-Aware Machine Learning from Multiple Sources in Python",
        "abstract": "Machine learning is a general-purpose technology holding promises for many interdisciplinary research problems. However, significant barriers exist in crossing disciplinary boundaries when most machine learning tools are developed in different areas separately. We present Pykale - a Python library for knowledge-aware machine learning on graphs, images, texts, and videos to enable and accelerate interdisciplinary research. We formulate new green machine learning guidelines based on standard software engineering practices and propose a novel pipeline-based application programming interface (API). PyKale focuses on leveraging knowledge from multiple sources for accurate and interpretable prediction, thus supporting multimodal learning and transfer learning (particularly domain adaptation) with latest deep learning and dimensionality reduction models. We build PyKale on PyTorch and leverage the rich PyTorch ecosystem. Our pipeline-based API design enforces standardization and minimalism, embracing green machine learning concepts via reducing repetitions and redundancy, reusing existing resources, and recycling learning models across areas. We demonstrate its interdisciplinary nature via examples in bioinformatics, knowledge graph, image/video recognition, and medical imaging.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2106.09756v1",
        "keywords": "cs.LG, cs.AI, cs.CV, stat.ML",
        "subject_areas": "cs.LG, cs.AI, cs.CV, stat.ML",
        "authors": [
            "Haiping Lu",
            "Xianyuan Liu",
            "Robert Turner",
            "Peizhen Bai",
            "Raivo E Koot",
            "Shuo Zhou",
            "Mustafa Chasmai",
            "Lawrence Schobs"
        ],
        "pdf_url": "http://arxiv.org/pdf/2106.09756v1"
    },
    {
        "title": "An efficient quantum algorithm for generative machine learning",
        "abstract": "A central task in the field of quantum computing is to find applications where quantum computer could provide exponential speedup over any classical computer. Machine learning represents an important field with broad applications where quantum computer may offer significant speedup. Several quantum algorithms for discriminative machine learning have been found based on efficient solving of linear algebraic problems, with potential exponential speedup in runtime under the assumption of effective input from a quantum random access memory. In machine learning, generative models represent another large class which is widely used for both supervised and unsupervised learning. Here, we propose an efficient quantum algorithm for machine learning based on a quantum generative model. We prove that our proposed model is exponentially more powerful to represent probability distributions compared with classical generative models and has exponential speedup in training and inference at least for some instances under a reasonable assumption in computational complexity theory. Our result opens a new direction for quantum machine learning and offers a remarkable example in which a quantum algorithm shows exponential improvement over any classical algorithm in an important application field.",
        "publication_year": "2017",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1711.02038v1",
        "keywords": "quant-ph, cs.LG, stat.ML",
        "subject_areas": "quant-ph, cs.LG, stat.ML",
        "authors": [
            "Xun Gao",
            "Zhengyu Zhang",
            "Luming Duan"
        ],
        "pdf_url": "http://arxiv.org/pdf/1711.02038v1"
    },
    {
        "title": "A conjugate prior for the Dirichlet distribution",
        "abstract": "This note investigates a conjugate class for the Dirichlet distribution class in the exponential family.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1811.05266v1",
        "keywords": "cs.LG, stat.ML, 60E99",
        "subject_areas": "cs.LG, stat.ML, 60E99",
        "authors": [
            "Jean-Marc Andreoli"
        ],
        "pdf_url": "http://arxiv.org/pdf/1811.05266v1"
    },
    {
        "title": "A Framework for Implementing Machine Learning on Omics Data",
        "abstract": "The potential benefits of applying machine learning methods to -omics data are becoming increasingly apparent, especially in clinical settings. However, the unique characteristics of these data are not always well suited to machine learning techniques. These data are often generated across different technologies in different labs, and frequently with high dimensionality. In this paper we present a framework for combining -omics data sets, and for handling high dimensional data, making -omics research more accessible to machine learning applications. We demonstrate the success of this framework through integration and analysis of multi-analyte data for a set of 3,533 breast cancers. We then use this data-set to predict breast cancer patient survival for individuals at risk of an impending event, with higher accuracy and lower variance than methods trained on individual data-sets. We hope that our pipelines for data-set generation and transformation will open up -omics data to machine learning researchers. We have made these freely available for noncommercial use at www.ccg.ai.",
        "publication_year": "2018",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1811.10455v1",
        "keywords": "cs.LG, cs.AI, q-bio.GN, stat.ML",
        "subject_areas": "cs.LG, cs.AI, q-bio.GN, stat.ML",
        "authors": [
            "Geoffroy Dubourg-Felonneau",
            "Timothy Cannings",
            "Fergal Cotter",
            "Hannah Thompson",
            "Nirmesh Patel",
            "John W Cassidy",
            "Harry W Clifford"
        ],
        "pdf_url": "http://arxiv.org/pdf/1811.10455v1"
    },
    {
        "title": "Two-stage Optimization for Machine Learning Workflow",
        "abstract": "Machines learning techniques plays a preponderant role in dealing with massive amount of data and are employed in almost every possible domain. Building a high quality machine learning model to be deployed in production is a challenging task, from both, the subject matter experts and the machine learning practitioners.   For a broader adoption and scalability of machine learning systems, the construction and configuration of machine learning workflow need to gain in automation. In the last few years, several techniques have been developed in this direction, known as autoML.   In this paper, we present a two-stage optimization process to build data pipelines and configure machine learning algorithms. First, we study the impact of data pipelines compared to algorithm configuration in order to show the importance of data preprocessing over hyperparameter tuning. The second part presents policies to efficiently allocate search time between data pipeline construction and algorithm configuration. Those policies are agnostic from the metaoptimizer. Last, we present a metric to determine if a data pipeline is specific or independent from the algorithm, enabling fine-grain pipeline pruning and meta-learning for the coldstart problem.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1907.00678v1",
        "keywords": "cs.LG, cs.AI",
        "subject_areas": "cs.LG, cs.AI",
        "authors": [
            "Alexandre Quemy"
        ],
        "pdf_url": "http://arxiv.org/pdf/1907.00678v1"
    },
    {
        "title": "Aleatoric and Epistemic Uncertainty in Machine Learning: An Introduction   to Concepts and Methods",
        "abstract": "The notion of uncertainty is of major importance in machine learning and constitutes a key element of machine learning methodology. In line with the statistical tradition, uncertainty has long been perceived as almost synonymous with standard probability and probabilistic predictions. Yet, due to the steadily increasing relevance of machine learning for practical applications and related issues such as safety requirements, new problems and challenges have recently been identified by machine learning scholars, and these problems may call for new methodological developments. In particular, this includes the importance of distinguishing between (at least) two different types of uncertainty, often referred to as aleatoric and epistemic. In this paper, we provide an introduction to the topic of uncertainty in machine learning as well as an overview of attempts so far at handling uncertainty in general and formalizing this distinction in particular.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1910.09457v3",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Eyke Hüllermeier",
            "Willem Waegeman"
        ],
        "pdf_url": "http://arxiv.org/pdf/1910.09457v3"
    },
    {
        "title": "A Hierarchy of Limitations in Machine Learning",
        "abstract": "\"All models are wrong, but some are useful\", wrote George E. P. Box (1979). Machine learning has focused on the usefulness of probability models for prediction in social systems, but is only now coming to grips with the ways in which these models are wrong---and the consequences of those shortcomings. This paper attempts a comprehensive, structured overview of the specific conceptual, procedural, and statistical limitations of models in machine learning when applied to society. Machine learning modelers themselves can use the described hierarchy to identify possible failure points and think through how to address them, and consumers of machine learning models can know what to question when confronted with the decision about if, where, and how to apply machine learning. The limitations go from commitments inherent in quantification itself, through to showing how unmodeled dependencies can lead to cross-validation being overly optimistic as a way of assessing model performance.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2002.05193v2",
        "keywords": "cs.CY, cs.LG, econ.EM, math.ST, stat.ML, stat.TH, G.3; I.6.4; J.4",
        "subject_areas": "cs.CY, cs.LG, econ.EM, math.ST, stat.ML, stat.TH, G.3; I.6.4; J.4",
        "authors": [
            "Momin M. Malik"
        ],
        "pdf_url": "http://arxiv.org/pdf/2002.05193v2"
    },
    {
        "title": "The PHOTON Wizard -- Towards Educational Machine Learning Code   Generators",
        "abstract": "Despite the tremendous efforts to democratize machine learning, especially in applied-science, the application is still often hampered by the lack of coding skills. As we consider programmatic understanding key to building effective and efficient machine learning solutions, we argue for a novel educational approach that builds upon the accessibility and acceptance of graphical user interfaces to convey programming skills to an applied-science target group. We outline a proof-of-concept, open-source web application, the PHOTON Wizard, which dynamically translates GUI interactions into valid source code for the Python machine learning framework PHOTON. Thereby, users possessing theoretical machine learning knowledge gain key insights into the model development workflow as well as an intuitive understanding of custom implementations. Specifically, the PHOTON Wizard integrates the concept of Educational Machine Learning Code Generators to teach users how to write code for designing, training, optimizing and evaluating custom machine learning pipelines.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2002.05432v1",
        "keywords": "cs.SE, cs.LG",
        "subject_areas": "cs.SE, cs.LG",
        "authors": [
            "Ramona Leenings",
            "Nils Ralf Winter",
            "Kelvin Sarink",
            "Jan Ernsting",
            "Xiaoyi Jiang",
            "Udo Dannlowski",
            "Tim Hahn"
        ],
        "pdf_url": "http://arxiv.org/pdf/2002.05432v1"
    },
    {
        "title": "In-Machine-Learning Database: Reimagining Deep Learning with Old-School   SQL",
        "abstract": "In-database machine learning has been very popular, almost being a cliche. However, can we do it the other way around? In this work, we say \"yes\" by applying plain old SQL to deep learning, in a sense implementing deep learning algorithms with SQL. Most deep learning frameworks, as well as generic machine learning ones, share a de facto standard of multidimensional array operations, underneath fancier infrastructure such as automatic differentiation. As SQL tables can be regarded as generalisations of (multi-dimensional) arrays, we have found a way to express common deep learning operations in SQL, encouraging a different way of thinking and thus potentially novel models. In particular, one of the latest trend in deep learning was the introduction of sparsity in the name of graph convolutional networks, whereas we take sparsity almost for granted in the database world. As both databases and machine learning involve transformation of datasets, we hope this work can inspire further works utilizing the large body of existing wisdom, algorithms and technologies in the database field to advance the state of the art in machine learning, rather than merely integerating machine learning into databases.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2004.05366v2",
        "keywords": "cs.LG, cs.DB, stat.ML",
        "subject_areas": "cs.LG, cs.DB, stat.ML",
        "authors": [
            "Len Du"
        ],
        "pdf_url": "http://arxiv.org/pdf/2004.05366v2"
    },
    {
        "title": "Quantum machine learning and quantum biomimetics: A perspective",
        "abstract": "Quantum machine learning has emerged as an exciting and promising paradigm inside quantum technologies. It may permit, on the one hand, to carry out more efficient machine learning calculations by means of quantum devices, while, on the other hand, to employ machine learning techniques to better control quantum systems. Inside quantum machine learning, quantum reinforcement learning aims at developing \"intelligent\" quantum agents that may interact with the outer world and adapt to it, with the strategy of achieving some final goal. Another paradigm inside quantum machine learning is that of quantum autoencoders, which may allow one for employing fewer resources in a quantum device via a training process. Moreover, the field of quantum biomimetics aims at establishing analogies between biological and quantum systems, to look for previously inadvertent connections that may enable useful applications. Two recent examples are the concepts of quantum artificial life, as well as of quantum memristors. In this Perspective, we give an overview of these topics, describing the related research carried out by the scientific community.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2004.12076v2",
        "keywords": "quant-ph, cond-mat.mes-hall, cs.LG",
        "subject_areas": "quant-ph, cond-mat.mes-hall, cs.LG",
        "authors": [
            "Lucas Lamata"
        ],
        "pdf_url": "http://arxiv.org/pdf/2004.12076v2"
    },
    {
        "title": "A Framework for Fairer Machine Learning in Organizations",
        "abstract": "With the increase in adoption of machine learning tools by organizations risks of unfairness abound, especially when human decision processes in outcomes of socio-economic importance such as hiring, housing, lending, and admissions are automated. We reveal sources of unfair machine learning, review fairness criteria, and provide a framework which, if implemented, would enable an organization to both avoid implementing an unfair machine learning model, but also to avoid the common situation that as an algorithm learns with more data it can become unfair over time. Issues of behavioral ethics in machine learning implementations by organizations have not been thoroughly addressed in the literature, because many of the necessary concepts are dispersed across three literatures: ethics, machine learning, and management. Further, tradeoffs between fairness criteria in machine learning have not been addressed with regards to organizations. We advance the research by introducing an organizing framework for selecting and implementing fair algorithms in organizations.",
        "publication_year": "2020",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2009.04661v1",
        "keywords": "cs.CY, cs.LG, 68T05, I.2.6",
        "subject_areas": "cs.CY, cs.LG, 68T05, I.2.6",
        "authors": [
            "Lily Morse",
            "Mike H. M. Teodorescu",
            "Yazeed Awwad",
            "Gerald Kane"
        ],
        "pdf_url": "http://arxiv.org/pdf/2009.04661v1"
    },
    {
        "title": "New Trends in Quantum Machine Learning",
        "abstract": "Here we will give a perspective on new possible interplays between Machine Learning and Quantum Physics, including also practical cases and applications. We will explore the ways in which machine learning could benefit from new quantum technologies and algorithms to find new ways to speed up their computations by breakthroughs in physical hardware, as well as to improve existing models or devise new learning schemes in the quantum domain. Moreover, there are lots of experiments in quantum physics that do generate incredible amounts of data and machine learning would be a great tool to analyze those and make predictions, or even control the experiment itself. On top of that, data visualization techniques and other schemes borrowed from machine learning can be of great use to theoreticians to have better intuition on the structure of complex manifolds or to make predictions on theoretical models. This new research field, named as Quantum Machine Learning, is very rapidly growing since it is expected to provide huge advantages over its classical counterpart and deeper investigations are timely needed since they can be already tested on the already commercially available quantum machines.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2108.09664v1",
        "keywords": "quant-ph, cond-mat.dis-nn, cs.LG, stat.ML",
        "subject_areas": "quant-ph, cond-mat.dis-nn, cs.LG, stat.ML",
        "authors": [
            "Lorenzo Buffoni",
            "Filippo Caruso"
        ],
        "pdf_url": "http://arxiv.org/pdf/2108.09664v1"
    },
    {
        "title": "Application of Machine Learning in understanding plant virus   pathogenesis: Trends and perspectives on emergence, diagnosis, host-virus   interplay and management",
        "abstract": "Inclusion of high throughput technologies in the field of biology has generated massive amounts of biological data in the recent years. Now, transforming these huge volumes of data into knowledge is the primary challenge in computational biology. The traditional methods of data analysis have failed to carry out the task. Hence, researchers are turning to machine learning based approaches for the analysis of high-dimensional big data. In machine learning, once a model is trained with a training dataset, it can be applied on a testing dataset which is independent. In current times, deep learning algorithms further promote the application of machine learning in several field of biology including plant virology. Considering a significant progress in the application of machine learning in understanding plant virology, this review highlights an introductory note on machine learning and comprehensively discusses the trends and prospects of machine learning in diagnosis of viral diseases, understanding host-virus interplay and emergence of plant viruses.",
        "publication_year": "2021",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/2112.01998v1",
        "keywords": "cs.LG",
        "subject_areas": "cs.LG",
        "authors": [
            "Dibyendu Ghosh",
            "Srija Chakraborty",
            "Hariprasad Kodamana",
            "Supriya Chakraborty"
        ],
        "pdf_url": "http://arxiv.org/pdf/2112.01998v1"
    },
    {
        "title": "Explainable Machine Learning for Scientific Insights and Discoveries",
        "abstract": "Machine learning methods have been remarkably successful for a wide range of application areas in the extraction of essential information from data. An exciting and relatively recent development is the uptake of machine learning in the natural sciences, where the major goal is to obtain novel scientific insights and discoveries from observational or simulated data. A prerequisite for obtaining a scientific outcome is domain knowledge, which is needed to gain explainability, but also to enhance scientific consistency. In this article we review explainable machine learning in view of applications in the natural sciences and discuss three core elements which we identified as relevant in this context: transparency, interpretability, and explainability. With respect to these core elements, we provide a survey of recent scientific works that incorporate machine learning and the way that explainable machine learning is used in combination with domain knowledge from the application areas.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1905.08883v3",
        "keywords": "cs.LG, stat.ML",
        "subject_areas": "cs.LG, stat.ML",
        "authors": [
            "Ribana Roscher",
            "Bastian Bohn",
            "Marco F. Duarte",
            "Jochen Garcke"
        ],
        "pdf_url": "http://arxiv.org/pdf/1905.08883v3"
    },
    {
        "title": "Machine Learning for Fluid Mechanics",
        "abstract": "The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from field measurements, experiments and large-scale simulations at multiple spatiotemporal scales. Machine learning offers a wealth of techniques to extract information from data that could be translated into knowledge about the underlying fluid mechanics. Moreover, machine learning algorithms can augment domain knowledge and automate tasks related to flow control and optimization. This article presents an overview of past history, current developments, and emerging opportunities of machine learning for fluid mechanics. It outlines fundamental machine learning methodologies and discusses their uses for understanding, modeling, optimizing, and controlling fluid flows. The strengths and limitations of these methods are addressed from the perspective of scientific inquiry that considers data as an inherent part of modeling, experimentation, and simulation. Machine learning provides a powerful information processing framework that can enrich, and possibly even transform, current lines of fluid mechanics research and industrial applications.",
        "publication_year": "2019",
        "journal_name": "ArXiv",
        "doi": null,
        "scopus_identifier": "http://arxiv.org/abs/1905.11075v3",
        "keywords": "physics.flu-dyn, cs.LG, stat.ML",
        "subject_areas": "physics.flu-dyn, cs.LG, stat.ML",
        "authors": [
            "Steven Brunton",
            "Bernd Noack",
            "Petros Koumoutsakos"
        ],
        "pdf_url": "http://arxiv.org/pdf/1905.11075v3"
    }
]