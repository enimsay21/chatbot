[
  {
    "title": "Lecture Notes: Optimization for Machine Learning",
    "abstract": "Lecture notes on optimization for machine learning, derived from a course at\nPrinceton University and tutorials given in MLSS, Buenos Aires, as well as\nSimons Foundation, Berkeley.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-09-08",
    "authors": [
      "Elad Hazan"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1909.03550v1"
  },
  {
    "title": "Machine Learning for Clinical Predictive Analytics",
    "abstract": "In this chapter, we provide a brief overview of applying machine learning\ntechniques for clinical prediction tasks. We begin with a quick introduction to\nthe concepts of machine learning and outline some of the most common machine\nlearning algorithms. Next, we demonstrate how to apply the algorithms with\nappropriate toolkits to conduct machine learning experiments for clinical\nprediction tasks. The objectives of this chapter are to (1) understand the\nbasics of machine learning techniques and the reasons behind why they are\nuseful for solving clinical prediction problems, (2) understand the intuition\nbehind some machine learning models, including regression, decision trees, and\nsupport vector machines, and (3) understand how to apply these models to\nclinical prediction problems using publicly available datasets via case\nstudies.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-09-19",
    "authors": [
      "Wei-Hung Weng"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1909.09246v1"
  },
  {
    "title": "Towards Modular Machine Learning Solution Development: Benefits and\n  Trade-offs",
    "abstract": "Machine learning technologies have demonstrated immense capabilities in\nvarious domains. They play a key role in the success of modern businesses.\nHowever, adoption of machine learning technologies has a lot of untouched\npotential. Cost of developing custom machine learning solutions that solve\nunique business problems is a major inhibitor to far-reaching adoption of\nmachine learning technologies. We recognize that the monolithic nature\nprevalent in today's machine learning applications stands in the way of\nefficient and cost effective customized machine learning solution development.\nIn this work we explore the benefits of modular machine learning solutions and\ndiscuss how modular machine learning solutions can overcome some of the major\nsolution engineering limitations of monolithic machine learning solutions. We\nanalyze the trade-offs between modular and monolithic machine learning\nsolutions through three deep learning problems; one text based and the two\nimage based. Our experimental results show that modular machine learning\nsolutions have a promising potential to reap the solution engineering\nadvantages of modularity while gaining performance and data advantages in a way\nthe monolithic machine learning solutions do not permit.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2023-01-23",
    "authors": [
      "Samiyuru Menik",
      "Lakshmish Ramaswamy"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2301.09753v1"
  },
  {
    "title": "An Optimal Control View of Adversarial Machine Learning",
    "abstract": "I describe an optimal control view of adversarial machine learning, where the\ndynamical system is the machine learner, the input are adversarial actions, and\nthe control costs are defined by the adversary's goals to do harm and be hard\nto detect. This view encompasses many types of adversarial machine learning,\nincluding test-item attacks, training-data poisoning, and adversarial reward\nshaping. The view encourages adversarial machine learning researcher to utilize\nadvances in control theory and reinforcement learning.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2018-11-11",
    "authors": [
      "Xiaojin Zhu"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1811.04422v1"
  },
  {
    "title": "The Tribes of Machine Learning and the Realm of Computer Architecture",
    "abstract": "Machine learning techniques have influenced the field of computer\narchitecture like many other fields. This paper studies how the fundamental\nmachine learning techniques can be applied towards computer architecture\nproblems. We also provide a detailed survey of computer architecture research\nthat employs different machine learning methods. Finally, we present some\nfuture opportunities and the outstanding challenges that need to be overcome to\nexploit full potential of machine learning for computer architecture.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-12-07",
    "authors": [
      "Ayaz Akram",
      "Jason Lowe-Power"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2012.04105v1"
  },
  {
    "title": "A Machine Learning Tutorial for Operational Meteorology, Part I:\n  Traditional Machine Learning",
    "abstract": "Recently, the use of machine learning in meteorology has increased greatly.\nWhile many machine learning methods are not new, university classes on machine\nlearning are largely unavailable to meteorology students and are not required\nto become a meteorologist. The lack of formal instruction has contributed to\nperception that machine learning methods are 'black boxes' and thus end-users\nare hesitant to apply the machine learning methods in their every day workflow.\nTo reduce the opaqueness of machine learning methods and lower hesitancy\ntowards machine learning in meteorology, this paper provides a survey of some\nof the most common machine learning methods. A familiar meteorological example\nis used to contextualize the machine learning methods while also discussing\nmachine learning topics using plain language. The following machine learning\nmethods are demonstrated: linear regression; logistic regression; decision\ntrees; random forest; gradient boosted decision trees; naive Bayes; and support\nvector machines. Beyond discussing the different methods, the paper also\ncontains discussions on the general machine learning process as well as best\npractices to enable readers to apply machine learning to their own datasets.\nFurthermore, all code (in the form of Jupyter notebooks and Google Colaboratory\nnotebooks) used to make the examples in the paper is provided in an effort to\ncatalyse the use of machine learning in meteorology.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2022-04-15",
    "authors": [
      "Randy J. Chase",
      "David R. Harrison",
      "Amanda Burke",
      "Gary M. Lackmann",
      "Amy McGovern"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2204.07492v2"
  },
  {
    "title": "MLBench: How Good Are Machine Learning Clouds for Binary Classification\n  Tasks on Structured Data?",
    "abstract": "We conduct an empirical study of machine learning functionalities provided by\nmajor cloud service providers, which we call machine learning clouds. Machine\nlearning clouds hold the promise of hiding all the sophistication of running\nlarge-scale machine learning: Instead of specifying how to run a machine\nlearning task, users only specify what machine learning task to run and the\ncloud figures out the rest. Raising the level of abstraction, however, rarely\ncomes free - a performance penalty is possible. How good, then, are current\nmachine learning clouds on real-world machine learning workloads?\n  We study this question with a focus on binary classication problems. We\npresent mlbench, a novel benchmark constructed by harvesting datasets from\nKaggle competitions. We then compare the performance of the top winning code\navailable from Kaggle with that of running machine learning clouds from both\nAzure and Amazon on mlbench. Our comparative study reveals the strength and\nweakness of existing machine learning clouds and points out potential future\ndirections for improvement.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2017-07-29",
    "authors": [
      "Yu Liu",
      "Hantian Zhang",
      "Luyuan Zeng",
      "Wentao Wu",
      "Ce Zhang"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1707.09562v3"
  },
  {
    "title": "Data Pricing in Machine Learning Pipelines",
    "abstract": "Machine learning is disruptive. At the same time, machine learning can only\nsucceed by collaboration among many parties in multiple steps naturally as\npipelines in an eco-system, such as collecting data for possible machine\nlearning applications, collaboratively training models by multiple parties and\ndelivering machine learning services to end users. Data is critical and\npenetrating in the whole machine learning pipelines. As machine learning\npipelines involve many parties and, in order to be successful, have to form a\nconstructive and dynamic eco-system, marketplaces and data pricing are\nfundamental in connecting and facilitating those many parties. In this article,\nwe survey the principles and the latest research development of data pricing in\nmachine learning pipelines. We start with a brief review of data marketplaces\nand pricing desiderata. Then, we focus on pricing in three important steps in\nmachine learning pipelines. To understand pricing in the step of training data\ncollection, we review pricing raw data sets and data labels. We also\ninvestigate pricing in the step of collaborative training of machine learning\nmodels, and overview pricing machine learning models for end users in the step\nof machine learning deployment. We also discuss a series of possible future\ndirections.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2021-08-18",
    "authors": [
      "Zicun Cong",
      "Xuan Luo",
      "Pei Jian",
      "Feida Zhu",
      "Yong Zhang"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2108.07915v1"
  },
  {
    "title": "Understanding Bias in Machine Learning",
    "abstract": "Bias is known to be an impediment to fair decisions in many domains such as\nhuman resources, the public sector, health care etc. Recently, hope has been\nexpressed that the use of machine learning methods for taking such decisions\nwould diminish or even resolve the problem. At the same time, machine learning\nexperts warn that machine learning models can be biased as well. In this\narticle, our goal is to explain the issue of bias in machine learning from a\ntechnical perspective and to illustrate the impact that biased data can have on\na machine learning model. To reach such a goal, we develop interactive plots to\nvisualizing the bias learned from synthetic data.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-09-02",
    "authors": [
      "Jindong Gu",
      "Daniela Oelke"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1909.01866v1"
  },
  {
    "title": "Introduction to Machine Learning: Class Notes 67577",
    "abstract": "Introduction to Machine learning covering Statistical Inference (Bayes, EM,\nML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering),\nand PAC learning (the Formal model, VC dimension, Double Sampling theorem).",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2009-04-23",
    "authors": [
      "Amnon Shashua"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/0904.3664v1"
  },
  {
    "title": "Proceedings of the 2016 ICML Workshop on #Data4Good: Machine Learning in\n  Social Good Applications",
    "abstract": "This is the Proceedings of the ICML Workshop on #Data4Good: Machine Learning\nin Social Good Applications, which was held on June 24, 2016 in New York.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2016-07-08",
    "authors": [
      "Kush R. Varshney"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1607.02450v2"
  },
  {
    "title": "Mathematical Perspective of Machine Learning",
    "abstract": "We take a closer look at some theoretical challenges of Machine Learning as a\nfunction approximation, gradient descent as the default optimization algorithm,\nlimitations of fixed length and width networks and a different approach to RNNs\nfrom a mathematical perspective.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-07-03",
    "authors": [
      "Yarema Boryshchak"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2007.01503v1"
  },
  {
    "title": "A Unified Analytical Framework for Trustable Machine Learning and\n  Automation Running with Blockchain",
    "abstract": "Traditional machine learning algorithms use data from databases that are\nmutable, and therefore the data cannot be fully trusted. Also, the machine\nlearning process is difficult to automate. This paper proposes building a\ntrustable machine learning system by using blockchain technology, which can\nstore data in a permanent and immutable way. In addition, smart contracts are\nused to automate the machine learning process. This paper makes three\ncontributions. First, it establishes a link between machine learning technology\nand blockchain technology. Previously, machine learning and blockchain have\nbeen considered two independent technologies without an obvious link. Second,\nit proposes a unified analytical framework for trustable machine learning by\nusing blockchain technology. This unified framework solves both the\ntrustability and automation issues in machine learning. Third, it enables a\ncomputer to translate core machine learning implementation from a single thread\non a single machine to multiple threads on multiple machines running with\nblockchain by using a unified approach. The paper uses association rule mining\nas an example to demonstrate how trustable machine learning can be implemented\nwith blockchain, and it shows how this approach can be used to analyze opioid\nprescriptions to help combat the opioid crisis.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-03-21",
    "authors": [
      "Tao Wang"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1903.08801v1"
  },
  {
    "title": "Ten-year Survival Prediction for Breast Cancer Patients",
    "abstract": "This report assesses different machine learning approaches to 10-year\nsurvival prediction of breast cancer patients.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-11-02",
    "authors": [
      "Changmao Li",
      "Han He",
      "Yunze Hao",
      "Caleb Ziems"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1911.00776v1"
  },
  {
    "title": "A Survey of Optimization Methods from a Machine Learning Perspective",
    "abstract": "Machine learning develops rapidly, which has made many theoretical\nbreakthroughs and is widely applied in various fields. Optimization, as an\nimportant part of machine learning, has attracted much attention of\nresearchers. With the exponential growth of data amount and the increase of\nmodel complexity, optimization methods in machine learning face more and more\nchallenges. A lot of work on solving optimization problems or improving\noptimization methods in machine learning has been proposed successively. The\nsystematic retrospect and summary of the optimization methods from the\nperspective of machine learning are of great significance, which can offer\nguidance for both developments of optimization and machine learning research.\nIn this paper, we first describe the optimization problems in machine learning.\nThen, we introduce the principles and progresses of commonly used optimization\nmethods. Next, we summarize the applications and developments of optimization\nmethods in some popular machine learning fields. Finally, we explore and give\nsome challenges and open problems for the optimization in machine learning.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-06-17",
    "authors": [
      "Shiliang Sun",
      "Zehui Cao",
      "Han Zhu",
      "Jing Zhao"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1906.06821v2"
  },
  {
    "title": "Towards CRISP-ML(Q): A Machine Learning Process Model with Quality\n  Assurance Methodology",
    "abstract": "Machine learning is an established and frequently used technique in industry\nand academia but a standard process model to improve success and efficiency of\nmachine learning applications is still missing. Project organizations and\nmachine learning practitioners have a need for guidance throughout the life\ncycle of a machine learning application to meet business expectations. We\ntherefore propose a process model for the development of machine learning\napplications, that covers six phases from defining the scope to maintaining the\ndeployed machine learning application. The first phase combines business and\ndata understanding as data availability oftentimes affects the feasibility of\nthe project. The sixth phase covers state-of-the-art approaches for monitoring\nand maintenance of a machine learning applications, as the risk of model\ndegradation in a changing environment is eminent. With each task of the\nprocess, we propose quality assurance methodology that is suitable to adress\nchallenges in machine learning development that we identify in form of risks.\nThe methodology is drawn from practical experience and scientific literature\nand has proven to be general and stable. The process model expands on CRISP-DM,\na data mining process model that enjoys strong industry support but lacks to\naddress machine learning specific tasks. Our work proposes an industry and\napplication neutral process model tailored for machine learning applications\nwith focus on technical tasks for quality assurance.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-03-11",
    "authors": [
      "Stefan Studer",
      "Thanh Binh Bui",
      "Christian Drescher",
      "Alexander Hanuschkin",
      "Ludwig Winkler",
      "Steven Peters",
      "Klaus-Robert Mueller"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2003.05155v2"
  },
  {
    "title": "When Machine Learning Meets Privacy: A Survey and Outlook",
    "abstract": "The newly emerged machine learning (e.g. deep learning) methods have become a\nstrong driving force to revolutionize a wide range of industries, such as smart\nhealthcare, financial technology, and surveillance systems. Meanwhile, privacy\nhas emerged as a big concern in this machine learning-based artificial\nintelligence era. It is important to note that the problem of privacy\npreservation in the context of machine learning is quite different from that in\ntraditional data privacy protection, as machine learning can act as both friend\nand foe. Currently, the work on the preservation of privacy and machine\nlearning (ML) is still in an infancy stage, as most existing solutions only\nfocus on privacy problems during the machine learning process. Therefore, a\ncomprehensive study on the privacy preservation problems and machine learning\nis required. This paper surveys the state of the art in privacy issues and\nsolutions for machine learning. The survey covers three categories of\ninteractions between privacy and machine learning: (i) private machine\nlearning, (ii) machine learning aided privacy protection, and (iii) machine\nlearning-based privacy attack and corresponding protection schemes. The current\nresearch progress in each category is reviewed and the key challenges are\nidentified. Finally, based on our in-depth analysis of the area of privacy and\nmachine learning, we point out future research directions in this field.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-11-24",
    "authors": [
      "Bo Liu",
      "Ming Ding",
      "Sina Shaham",
      "Wenny Rahayu",
      "Farhad Farokhi",
      "Zihuai Lin"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2011.11819v1"
  },
  {
    "title": "Proceedings of the 29th International Conference on Machine Learning\n  (ICML-12)",
    "abstract": "This is an index to the papers that appear in the Proceedings of the 29th\nInternational Conference on Machine Learning (ICML-12). The conference was held\nin Edinburgh, Scotland, June 27th - July 3rd, 2012.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2012-07-19",
    "authors": [
      "John Langford",
      "Joelle Pineau"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1207.4676v2"
  },
  {
    "title": "Position Paper: Towards Transparent Machine Learning",
    "abstract": "Transparent machine learning is introduced as an alternative form of machine\nlearning, where both the model and the learning system are represented in\nsource code form. The goal of this project is to enable direct human\nunderstanding of machine learning models, giving us the ability to learn,\nverify, and refine them as programs. If solved, this technology could represent\na best-case scenario for the safety and security of AI systems going forward.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-11-12",
    "authors": [
      "Dustin Juliano"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1911.06612v1"
  },
  {
    "title": "Components of Machine Learning: Binding Bits and FLOPS",
    "abstract": "Many machine learning problems and methods are combinations of three\ncomponents: data, hypothesis space and loss function. Different machine\nlearning methods are obtained as combinations of different choices for the\nrepresentation of data, hypothesis space and loss function. After reviewing the\nmathematical structure of these three components, we discuss intrinsic\ntrade-offs between statistical and computational properties of machine learning\nmethods.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-10-25",
    "authors": [
      "Alexander Jung"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1910.12387v2"
  },
  {
    "title": "Private Machine Learning via Randomised Response",
    "abstract": "We introduce a general learning framework for private machine learning based\non randomised response. Our assumption is that all actors are potentially\nadversarial and as such we trust only to release a single noisy version of an\nindividual's datapoint. We discuss a general approach that forms a consistent\nway to estimate the true underlying machine learning model and demonstrate this\nin the case of logistic regression.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-01-14",
    "authors": [
      "David Barber"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2001.04942v2"
  },
  {
    "title": "Impact of Legal Requirements on Explainability in Machine Learning",
    "abstract": "The requirements on explainability imposed by European laws and their\nimplications for machine learning (ML) models are not always clear. In that\nperspective, our research analyzes explanation obligations imposed for private\nand public decision-making, and how they can be implemented by machine learning\ntechniques.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-07-10",
    "authors": [
      "Adrien Bibal",
      "Michael Lognoul",
      "Alexandre de Streel",
      "Benoît Frénay"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2007.05479v1"
  },
  {
    "title": "Machine Learning Potential Repository",
    "abstract": "This paper introduces a machine learning potential repository that includes\nPareto optimal machine learning potentials. It also shows the systematic\ndevelopment of accurate and fast machine learning potentials for a wide range\nof elemental systems. As a result, many Pareto optimal machine learning\npotentials are available in the repository from a website. Therefore, the\nrepository will help many scientists to perform accurate and fast atomistic\nsimulations.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-07-27",
    "authors": [
      "Atsuto Seko"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2007.14206v1"
  },
  {
    "title": "Quantum memristors for neuromorphic quantum machine learning",
    "abstract": "Quantum machine learning may permit to realize more efficient machine\nlearning calculations with near-term quantum devices. Among the diverse quantum\nmachine learning paradigms which are currently being considered, quantum\nmemristors are promising as a way of combining, in the same quantum hardware, a\nunitary evolution with the nonlinearity provided by the measurement and\nfeedforward. Thus, an efficient way of deploying neuromorphic quantum computing\nfor quantum machine learning may be enabled.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2024-12-25",
    "authors": [
      "Lucas Lamata"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2412.18979v1"
  },
  {
    "title": "AutoCompete: A Framework for Machine Learning Competition",
    "abstract": "In this paper, we propose AutoCompete, a highly automated machine learning\nframework for tackling machine learning competitions. This framework has been\nlearned by us, validated and improved over a period of more than two years by\nparticipating in online machine learning competitions. It aims at minimizing\nhuman interference required to build a first useful predictive model and to\nassess the practical difficulty of a given machine learning challenge. The\nproposed system helps in identifying data types, choosing a machine learn- ing\nmodel, tuning hyper-parameters, avoiding over-fitting and optimization for a\nprovided evaluation metric. We also observe that the proposed system produces\nbetter (or comparable) results with less runtime as compared to other\napproaches.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2015-07-08",
    "authors": [
      "Abhishek Thakur",
      "Artus Krohn-Grimberghe"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1507.02188v1"
  },
  {
    "title": "Towards A Rigorous Science of Interpretable Machine Learning",
    "abstract": "As machine learning systems become ubiquitous, there has been a surge of\ninterest in interpretable machine learning: systems that provide explanation\nfor their outputs. These explanations are often used to qualitatively assess\nother criteria such as safety or non-discrimination. However, despite the\ninterest in interpretability, there is very little consensus on what\ninterpretable machine learning is and how it should be measured. In this\nposition paper, we first define interpretability and describe when\ninterpretability is needed (and when it is not). Next, we suggest a taxonomy\nfor rigorous evaluation and expose open questions towards a more rigorous\nscience of interpretable machine learning.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2017-02-28",
    "authors": [
      "Finale Doshi-Velez",
      "Been Kim"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1702.08608v2"
  },
  {
    "title": "Infrastructure for Usable Machine Learning: The Stanford DAWN Project",
    "abstract": "Despite incredible recent advances in machine learning, building machine\nlearning applications remains prohibitively time-consuming and expensive for\nall but the best-trained, best-funded engineering organizations. This expense\ncomes not from a need for new and improved statistical models but instead from\na lack of systems and tools for supporting end-to-end machine learning\napplication development, from data preparation and labeling to\nproductionization and monitoring. In this document, we outline opportunities\nfor infrastructure supporting usable, end-to-end machine learning applications\nin the context of the nascent DAWN (Data Analytics for What's Next) project at\nStanford.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2017-05-22",
    "authors": [
      "Peter Bailis",
      "Kunle Olukotun",
      "Christopher Re",
      "Matei Zaharia"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1705.07538v2"
  },
  {
    "title": "Techniques for Interpretable Machine Learning",
    "abstract": "Interpretable machine learning tackles the important problem that humans\ncannot understand the behaviors of complex machine learning models and how\nthese models arrive at a particular decision. Although many approaches have\nbeen proposed, a comprehensive understanding of the achievements and challenges\nis still lacking. We provide a survey covering existing techniques to increase\nthe interpretability of machine learning models. We also discuss crucial issues\nthat the community should consider in future work such as designing\nuser-friendly explanations and developing comprehensive evaluation metrics to\nfurther push forward the area of interpretable machine learning.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2018-07-31",
    "authors": [
      "Mengnan Du",
      "Ninghao Liu",
      "Xia Hu"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1808.00033v3"
  },
  {
    "title": "Solving machine learning optimization problems using quantum computers",
    "abstract": "Classical optimization algorithms in machine learning often take a long time\nto compute when applied to a multi-dimensional problem and require a huge\namount of CPU and GPU resource. Quantum parallelism has a potential to speed up\nmachine learning algorithms. We describe a generic mathematical model to\nleverage quantum parallelism to speed-up machine learning algorithms. We also\napply quantum machine learning and quantum parallelism applied to a\n$3$-dimensional image that vary with time.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-11-17",
    "authors": [
      "Venkat R. Dasari",
      "Mee Seong Im",
      "Lubjana Beshaj"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1911.08587v1"
  },
  {
    "title": "Bayesian Optimization for Machine Learning : A Practical Guidebook",
    "abstract": "The engineering of machine learning systems is still a nascent field; relying\non a seemingly daunting collection of quickly evolving tools and best\npractices. It is our hope that this guidebook will serve as a useful resource\nfor machine learning practitioners looking to take advantage of Bayesian\noptimization techniques. We outline four example machine learning problems that\ncan be solved using open source machine learning libraries, and highlight the\nbenefits of using Bayesian optimization in the context of these common machine\nlearning applications.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2016-12-14",
    "authors": [
      "Ian Dewancker",
      "Michael McCourt",
      "Scott Clark"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1612.04858v1"
  },
  {
    "title": "Probabilistic Machine Learning for Healthcare",
    "abstract": "Machine learning can be used to make sense of healthcare data. Probabilistic\nmachine learning models help provide a complete picture of observed data in\nhealthcare. In this review, we examine how probabilistic machine learning can\nadvance healthcare. We consider challenges in the predictive model building\npipeline where probabilistic models can be beneficial including calibration and\nmissing data. Beyond predictive models, we also investigate the utility of\nprobabilistic machine learning models in phenotyping, in generative models for\nclinical use cases, and in reinforcement learning.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-09-23",
    "authors": [
      "Irene Y. Chen",
      "Shalmali Joshi",
      "Marzyeh Ghassemi",
      "Rajesh Ranganath"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2009.11087v1"
  },
  {
    "title": "Teaching Uncertainty Quantification in Machine Learning through Use\n  Cases",
    "abstract": "Uncertainty in machine learning is not generally taught as general knowledge\nin Machine Learning course curricula. In this paper we propose a short\ncurriculum for a course about uncertainty in machine learning, and complement\nthe course with a selection of use cases, aimed to trigger discussion and let\nstudents play with the concepts of uncertainty in a programming setting. Our\nuse cases cover the concept of output uncertainty, Bayesian neural networks and\nweight distributions, sources of uncertainty, and out of distribution\ndetection. We expect that this curriculum and set of use cases motivates the\ncommunity to adopt these important concepts into courses for safety in AI.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2021-08-19",
    "authors": [
      "Matias Valdenegro-Toro"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2108.08712v1"
  },
  {
    "title": "Lale: Consistent Automated Machine Learning",
    "abstract": "Automated machine learning makes it easier for data scientists to develop\npipelines by searching over possible choices for hyperparameters, algorithms,\nand even pipeline topologies. Unfortunately, the syntax for automated machine\nlearning tools is inconsistent with manual machine learning, with each other,\nand with error checks. Furthermore, few tools support advanced features such as\ntopology search or higher-order operators. This paper introduces Lale, a\nlibrary of high-level Python interfaces that simplifies and unifies automated\nmachine learning in a consistent way.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-07-04",
    "authors": [
      "Guillaume Baudart",
      "Martin Hirzel",
      "Kiran Kate",
      "Parikshit Ram",
      "Avraham Shinnar"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2007.01977v1"
  },
  {
    "title": "Differential Replication in Machine Learning",
    "abstract": "When deployed in the wild, machine learning models are usually confronted\nwith data and requirements that constantly vary, either because of changes in\nthe generating distribution or because external constraints change the\nenvironment where the model operates. To survive in such an ecosystem, machine\nlearning models need to adapt to new conditions by evolving over time. The idea\nof model adaptability has been studied from different perspectives. In this\npaper, we propose a solution based on reusing the knowledge acquired by the\nalready deployed machine learning models and leveraging it to train future\ngenerations. This is the idea behind differential replication of machine\nlearning models.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-07-15",
    "authors": [
      "Irene Unceta",
      "Jordi Nin",
      "Oriol Pujol"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2007.07981v1"
  },
  {
    "title": "Techniques for Automated Machine Learning",
    "abstract": "Automated machine learning (AutoML) aims to find optimal machine learning\nsolutions automatically given a machine learning problem. It could release the\nburden of data scientists from the multifarious manual tuning process and\nenable the access of domain experts to the off-the-shelf machine learning\nsolutions without extensive experience. In this paper, we review the current\ndevelopments of AutoML in terms of three categories, automated feature\nengineering (AutoFE), automated model and hyperparameter learning (AutoMHL),\nand automated deep learning (AutoDL). State-of-the-art techniques adopted in\nthe three categories are presented, including Bayesian optimization,\nreinforcement learning, evolutionary algorithm, and gradient-based approaches.\nWe summarize popular AutoML frameworks and conclude with current open\nchallenges of AutoML.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-07-21",
    "authors": [
      "Yi-Wei Chen",
      "Qingquan Song",
      "Xia Hu"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1907.08908v1"
  },
  {
    "title": "mlr3proba: An R Package for Machine Learning in Survival Analysis",
    "abstract": "As machine learning has become increasingly popular over the last few\ndecades, so too has the number of machine learning interfaces for implementing\nthese models. Whilst many R libraries exist for machine learning, very few\noffer extended support for survival analysis. This is problematic considering\nits importance in fields like medicine, bioinformatics, economics, engineering,\nand more. mlr3proba provides a comprehensive machine learning interface for\nsurvival analysis and connects with mlr3's general model tuning and\nbenchmarking facilities to provide a systematic infrastructure for survival\nmodeling and evaluation.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-08-18",
    "authors": [
      "Raphael Sonabend",
      "Franz J. Király",
      "Andreas Bender",
      "Bernd Bischl",
      "Michel Lang"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2008.08080v2"
  },
  {
    "title": "Introduction to Machine Learning for Physicians: A Survival Guide for\n  Data Deluge",
    "abstract": "Many modern research fields increasingly rely on collecting and analysing\nmassive, often unstructured, and unwieldy datasets. Consequently, there is\ngrowing interest in machine learning and artificial intelligence applications\nthat can harness this `data deluge'. This broad nontechnical overview provides\na gentle introduction to machine learning with a specific focus on medical and\nbiological applications. We explain the common types of machine learning\nalgorithms and typical tasks that can be solved, illustrating the basics with\nconcrete examples from healthcare. Lastly, we provide an outlook on open\nchallenges, limitations, and potential impacts of machine-learning-powered\nmedicine.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2022-12-23",
    "authors": [
      "Ričards Marcinkevičs",
      "Ece Ozkan",
      "Julia E. Vogt"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2212.12303v1"
  },
  {
    "title": "Evaluation Challenges for Geospatial ML",
    "abstract": "As geospatial machine learning models and maps derived from their predictions\nare increasingly used for downstream analyses in science and policy, it is\nimperative to evaluate their accuracy and applicability. Geospatial machine\nlearning has key distinctions from other learning paradigms, and as such, the\ncorrect way to measure performance of spatial machine learning outputs has been\na topic of debate. In this paper, I delineate unique challenges of model\nevaluation for geospatial machine learning with global or remotely sensed\ndatasets, culminating in concrete takeaways to improve evaluations of\ngeospatial model performance.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2023-03-31",
    "authors": [
      "Esther Rolf"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2303.18087v1"
  },
  {
    "title": "Machine learning-assisted close-set X-ray diffraction phase\n  identification of transition metals",
    "abstract": "Machine learning has been applied to the problem of X-ray diffraction phase\nprediction with promising results. In this paper, we describe a method for\nusing machine learning to predict crystal structure phases from X-ray\ndiffraction data of transition metals and their oxides. We evaluate the\nperformance of our method and compare the variety of its settings. Our results\ndemonstrate that the proposed machine learning framework achieves competitive\nperformance. This demonstrates the potential for machine learning to\nsignificantly impact the field of X-ray diffraction and crystal structure\ndetermination. Open-source implementation:\nhttps://github.com/maxnygma/NeuralXRD.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2023-04-28",
    "authors": [
      "Maksim Zhdanov",
      "Andrey Zhdanov"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2305.15410v1"
  },
  {
    "title": "Insights From Insurance for Fair Machine Learning",
    "abstract": "We argue that insurance can act as an analogon for the social situatedness of\nmachine learning systems, hence allowing machine learning scholars to take\ninsights from the rich and interdisciplinary insurance literature. Tracing the\ninteraction of uncertainty, fairness and responsibility in insurance provides a\nfresh perspective on fairness in machine learning. We link insurance fairness\nconceptions to their machine learning relatives, and use this bridge to\nproblematize fairness as calibration. In this process, we bring to the\nforefront two themes that have been largely overlooked in the machine learning\nliterature: responsibility and aggregate-individual tensions.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2023-06-26",
    "authors": [
      "Christian Fröhlich",
      "Robert C. Williamson"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2306.14624v2"
  },
  {
    "title": "A comprehensive review of Quantum Machine Learning: from NISQ to Fault\n  Tolerance",
    "abstract": "Quantum machine learning, which involves running machine learning algorithms\non quantum devices, has garnered significant attention in both academic and\nbusiness circles. In this paper, we offer a comprehensive and unbiased review\nof the various concepts that have emerged in the field of quantum machine\nlearning. This includes techniques used in Noisy Intermediate-Scale Quantum\n(NISQ) technologies and approaches for algorithms compatible with\nfault-tolerant quantum computing hardware. Our review covers fundamental\nconcepts, algorithms, and the statistical learning theory pertinent to quantum\nmachine learning.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2024-01-21",
    "authors": [
      "Yunfei Wang",
      "Junyu Liu"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2401.11351v2"
  },
  {
    "title": "Quantum Dynamics of Machine Learning",
    "abstract": "The quantum dynamic equation (QDE) of machine learning is obtained based on\nSchr\\\"odinger equation and potential energy equivalence relationship. Through\nWick rotation, the relationship between quantum dynamics and thermodynamics is\nalso established in this paper. This equation reformulates the iterative\nprocess of machine learning into a time-dependent partial differential equation\nwith a clear mathematical structure, offering a theoretical framework for\ninvestigating machine learning iterations through quantum and mathematical\ntheories. Within this framework, the fundamental iterative process, the\ndiffusion model, and the Softmax and Sigmoid functions are examined, validating\nthe proposed quantum dynamics equations. This approach not only presents a\nrigorous theoretical foundation for machine learning but also holds promise for\nsupporting the implementation of machine learning algorithms on quantum\ncomputers.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2024-07-07",
    "authors": [
      "Peng Wang",
      "Maimaitiniyazi Maimaitiabudula"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2407.19890v1"
  },
  {
    "title": "On the Conditions for Domain Stability for Machine Learning: a\n  Mathematical Approach",
    "abstract": "This work proposes a mathematical approach that (re)defines a property of\nMachine Learning models named stability and determines sufficient conditions to\nvalidate it. Machine Learning models are represented as functions, and the\ncharacteristics in scope depend upon the domain of the function, what allows us\nto adopt topological and metric spaces theory as a basis. Finally, this work\nprovides some equivalences useful to prove and test stability in Machine\nLearning models. The results suggest that whenever stability is aligned with\nthe notion of function smoothness, then the stability of Machine Learning\nmodels primarily depends upon certain topological, measurable properties of the\nclassification sets within the ML model domain.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2024-11-30",
    "authors": [
      "Gabriel Pedroza"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2412.00464v1"
  },
  {
    "title": "How Developers Iterate on Machine Learning Workflows -- A Survey of the\n  Applied Machine Learning Literature",
    "abstract": "Machine learning workflow development is anecdotally regarded to be an\niterative process of trial-and-error with humans-in-the-loop. However, we are\nnot aware of quantitative evidence corroborating this popular belief. A\nquantitative characterization of iteration can serve as a benchmark for machine\nlearning workflow development in practice, and can aid the development of\nhuman-in-the-loop machine learning systems. To this end, we conduct a\nsmall-scale survey of the applied machine learning literature from five\ndistinct application domains. We collect and distill statistics on the role of\niteration within machine learning workflow development, and report preliminary\ntrends and insights from our investigation, as a starting point towards this\nbenchmark. Based on our findings, we finally describe desiderata for effective\nand versatile human-in-the-loop machine learning systems that can cater to\nusers in diverse domains.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2018-03-27",
    "authors": [
      "Doris Xin",
      "Litian Ma",
      "Shuchen Song",
      "Aditya Parameswaran"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1803.10311v2"
  },
  {
    "title": "Scientific Machine Learning Benchmarks",
    "abstract": "The breakthrough in Deep Learning neural networks has transformed the use of\nAI and machine learning technologies for the analysis of very large\nexperimental datasets. These datasets are typically generated by large-scale\nexperimental facilities at national laboratories. In the context of science,\nscientific machine learning focuses on training machines to identify patterns,\ntrends, and anomalies to extract meaningful scientific insights from such\ndatasets. With a new generation of experimental facilities, the rate of data\ngeneration and the scale of data volumes will increasingly require the use of\nmore automated data analysis. At present, identifying the most appropriate\nmachine learning algorithm for the analysis of any given scientific dataset is\nstill a challenge for scientists. This is due to many different machine\nlearning frameworks, computer architectures, and machine learning models.\nHistorically, for modelling and simulation on HPC systems such problems have\nbeen addressed through benchmarking computer applications, algorithms, and\narchitectures. Extending such a benchmarking approach and identifying metrics\nfor the application of machine learning methods to scientific datasets is a new\nchallenge for both scientists and computer scientists. In this paper, we\ndescribe our approach to the development of scientific machine learning\nbenchmarks and review other approaches to benchmarking scientific machine\nlearning.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2021-10-25",
    "authors": [
      "Jeyan Thiyagalingam",
      "Mallikarjun Shankar",
      "Geoffrey Fox",
      "Tony Hey"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2110.12773v1"
  },
  {
    "title": "Machine Learning Interpretability: A Science rather than a tool",
    "abstract": "The term \"interpretability\" is oftenly used by machine learning researchers\neach with their own intuitive understanding of it. There is no universal well\nagreed upon definition of interpretability in machine learning. As any type of\nscience discipline is mainly driven by the set of formulated questions rather\nthan by different tools in that discipline, e.g. astrophysics is the discipline\nthat learns the composition of stars, not as the discipline that use the\nspectroscopes. Similarly, we propose that machine learning interpretability\nshould be a discipline that answers specific questions related to\ninterpretability. These questions can be of statistical, causal and\ncounterfactual nature. Therefore, there is a need to look into the\ninterpretability problem of machine learning in the context of questions that\nneed to be addressed rather than different tools. We discuss about a\nhypothetical interpretability framework driven by a question based scientific\napproach rather than some specific machine learning model. Using a question\nbased notion of interpretability, we can step towards understanding the science\nof machine learning rather than its engineering. This notion will also help us\nunderstanding any specific problem more in depth rather than relying solely on\nmachine learning methods.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2018-07-18",
    "authors": [
      "Abdul Karim",
      "Avinash Mishra",
      "MA Hakim Newton",
      "Abdul Sattar"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1807.06722v2"
  },
  {
    "title": "Practical Solutions for Machine Learning Safety in Autonomous Vehicles",
    "abstract": "Autonomous vehicles rely on machine learning to solve challenging tasks in\nperception and motion planning. However, automotive software safety standards\nhave not fully evolved to address the challenges of machine learning safety\nsuch as interpretability, verification, and performance limitations. In this\npaper, we review and organize practical machine learning safety techniques that\ncan complement engineering safety for machine learning based software in\nautonomous vehicles. Our organization maps safety strategies to\nstate-of-the-art machine learning techniques in order to enhance dependability\nand safety of machine learning algorithms. We also discuss security limitations\nand user experience aspects of machine learning components in autonomous\nvehicles.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-12-20",
    "authors": [
      "Sina Mohseni",
      "Mandar Pitale",
      "Vasu Singh",
      "Zhangyang Wang"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1912.09630v1"
  },
  {
    "title": "Julia Language in Machine Learning: Algorithms, Applications, and Open\n  Issues",
    "abstract": "Machine learning is driving development across many fields in science and\nengineering. A simple and efficient programming language could accelerate\napplications of machine learning in various fields. Currently, the programming\nlanguages most commonly used to develop machine learning algorithms include\nPython, MATLAB, and C/C ++. However, none of these languages well balance both\nefficiency and simplicity. The Julia language is a fast, easy-to-use, and\nopen-source programming language that was originally designed for\nhigh-performance computing, which can well balance the efficiency and\nsimplicity. This paper summarizes the related research work and developments in\nthe application of the Julia language in machine learning. It first surveys the\npopular machine learning algorithms that are developed in the Julia language.\nThen, it investigates applications of the machine learning algorithms\nimplemented with the Julia language. Finally, it discusses the open issues and\nthe potential future directions that arise in the use of the Julia language in\nmachine learning.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-03-23",
    "authors": [
      "Kaifeng Gao",
      "Gang Mei",
      "Francesco Piccialli",
      "Salvatore Cuomo",
      "Jingzhi Tu",
      "Zenan Huo"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2003.10146v2"
  },
  {
    "title": "Modeling Generalization in Machine Learning: A Methodological and\n  Computational Study",
    "abstract": "As machine learning becomes more and more available to the general public,\ntheoretical questions are turning into pressing practical issues. Possibly, one\nof the most relevant concerns is the assessment of our confidence in trusting\nmachine learning predictions. In many real-world cases, it is of utmost\nimportance to estimate the capabilities of a machine learning algorithm to\ngeneralize, i.e., to provide accurate predictions on unseen data, depending on\nthe characteristics of the target problem. In this work, we perform a\nmeta-analysis of 109 publicly-available classification data sets, modeling\nmachine learning generalization as a function of a variety of data set\ncharacteristics, ranging from number of samples to intrinsic dimensionality,\nfrom class-wise feature skewness to $F1$ evaluated on test samples falling\noutside the convex hull of the training set. Experimental results demonstrate\nthe relevance of using the concept of the convex hull of the training data in\nassessing machine learning generalization, by emphasizing the difference\nbetween interpolated and extrapolated predictions. Besides several predictable\ncorrelations, we observe unexpectedly weak associations between the\ngeneralization ability of machine learning models and all metrics related to\ndimensionality, thus challenging the common assumption that the \\textit{curse\nof dimensionality} might impair generalization in machine learning.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-06-28",
    "authors": [
      "Pietro Barbiero",
      "Giovanni Squillero",
      "Alberto Tonda"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2006.15680v1"
  },
  {
    "title": "Automated Machine Learning on Graphs: A Survey",
    "abstract": "Machine learning on graphs has been extensively studied in both academic and\nindustry. However, as the literature on graph learning booms with a vast number\nof emerging methods and techniques, it becomes increasingly difficult to\nmanually design the optimal machine learning algorithm for different\ngraph-related tasks. To solve this critical challenge, automated machine\nlearning (AutoML) on graphs which combines the strength of graph machine\nlearning and AutoML together, is gaining attention from the research community.\nTherefore, we comprehensively survey AutoML on graphs in this paper, primarily\nfocusing on hyper-parameter optimization (HPO) and neural architecture search\n(NAS) for graph machine learning. We further overview libraries related to\nautomated graph machine learning and in-depth discuss AutoGL, the first\ndedicated open-source library for AutoML on graphs. In the end, we share our\ninsights on future research directions for automated graph machine learning.\nThis paper is the first systematic and comprehensive review of automated\nmachine learning on graphs to the best of our knowledge.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2021-03-01",
    "authors": [
      "Ziwei Zhang",
      "Xin Wang",
      "Wenwu Zhu"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2103.00742v4"
  },
  {
    "title": "Mental Models of Adversarial Machine Learning",
    "abstract": "Although machine learning is widely used in practice, little is known about\npractitioners' understanding of potential security challenges. In this work, we\nclose this substantial gap and contribute a qualitative study focusing on\ndevelopers' mental models of the machine learning pipeline and potentially\nvulnerable components. Similar studies have helped in other security fields to\ndiscover root causes or improve risk communication. Our study reveals two\n\\facets of practitioners' mental models of machine learning security. Firstly,\npractitioners often confuse machine learning security with threats and defences\nthat are not directly related to machine learning. Secondly, in contrast to\nmost academic research, our participants perceive security of machine learning\nas not solely related to individual models, but rather in the context of entire\nworkflows that consist of multiple components. Jointly with our additional\nfindings, these two facets provide a foundation to substantiate mental models\nfor machine learning security and have implications for the integration of\nadversarial machine learning into corporate workflows, \\new{decreasing\npractitioners' reported uncertainty}, and appropriate regulatory frameworks for\nmachine learning security.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2021-05-08",
    "authors": [
      "Lukas Bieringer",
      "Kathrin Grosse",
      "Michael Backes",
      "Battista Biggio",
      "Katharina Krombholz"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2105.03726v4"
  },
  {
    "title": "Can Machine Learning be Moral?",
    "abstract": "The ethics of Machine Learning has become an unavoidable topic in the AI\nCommunity. The deployment of machine learning systems in multiple social\ncontexts has resulted in a closer ethical scrutiny of the design, development,\nand application of these systems. The AI/ML community has come to terms with\nthe imperative to think about the ethical implications of machine learning, not\nonly as a product but also as a practice (Birhane, 2021; Shen et al. 2021). The\ncritical question that is troubling many debates is what can constitute an\nethically accountable machine learning system. In this paper we explore\npossibilities for ethical evaluation of machine learning methodologies. We\nscrutinize techniques, methods and technical practices in machine learning from\na relational ethics perspective, taking into consideration how machine learning\nsystems are part of the world and how they relate to different forms of agency.\nTaking a page from Phil Agre (1997) we use the notion of a critical technical\npractice as a means of analysis of machine learning approaches. Our radical\nproposal is that supervised learning appears to be the only machine learning\nmethod that is ethically defensible.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2021-12-13",
    "authors": [
      "Miguel Sicart",
      "Irina Shklovski",
      "Mirabelle Jones"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2201.06921v1"
  },
  {
    "title": "Applying Machine Learning to Life Insurance: some knowledge sharing to\n  master it",
    "abstract": "Machine Learning permeates many industries, which brings new source of\nbenefits for companies. However within the life insurance industry, Machine\nLearning is not widely used in practice as over the past years statistical\nmodels have shown their efficiency for risk assessment. Thus insurers may face\ndifficulties to assess the value of the artificial intelligence. Focusing on\nthe modification of the life insurance industry over time highlights the stake\nof using Machine Learning for insurers and benefits that it can bring by\nunleashing data value. This paper reviews traditional actuarial methodologies\nfor survival modeling and extends them with Machine Learning techniques. It\npoints out differences with regular machine learning models and emphasizes\nimportance of specific implementations to face censored data with machine\nlearning models family. In complement to this article, a Python library has\nbeen developed. Different open-source Machine Learning algorithms have been\nadjusted to adapt the specificities of life insurance data, namely censoring\nand truncation. Such models can be easily applied from this SCOR library to\naccurately model life insurance risks.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2022-09-05",
    "authors": [
      "Antoine Chancel",
      "Laura Bradier",
      "Antoine Ly",
      "Razvan Ionescu",
      "Laurene Martin",
      "Marguerite Sauce"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2209.02057v3"
  },
  {
    "title": "Machine learning and domain decomposition methods -- a survey",
    "abstract": "Hybrid algorithms, which combine black-box machine learning methods with\nexperience from traditional numerical methods and domain expertise from diverse\napplication areas, are progressively gaining importance in scientific machine\nlearning and various industrial domains, especially in computational science\nand engineering. In the present survey, several promising avenues of research\nwill be examined which focus on the combination of machine learning (ML) and\ndomain decomposition methods (DDMs). The aim of this survey is to provide an\noverview of existing work within this field and to structure it into domain\ndecomposition for machine learning and machine learning-enhanced domain\ndecomposition, including: domain decomposition for classical machine learning,\ndomain decomposition to accelerate the training of physics-aware neural\nnetworks, machine learning to enhance the convergence properties or\ncomputational efficiency of DDMs, and machine learning as a discretization\nmethod in a DDM for the solution of PDEs. In each of these fields, we summarize\nexisting work and key advances within a common framework and, finally, disuss\nongoing challenges and opportunities for future research.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2023-12-21",
    "authors": [
      "Axel Klawonn",
      "Martin Lanser",
      "Janine Weber"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2312.14050v1"
  },
  {
    "title": "Beyond Model Interpretability: Socio-Structural Explanations in Machine\n  Learning",
    "abstract": "What is it to interpret the outputs of an opaque machine learning model. One\napproach is to develop interpretable machine learning techniques. These\ntechniques aim to show how machine learning models function by providing either\nmodel centric local or global explanations, which can be based on mechanistic\ninterpretations revealing the inner working mechanisms of models or\nnonmechanistic approximations showing input feature output data relationships.\nIn this paper, we draw on social philosophy to argue that interpreting machine\nlearning outputs in certain normatively salient domains could require appealing\nto a third type of explanation that we call sociostructural explanation. The\nrelevance of this explanation type is motivated by the fact that machine\nlearning models are not isolated entities but are embedded within and shaped by\nsocial structures. Sociostructural explanations aim to illustrate how social\nstructures contribute to and partially explain the outputs of machine learning\nmodels. We demonstrate the importance of sociostructural explanations by\nexamining a racially biased healthcare allocation algorithm. Our proposal\nhighlights the need for transparency beyond model interpretability,\nunderstanding the outputs of machine learning systems could require a broader\nanalysis that extends beyond the understanding of the machine learning model\nitself.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2024-09-05",
    "authors": [
      "Andrew Smart",
      "Atoosa Kasirzadeh"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2409.03632v1"
  },
  {
    "title": "Aspects of Artificial Intelligence: Transforming Machine Learning\n  Systems Naturally",
    "abstract": "In this paper, we study the machine learning elements which we are interested\nin together as a machine learning system, consisting of a collection of machine\nlearning elements and a collection of relations between the elements. The\nrelations we concern are algebraic operations, binary relations, and binary\nrelations with composition that can be reasoned categorically. A machine\nlearning system transformation between two systems is a map between the\nsystems, which preserves the relations we concern. The system transformations\ngiven by quotient or clustering, representable functor, and Yoneda embedding\nare highlighted and discussed by machine learning examples. An adjunction\nbetween machine learning systems, a special machine learning system\ntransformation loop, provides the optimal way of solving problems. Machine\nlearning system transformations are linked and compared by their maps at\n2-cell, natural transformations. New insights and structures can be obtained\nfrom universal properties and algebraic structures given by monads, which are\ngenerated from adjunctions.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2025-02-03",
    "authors": [
      "Xiuzhan Guo"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2502.01708v1"
  },
  {
    "title": "A systematic review of fuzzing based on machine learning techniques",
    "abstract": "Security vulnerabilities play a vital role in network security system.\nFuzzing technology is widely used as a vulnerability discovery technology to\nreduce damage in advance. However, traditional fuzzing techniques have many\nchallenges, such as how to mutate input seed files, how to increase code\ncoverage, and how to effectively bypass verification. Machine learning\ntechnology has been introduced as a new method into fuzzing test to alleviate\nthese challenges. This paper reviews the research progress of using machine\nlearning technology for fuzzing test in recent years, analyzes how machine\nlearning improve the fuzz process and results, and sheds light on future work\nin fuzzing. Firstly, this paper discusses the reasons why machine learning\ntechniques can be used for fuzzing scenarios and identifies six different\nstages in which machine learning have been used. Then this paper systematically\nstudy the machine learning based fuzzing models from selection of machine\nlearning algorithm, pre-processing methods, datasets, evaluation metrics, and\nhyperparameters setting. Next, this paper assesses the performance of the\nmachine learning models based on the frequently used evaluation metrics. The\nresults of the evaluation prove that machine learning technology has an\nacceptable capability of categorize predictive for fuzzing. Finally, the\ncomparison on capability of discovering vulnerabilities between traditional\nfuzzing tools and machine learning based fuzzing tools is analyzed. The results\ndepict that the introduction of machine learning technology can improve the\nperformance of fuzzing. However, there are still some limitations, such as\nunbalanced training samples and difficult to extract the characteristics\nrelated to vulnerabilities.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-08-04",
    "authors": [
      "Yan Wang",
      "Peng Jia",
      "Luping Liu",
      "Jiayong Liu"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1908.01262v1"
  },
  {
    "title": "A Comparison of First-order Algorithms for Machine Learning",
    "abstract": "Using an optimization algorithm to solve a machine learning problem is one of\nmainstreams in the field of science. In this work, we demonstrate a\ncomprehensive comparison of some state-of-the-art first-order optimization\nalgorithms for convex optimization problems in machine learning. We concentrate\non several smooth and non-smooth machine learning problems with a loss function\nplus a regularizer. The overall experimental results show the superiority of\nprimal-dual algorithms in solving a machine learning problem from the\nperspectives of the ease to construct, running time and accuracy.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2014-04-26",
    "authors": [
      "Yu Wei",
      "Pock Thomas"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1404.6674v1"
  },
  {
    "title": "Meaningful Models: Utilizing Conceptual Structure to Improve Machine\n  Learning Interpretability",
    "abstract": "The last decade has seen huge progress in the development of advanced machine\nlearning models; however, those models are powerless unless human users can\ninterpret them. Here we show how the mind's construction of concepts and\nmeaning can be used to create more interpretable machine learning models. By\nproposing a novel method of classifying concepts, in terms of 'form' and\n'function', we elucidate the nature of meaning and offer proposals to improve\nmodel understandability. As machine learning begins to permeate daily life,\ninterpretable models may serve as a bridge between domain-expert authors and\nnon-expert users.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2016-07-01",
    "authors": [
      "Nick Condry"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1607.00279v1"
  },
  {
    "title": "An Aggregate and Iterative Disaggregate Algorithm with Proven Optimality\n  in Machine Learning",
    "abstract": "We propose a clustering-based iterative algorithm to solve certain\noptimization problems in machine learning, where we start the algorithm by\naggregating the original data, solving the problem on aggregated data, and then\nin subsequent steps gradually disaggregate the aggregated data. We apply the\nalgorithm to common machine learning problems such as the least absolute\ndeviation regression problem, support vector machines, and semi-supervised\nsupport vector machines. We derive model-specific data aggregation and\ndisaggregation procedures. We also show optimality, convergence, and the\noptimality gap of the approximated solution in each iteration. A computational\nstudy is provided.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2016-07-05",
    "authors": [
      "Young Woong Park",
      "Diego Klabjan"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1607.01400v1"
  },
  {
    "title": "Seven Myths in Machine Learning Research",
    "abstract": "We present seven myths commonly believed to be true in machine learning\nresearch, circa Feb 2019. This is an archival copy of the blog post at\nhttps://crazyoscarchang.github.io/2019/02/16/seven-myths-in-machine-learning-research/\n  Myth 1: TensorFlow is a Tensor manipulation library\n  Myth 2: Image datasets are representative of real images found in the wild\n  Myth 3: Machine Learning researchers do not use the test set for validation\n  Myth 4: Every datapoint is used in training a neural network\n  Myth 5: We need (batch) normalization to train very deep residual networks\n  Myth 6: Attention $>$ Convolution\n  Myth 7: Saliency maps are robust ways to interpret neural networks",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-02-18",
    "authors": [
      "Oscar Chang",
      "Hod Lipson"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1902.06789v2"
  },
  {
    "title": "Optimal Algorithms for Ski Rental with Soft Machine-Learned Predictions",
    "abstract": "We consider a variant of the classic Ski Rental online algorithm with\napplications to machine learning. In our variant, we allow the skier access to\na black-box machine-learning algorithm that provides an estimate of the\nprobability that there will be at most a threshold number of ski-days. We\nderive a class of optimal randomized algorithms to determine the strategy that\nminimizes the worst-case expected competitive ratio for the skier given a\nprediction from the machine learning algorithm,and analyze the performance and\nrobustness of these algorithms.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-02-28",
    "authors": [
      "Rohan Kodialam"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1903.00092v2"
  },
  {
    "title": "Towards Quantification of Bias in Machine Learning for Healthcare: A\n  Case Study of Renal Failure Prediction",
    "abstract": "As machine learning (ML) models, trained on real-world datasets, become\ncommon practice, it is critical to measure and quantify their potential biases.\nIn this paper, we focus on renal failure and compare a commonly used\ntraditional risk score, Tangri, with a more powerful machine learning model,\nwhich has access to a larger variable set and trained on 1.6 million patients'\nEHR data. We will compare and discuss the generalization and applicability of\nthese two models, in an attempt to quantify biases of status quo clinical\npractice, compared to ML-driven models.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-11-18",
    "authors": [
      "Josie Williams",
      "Narges Razavian"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1911.07679v1"
  },
  {
    "title": "On the computation of counterfactual explanations -- A survey",
    "abstract": "Due to the increasing use of machine learning in practice it becomes more and\nmore important to be able to explain the prediction and behavior of machine\nlearning models. An instance of explanations are counterfactual explanations\nwhich provide an intuitive and useful explanations of machine learning models.\nIn this survey we review model-specific methods for efficiently computing\ncounterfactual explanations of many different machine learning models and\npropose methods for models that have not been considered in literature so far.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-11-15",
    "authors": [
      "André Artelt",
      "Barbara Hammer"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1911.07749v1"
  },
  {
    "title": "Computer Systems Have 99 Problems, Let's Not Make Machine Learning\n  Another One",
    "abstract": "Machine learning techniques are finding many applications in computer\nsystems, including many tasks that require decision making: network\noptimization, quality of service assurance, and security. We believe machine\nlearning systems are here to stay, and to materialize on their potential we\nadvocate a fresh look at various key issues that need further attention,\nincluding security as a requirement and system complexity, and how machine\nlearning systems affect them. We also discuss reproducibility as a key\nrequirement for sustainable machine learning systems, and leads to pursuing it.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-11-28",
    "authors": [
      "David Mohaisen",
      "Songqing Chen"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1911.12593v1"
  },
  {
    "title": "TF.Learn: TensorFlow's High-level Module for Distributed Machine\n  Learning",
    "abstract": "TF.Learn is a high-level Python module for distributed machine learning\ninside TensorFlow. It provides an easy-to-use Scikit-learn style interface to\nsimplify the process of creating, configuring, training, evaluating, and\nexperimenting a machine learning model. TF.Learn integrates a wide range of\nstate-of-art machine learning algorithms built on top of TensorFlow's low level\nAPIs for small to large-scale supervised and unsupervised problems. This module\nfocuses on bringing machine learning to non-specialists using a general-purpose\nhigh-level language as well as researchers who want to implement, benchmark,\nand compare their new methods in a structured environment. Emphasis is put on\nease of use, performance, documentation, and API consistency.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2016-12-13",
    "authors": [
      "Yuan Tang"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1612.04251v1"
  },
  {
    "title": "Application of Machine Learning Techniques in Aquaculture",
    "abstract": "In this paper we present applications of different machine learning\nalgorithms in aquaculture. Machine learning algorithms learn models from\nhistorical data. In aquaculture historical data are obtained from farm\npractices, yields, and environmental data sources. Associations between these\ndifferent variables can be obtained by applying machine learning algorithms to\nhistorical data. In this paper we present applications of different machine\nlearning algorithms in aquaculture applications.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2014-05-03",
    "authors": [
      "Akhlaqur Rahman",
      "Sumaira Tasnim"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1405.1304v1"
  },
  {
    "title": "Using Deep Learning and Machine Learning to Detect Epileptic Seizure\n  with Electroencephalography (EEG) Data",
    "abstract": "The prediction of epileptic seizure has always been extremely challenging in\nmedical domain. However, as the development of computer technology, the\napplication of machine learning introduced new ideas for seizure forecasting.\nApplying machine learning model onto the predication of epileptic seizure could\nhelp us obtain a better result and there have been plenty of scientists who\nhave been doing such works so that there are sufficient medical data provided\nfor researchers to do training of machine learning models.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-10-06",
    "authors": [
      "Haotian Liu",
      "Lin Xi",
      "Ying Zhao",
      "Zhixiang Li"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1910.02544v1"
  },
  {
    "title": "Machine Learning in Network Security Using KNIME Analytics",
    "abstract": "Machine learning has more and more effect on our every day's life. This field\nkeeps growing and expanding into new areas. Machine learning is based on the\nimplementation of artificial intelligence that gives systems the capability to\nautomatically learn and enhance from experiments without being explicitly\nprogrammed. Machine Learning algorithms apply mathematical equations to analyze\ndatasets and predict values based on the dataset. In the field of\ncybersecurity, machine learning algorithms can be utilized to train and analyze\nthe Intrusion Detection Systems (IDSs) on security-related datasets. In this\npaper, we tested different machine learning algorithms to analyze NSL-KDD\ndataset using KNIME analytics.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-11-18",
    "authors": [
      "Munther Abualkibash"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2001.11489v1"
  },
  {
    "title": "Addressing Privacy Threats from Machine Learning",
    "abstract": "Every year at NeurIPS, machine learning researchers gather and discuss\nexciting applications of machine learning in areas such as public health,\ndisaster response, climate change, education, and more. However, many of these\nsame researchers are expressing growing concern about applications of machine\nlearning for surveillance (Nanayakkara et al., 2021). This paper presents a\nbrief overview of strategies for resisting these surveillance technologies and\ncalls for greater collaboration between machine learning and human-computer\ninteraction researchers to address the threats that these technologies pose.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2021-10-25",
    "authors": [
      "Mary Anne Smart"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2111.04439v1"
  },
  {
    "title": "Parallelization of Machine Learning Algorithms Respectively on Single\n  Machine and Spark",
    "abstract": "With the rapid development of big data technologies, how to dig out useful\ninformation from massive data becomes an essential problem. However, using\nmachine learning algorithms to analyze large data may be time-consuming and\ninefficient on the traditional single machine. To solve these problems, this\npaper has made some research on the parallelization of several classic machine\nlearning algorithms respectively on the single machine and the big data\nplatform Spark. We compare the runtime and efficiency of traditional machine\nlearning algorithms with parallelized machine learning algorithms respectively\non the single machine and Spark platform. The research results have shown\nsignificant improvement in runtime and efficiency of parallelized machine\nlearning algorithms.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2022-05-08",
    "authors": [
      "Jiajun Shen"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2206.07090v2"
  },
  {
    "title": "Machine Learning in Official Statistics",
    "abstract": "In the first half of 2018, the Federal Statistical Office of Germany\n(Destatis) carried out a \"Proof of Concept Machine Learning\" as part of its\nDigital Agenda. A major component of this was surveys on the use of machine\nlearning methods in official statistics, which were conducted at selected\nnational and international statistical institutions and among the divisions of\nDestatis. It was of particular interest to find out in which statistical areas\nand for which tasks machine learning is used and which methods are applied.\nThis paper is intended to make the results of the surveys publicly accessible.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2018-12-13",
    "authors": [
      "Martin Beck",
      "Florian Dumpert",
      "Joerg Feuerhake"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1812.10422v1"
  },
  {
    "title": "When Machine Learning Meets Multiscale Modeling in Chemical Reactions",
    "abstract": "Due to the intrinsic complexity and nonlinearity of chemical reactions,\ndirect applications of traditional machine learning algorithms may face with\nmany difficulties. In this study, through two concrete examples with biological\nbackground, we illustrate how the key ideas of multiscale modeling can help to\nreduce the computational cost of machine learning a lot, as well as how machine\nlearning algorithms perform model reduction automatically in a time-scale\nseparated system. Our study highlights the necessity and effectiveness of an\nintegration of machine learning algorithms and multiscale modeling during the\nstudy of chemical reactions.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-06-01",
    "authors": [
      "Wuyue Yang",
      "Liangrong Peng",
      "Yi Zhu",
      "Liu Hong"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2006.00700v1"
  },
  {
    "title": "Efficient Private Machine Learning by Differentiable Random\n  Transformations",
    "abstract": "With the increasing demands for privacy protection, many privacy-preserving\nmachine learning systems were proposed in recent years. However, most of them\ncannot be put into production due to their slow training and inference speed\ncaused by the heavy cost of homomorphic encryption and secure multiparty\ncomputation(MPC) methods. To circumvent this, I proposed a privacy definition\nwhich is suitable for large amount of data in machine learning tasks. Based on\nthat, I showed that random transformations like linear transformation and\nrandom permutation can well protect privacy. Merging random transformations and\narithmetic sharing together, I designed a framework for private machine\nlearning with high efficiency and low computation cost.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2020-08-18",
    "authors": [
      "Fei Zheng"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2008.07758v1"
  },
  {
    "title": "Distributed Double Machine Learning with a Serverless Architecture",
    "abstract": "This paper explores serverless cloud computing for double machine learning.\nBeing based on repeated cross-fitting, double machine learning is particularly\nwell suited to exploit the high level of parallelism achievable with serverless\ncomputing. It allows to get fast on-demand estimations without additional cloud\nmaintenance effort. We provide a prototype Python implementation\n\\texttt{DoubleML-Serverless} for the estimation of double machine learning\nmodels with the serverless computing platform AWS Lambda and demonstrate its\nutility with a case study analyzing estimation times and costs.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2021-01-11",
    "authors": [
      "Malte S. Kurz"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2101.04025v2"
  },
  {
    "title": "Energy-Harvesting Distributed Machine Learning",
    "abstract": "This paper provides a first study of utilizing energy harvesting for\nsustainable machine learning in distributed networks. We consider a distributed\nlearning setup in which a machine learning model is trained over a large number\nof devices that can harvest energy from the ambient environment, and develop a\npractical learning framework with theoretical convergence guarantees. We\ndemonstrate through numerical experiments that the proposed framework can\nsignificantly outperform energy-agnostic benchmarks. Our framework is scalable,\nrequires only local estimation of the energy statistics, and can be applied to\na wide range of distributed training settings, including machine learning in\nwireless networks, edge computing, and mobile internet of things.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2021-02-10",
    "authors": [
      "Basak Guler",
      "Aylin Yener"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2102.05639v1"
  },
  {
    "title": "SELM: Software Engineering of Machine Learning Models",
    "abstract": "One of the pillars of any machine learning model is its concepts. Using\nsoftware engineering, we can engineer these concepts and then develop and\nexpand them. In this article, we present a SELM framework for Software\nEngineering of machine Learning Models. We then evaluate this framework through\na case study. Using the SELM framework, we can improve a machine learning\nprocess efficiency and provide more accuracy in learning with less processing\nhardware resources and a smaller training dataset. This issue highlights the\nimportance of an interdisciplinary approach to machine learning. Therefore, in\nthis article, we have provided interdisciplinary teams' proposals for machine\nlearning.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2021-03-20",
    "authors": [
      "Nafiseh Jafari",
      "Mohammad Reza Besharati",
      "Mohammad Izadi",
      "Maryam Hourali"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2103.11249v1"
  },
  {
    "title": "Human-in-the-loop Machine Learning: A Macro-Micro Perspective",
    "abstract": "Though technical advance of artificial intelligence and machine learning has\nenabled many promising intelligent systems, many computing tasks are still not\nable to be fully accomplished by machine intelligence. Motivated by the\ncomplementary nature of human and machine intelligence, an emerging trend is to\ninvolve humans in the loop of machine learning and decision-making. In this\npaper, we provide a macro-micro review of human-in-the-loop machine learning.\nWe first describe major machine learning challenges which can be addressed by\nhuman intervention in the loop. Then we examine closely the latest research and\nfindings of introducing humans into each step of the lifecycle of machine\nlearning. Finally, we analyze current research gaps and point out future\nresearch directions.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2022-02-21",
    "authors": [
      "Jiangtao Wang",
      "Bin Guo",
      "Liming Chen"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2202.10564v1"
  },
  {
    "title": "Categories of Differentiable Polynomial Circuits for Machine Learning",
    "abstract": "Reverse derivative categories (RDCs) have recently been shown to be a\nsuitable semantic framework for studying machine learning algorithms. Whereas\nemphasis has been put on training methodologies, less attention has been\ndevoted to particular \\emph{model classes}: the concrete categories whose\nmorphisms represent machine learning models. In this paper we study\npresentations by generators and equations of classes of RDCs. In particular, we\npropose \\emph{polynomial circuits} as a suitable machine learning model. We\ngive an axiomatisation for these circuits and prove a functional completeness\nresult. Finally, we discuss the use of polynomial circuits over specific\nsemirings to perform machine learning with discrete values.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2022-03-12",
    "authors": [
      "Paul Wilson",
      "Fabio Zanasi"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2203.06430v2"
  },
  {
    "title": "When Physics Meets Machine Learning: A Survey of Physics-Informed\n  Machine Learning",
    "abstract": "Physics-informed machine learning (PIML), referring to the combination of\nprior knowledge of physics, which is the high level abstraction of natural\nphenomenons and human behaviours in the long history, with data-driven machine\nlearning models, has emerged as an effective way to mitigate the shortage of\ntraining data, to increase models' generalizability and to ensure the physical\nplausibility of results. In this paper, we survey an abundant number of recent\nworks in PIML and summarize them from three aspects: (1) motivations of PIML,\n(2) physics knowledge in PIML, (3) methods of physics knowledge integration in\nPIML. We also discuss current challenges and corresponding research\nopportunities in PIML.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2022-03-31",
    "authors": [
      "Chuizheng Meng",
      "Sungyong Seo",
      "Defu Cao",
      "Sam Griesemer",
      "Yan Liu"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2203.16797v1"
  },
  {
    "title": "Challenges and Opportunities in Quantum Machine Learning",
    "abstract": "At the intersection of machine learning and quantum computing, Quantum\nMachine Learning (QML) has the potential of accelerating data analysis,\nespecially for quantum data, with applications for quantum materials,\nbiochemistry, and high-energy physics. Nevertheless, challenges remain\nregarding the trainability of QML models. Here we review current methods and\napplications for QML. We highlight differences between quantum and classical\nmachine learning, with a focus on quantum neural networks and quantum deep\nlearning. Finally, we discuss opportunities for quantum advantage with QML.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2023-03-16",
    "authors": [
      "M. Cerezo",
      "Guillaume Verdon",
      "Hsin-Yuan Huang",
      "Lukasz Cincio",
      "Patrick J. Coles"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2303.09491v1"
  },
  {
    "title": "Nine tips for ecologists using machine learning",
    "abstract": "Due to their high predictive performance and flexibility, machine learning\nmodels are an appropriate and efficient tool for ecologists. However,\nimplementing a machine learning model is not yet a trivial task and may seem\nintimidating to ecologists with no previous experience in this area. Here we\nprovide a series of tips to help ecologists in implementing machine learning\nmodels. We focus on classification problems as many ecological studies aim to\nassign data into predefined classes such as ecological states or biological\nentities. Each of the nine tips identifies a common error, trap or challenge in\ndeveloping machine learning models and provides recommendations to facilitate\ntheir use in ecological studies.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2023-05-17",
    "authors": [
      "Marine Desprez",
      "Vincent Miele",
      "Olivier Gimenez"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2305.10472v2"
  },
  {
    "title": "A Comparison of Machine Learning Methods for Data with High-Cardinality\n  Categorical Variables",
    "abstract": "High-cardinality categorical variables are variables for which the number of\ndifferent levels is large relative to the sample size of a data set, or in\nother words, there are few data points per level. Machine learning methods can\nhave difficulties with high-cardinality variables. In this article, we\nempirically compare several versions of two of the most successful machine\nlearning methods, tree-boosting and deep neural networks, and linear mixed\neffects models using multiple tabular data sets with high-cardinality\ncategorical variables. We find that, first, machine learning models with random\neffects have higher prediction accuracy than their classical counterparts\nwithout random effects, and, second, tree-boosting with random effects\noutperforms deep neural networks with random effects.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2023-07-05",
    "authors": [
      "Fabio Sigrist"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2307.02071v1"
  },
  {
    "title": "Machine learning for accuracy in density functional approximations",
    "abstract": "Machine learning techniques have found their way into computational chemistry\nas indispensable tools to accelerate atomistic simulations and materials\ndesign. In addition, machine learning approaches hold the potential to boost\nthe predictive power of computationally efficient electronic structure methods,\nsuch as density functional theory, to chemical accuracy and to correct for\nfundamental errors in density functional approaches. Here, recent progress in\napplying machine learning to improve the accuracy of density functional and\nrelated approximations is reviewed. Promises and challenges in devising machine\nlearning models transferable between different chemistries and materials\nclasses are discussed with the help of examples applying promising models to\nsystems far outside their training sets.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2023-11-01",
    "authors": [
      "Johannes Voss"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2311.00196v1"
  },
  {
    "title": "Improving Radiography Machine Learning Workflows via Metadata Management\n  for Training Data Selection",
    "abstract": "Most machine learning models require many iterations of hyper-parameter\ntuning, feature engineering, and debugging to produce effective results. As\nmachine learning models become more complicated, this pipeline becomes more\ndifficult to manage effectively. In the physical sciences, there is an\never-increasing pool of metadata that is generated by the scientific research\ncycle. Tracking this metadata can reduce redundant work, improve\nreproducibility, and aid in the feature and training dataset engineering\nprocess. In this case study, we present a tool for machine learning metadata\nmanagement in dynamic radiography. We evaluate the efficacy of this tool\nagainst the initial research workflow and discuss extensions to general machine\nlearning pipelines in the physical sciences.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2024-08-22",
    "authors": [
      "Mirabel Reid",
      "Christine Sweeney",
      "Oleg Korobkin"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2408.12655v1"
  },
  {
    "title": "A method to benchmark high-dimensional process drift detection",
    "abstract": "Process curves are multivariate finite time series data coming from\nmanufacturing processes. This paper studies machine learning that detect drifts\nin process curve datasets. A theoretic framework to synthetically generate\nprocess curves in a controlled way is introduced in order to benchmark machine\nlearning algorithms for process drift detection. An evaluation score, called\nthe temporal area under the curve, is introduced, which allows to quantify how\nwell machine learning models unveil curves belonging to drift segments.\nFinally, a benchmark study comparing popular machine learning approaches on\nsynthetic data generated with the introduced framework is presented that shows\nthat existing algorithms often struggle with datasets containing multiple drift\nsegments.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2024-09-05",
    "authors": [
      "Edgar Wolf",
      "Tobias Windisch"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2409.03669v2"
  },
  {
    "title": "Inverse Problems and Data Assimilation: A Machine Learning Approach",
    "abstract": "The aim of these notes is to demonstrate the potential for ideas in machine\nlearning to impact on the fields of inverse problems and data assimilation. The\nperspective is one that is primarily aimed at researchers from inverse problems\nand/or data assimilation who wish to see a mathematical presentation of machine\nlearning as it pertains to their fields. As a by-product, we include a succinct\nmathematical treatment of various topics in machine learning.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2024-10-14",
    "authors": [
      "Eviatar Bach",
      "Ricardo Baptista",
      "Daniel Sanz-Alonso",
      "Andrew Stuart"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2410.10523v1"
  },
  {
    "title": "Minimax deviation strategies for machine learning and recognition with\n  short learning samples",
    "abstract": "The article is devoted to the problem of small learning samples in machine\nlearning. The flaws of maximum likelihood learning and minimax learning are\nlooked into and the concept of minimax deviation learning is introduced that is\nfree of those flaws.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2017-07-16",
    "authors": [
      "Michail Schlesinger",
      "Evgeniy Vodolazskiy"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1707.04849v1"
  },
  {
    "title": "Classifying medical notes into standard disease codes using Machine\n  Learning",
    "abstract": "We investigate the automatic classification of patient discharge notes into\nstandard disease labels. We find that Convolutional Neural Networks with\nAttention outperform previous algorithms used in this task, and suggest further\nareas for improvement.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2018-02-01",
    "authors": [
      "Amitabha Karmakar"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1802.00382v1"
  },
  {
    "title": "Proceedings of NIPS 2016 Workshop on Interpretable Machine Learning for\n  Complex Systems",
    "abstract": "This is the Proceedings of NIPS 2016 Workshop on Interpretable Machine\nLearning for Complex Systems, held in Barcelona, Spain on December 9, 2016",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2016-11-28",
    "authors": [
      "Andrew Gordon Wilson",
      "Been Kim",
      "William Herlands"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1611.09139v1"
  },
  {
    "title": "Introduction to intelligent computing unit 1",
    "abstract": "This brief note highlights some basic concepts required toward understanding\nthe evolution of machine learning and deep learning models. The note starts\nwith an overview of artificial intelligence and its relationship to biological\nneuron that ultimately led to the evolution of todays intelligent models.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2017-11-15",
    "authors": [
      "Isa Inuwa-Dutse"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1711.06552v1"
  },
  {
    "title": "Proceedings of NIPS 2017 Workshop on Machine Learning for the Developing\n  World",
    "abstract": "This is the Proceedings of NIPS 2017 Workshop on Machine Learning for the\nDeveloping World, held in Long Beach, California, USA on December 8, 2017",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2017-11-27",
    "authors": [
      "Maria De-Arteaga",
      "William Herlands"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1711.09522v2"
  },
  {
    "title": "Engineering problems in machine learning systems",
    "abstract": "Fatal accidents are a major issue hindering the wide acceptance of\nsafety-critical systems that employ machine learning and deep learning models,\nsuch as automated driving vehicles. In order to use machine learning in a\nsafety-critical system, it is necessary to demonstrate the safety and security\nof the system through engineering processes. However, thus far, no such widely\naccepted engineering concepts or frameworks have been established for these\nsystems. The key to using a machine learning model in a deductively engineered\nsystem is decomposing the data-driven training of machine learning models into\nrequirement, design, and verification, particularly for machine learning models\nused in safety-critical systems. Simultaneously, open problems and relevant\ntechnical fields are not organized in a manner that enables researchers to\nselect a theme and work on it. In this study, we identify, classify, and\nexplore the open problems in engineering (safety-critical) machine learning\nsystems --- that is, in terms of requirement, design, and verification of\nmachine learning models and systems --- as well as discuss related works and\nresearch directions, using automated driving vehicles as an example. Our\nresults show that machine learning models are characterized by a lack of\nrequirements specification, lack of design specification, lack of\ninterpretability, and lack of robustness. We also perform a gap analysis on a\nconventional system quality standard SQuARE with the characteristics of machine\nlearning models to study quality models for machine learning systems. We find\nthat a lack of requirements specification and lack of robustness have the\ngreatest impact on conventional quality models.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2019-04-01",
    "authors": [
      "Hiroshi Kuwajima",
      "Hirotoshi Yasuoka",
      "Toshihiro Nakae"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1904.00001v2"
  },
  {
    "title": "Linear, Machine Learning and Probabilistic Approaches for Time Series\n  Analysis",
    "abstract": "In this paper we study different approaches for time series modeling. The\nforecasting approaches using linear models, ARIMA alpgorithm, XGBoost machine\nlearning algorithm are described. Results of different model combinations are\nshown. For probabilistic modeling the approaches using copulas and Bayesian\ninference are considered.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2017-02-26",
    "authors": [
      "B. M. Pavlyshenko"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1703.01977v1"
  },
  {
    "title": "Automated Graph Machine Learning: Approaches, Libraries, Benchmarks and\n  Directions",
    "abstract": "Graph machine learning has been extensively studied in both academic and\nindustry. However, as the literature on graph learning booms with a vast number\nof emerging methods and techniques, it becomes increasingly difficult to\nmanually design the optimal machine learning algorithm for different\ngraph-related tasks. To tackle the challenge, automated graph machine learning,\nwhich aims at discovering the best hyper-parameter and neural architecture\nconfiguration for different graph tasks/data without manual design, is gaining\nan increasing number of attentions from the research community. In this paper,\nwe extensively discuss automated graph machine learning approaches, covering\nhyper-parameter optimization (HPO) and neural architecture search (NAS) for\ngraph machine learning. We briefly overview existing libraries designed for\neither graph machine learning or automated machine learning respectively, and\nfurther in depth introduce AutoGL, our dedicated and the world's first\nopen-source library for automated graph machine learning. Also, we describe a\ntailored benchmark that supports unified, reproducible, and efficient\nevaluations. Last but not least, we share our insights on future research\ndirections for automated graph machine learning. This paper is the first\nsystematic and comprehensive discussion of approaches, libraries as well as\ndirections for automated graph machine learning.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2022-01-04",
    "authors": [
      "Xin Wang",
      "Ziwei Zhang",
      "Haoyang Li",
      "Wenwu Zhu"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2201.01288v2"
  },
  {
    "title": "Detection of brain tumors using machine learning algorithms",
    "abstract": "An algorithm capable of processing NMR images was developed for analysis\nusing machine learning techniques to detect the presence of brain tumors.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2022-01-12",
    "authors": [
      "Horacio Corral",
      "Javier Melchor",
      "Balam Sotelo",
      "Jorge Vera"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2201.04703v1"
  },
  {
    "title": "Elements of effective machine learning datasets in astronomy",
    "abstract": "In this work, we identify elements of effective machine learning datasets in\nastronomy and present suggestions for their design and creation. Machine\nlearning has become an increasingly important tool for analyzing and\nunderstanding the large-scale flood of data in astronomy. To take advantage of\nthese tools, datasets are required for training and testing. However, building\nmachine learning datasets for astronomy can be challenging. Astronomical data\nis collected from instruments built to explore science questions in a\ntraditional fashion rather than to conduct machine learning. Thus, it is often\nthe case that raw data, or even downstream processed data is not in a form\namenable to machine learning. We explore the construction of machine learning\ndatasets and we ask: what elements define effective machine learning datasets?\nWe define effective machine learning datasets in astronomy to be formed with\nwell-defined data points, structure, and metadata. We discuss why these\nelements are important for astronomical applications and ways to put them in\npractice. We posit that these qualities not only make the data suitable for\nmachine learning, they also help to foster usable, reusable, and replicable\nscience practices.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2022-11-25",
    "authors": [
      "Bernie Boscoe",
      "Tuan Do",
      "Evan Jones",
      "Yunqi Li",
      "Kevin Alfaro",
      "Christy Ma"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/2211.14401v2"
  },
  {
    "title": "Bridging belief function theory to modern machine learning",
    "abstract": "Machine learning is a quickly evolving field which now looks really different\nfrom what it was 15 years ago, when classification and clustering were major\nissues. This document proposes several trends to explore the new questions of\nmodern machine learning, with the strong afterthought that the belief function\nframework has a major role to play.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2015-04-15",
    "authors": [
      "Thomas Burger"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1504.03874v1"
  },
  {
    "title": "Electre Tri-Machine Learning Approach to the Record Linkage Problem",
    "abstract": "In this short paper, the Electre Tri-Machine Learning Method, generally used\nto solve ordinal classification problems, is proposed for solving the Record\nLinkage problem. Preliminary experimental results show that, using the Electre\nTri method, high accuracy can be achieved and more than 99% of the matches and\nnonmatches were correctly identified by the procedure.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2015-05-25",
    "authors": [
      "Renato De Leone",
      "Valentina Minnetti"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1505.06614v1"
  },
  {
    "title": "Distributed Multitask Learning",
    "abstract": "We consider the problem of distributed multi-task learning, where each\nmachine learns a separate, but related, task. Specifically, each machine learns\na linear predictor in high-dimensional space,where all tasks share the same\nsmall support. We present a communication-efficient estimator based on the\ndebiased lasso and show that it is comparable with the optimal centralized\nmethod.",
    "doi": "",
    "journal_name": "Arxiv",
    "publication_year": "2015-10-02",
    "authors": [
      "Jialei Wang",
      "Mladen Kolar",
      "Nathan Srebro"
    ],
    "keywords": "",
    "subject_areas": "",
    "scopus_id": "http://arxiv.org/abs/1510.00633v1"
  }
]